{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일 불러오기\n",
    "학습 데이터, 테스트 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf) # print all numpy values\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, OneHotEncoder, MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['주야', '요일', '발생지시도', '발생지시군구', '사고유형_대분류', '사고유형_중분류', '법규위반', \n",
    "            '도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류']\n",
    "numerical = ['사상자수', '사망자수', '중상자수', '경상자수','부상신고자수']\n",
    "\n",
    "x_train_num = pd.read_csv('./교통사망사고정보/Kor_Train_교통사망사고정보(12.1~17.6).csv',encoding='cp949', usecols=numerical)\n",
    "\n",
    "x_train_cat = pd.read_csv('./교통사망사고정보/Kor_Train_교통사망사고정보(12.1~17.6).csv',encoding='cp949', usecols=categorical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_num = pd.read_csv('./test_kor.csv',encoding='cp949', usecols=numerical)\n",
    "\n",
    "x_test_cat = pd.read_csv('./test_kor.csv',encoding='cp949', usecols=categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encdoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat((x_test_cat.dropna(), x_train_cat))\n",
    "# for col in all_data.select_dtypes(include=[np.object]).columns:\n",
    "#     print(col, all_data[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iron/.local/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  \n",
      "/home/iron/.local/lib/python3.5/site-packages/ipykernel_launcher.py:3: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for column in all_data.select_dtypes(include=[np.object]).columns:\n",
    "    x_train_cat[column] = x_train_cat[column].astype('category', categories = all_data[column].unique())\n",
    "    x_test_cat[column] = x_test_cat[column].astype('category', categories = all_data[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cat = pd.get_dummies(data=x_train_cat)\n",
    "x_test_cat = pd.get_dummies(data=x_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 328)\n",
      "(50, 328)\n"
     ]
    }
   ],
   "source": [
    "# One Encoding Shape 확인\n",
    "print(x_train_cat.shape)\n",
    "print(x_test_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Input, LSTM, concatenate, Dropout, Conv2D, MaxPool2D, Embedding, Reshape, Conv1D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras import metrics\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 328)\n",
      "(25037, 5)\n",
      "(50, 328)\n",
      "(50, 5)\n"
     ]
    }
   ],
   "source": [
    "# Train Data Shape\n",
    "print(x_train_cat.shape)\n",
    "print(x_train_num.shape)\n",
    "# Test Data Shape\n",
    "print(x_test_cat.shape)\n",
    "print(x_test_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric cases\n",
    "Case1 = ['사망자수','사상자수','경상자수']\n",
    "Case2 = ['사상자수', '중상자수', '부상신고자수']\n",
    "Case3 = ['사상자수', '중상자수', '경상자수' ]\n",
    "Case4 = ['사망자수', '사상자수', '중상자수' ]\n",
    "\n",
    "# Categorical cases\n",
    "Case5 = ['사고유형_대분류', '사고유형_중분류', '법규위반']\n",
    "Case6 = ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류']\n",
    "Case7 = ['도로형태_대분류', '도로형태', '당사자종별_2당_대분류']\n",
    "Case8 = ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류']\n",
    "Case11 = ['발생지시도', '발생지시군구']\n",
    "Case12 = ['요일', '사고유형_대분류', '사고유형_중분류']\n",
    "Case13 = ['요일', '사고유형_중분류', '법규위반', '도로형태_대분류']\n",
    "\n",
    "# Mixed cases\n",
    "Case9 = ['사망자수', '사상자수', '발생지시군구']\n",
    "Case10 = ['중상자수', '경상자수', '발생지시군구']\n",
    "Case14 = ['사망자수', '사상자수', '주야', '당사자종별_1당_대분류']\n",
    "Case15 = ['사상자수', '중상자수', '주야', '도로형태']\n",
    "\n",
    "Cases = [Case1, Case2, Case3, Case4, Case5, Case6, Case7, Case8, Case9, Case10,\n",
    "         Case11, Case12, Case13, Case14, Case15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case ranges\n",
    "\n",
    "case1_range = [0, 1]\n",
    "case2_range = [2, 3]\n",
    "case3_range = [4, 6]\n",
    "case4_range = [7, 9]\n",
    "case5_range = [10, 19]\n",
    "case6_range = [20, 22]\n",
    "case7_range = [23, 25]\n",
    "case8_range = [26, 29]\n",
    "case9_range = [30, 31]\n",
    "case10_range = [32, 34]\n",
    "case11_range = [35, 39]\n",
    "case12_range = [40, 41]\n",
    "case13_range = [42, 44]\n",
    "case14_range = [45, 46]\n",
    "case15_range = [47, 49]\n",
    "\n",
    "test_ranges = [case1_range, case2_range, case3_range, case4_range, case5_range, case6_range,\n",
    "             case7_range, case8_range, case9_range, case10_range, case11_range, case12_range,\n",
    "             case13_range, case14_range, case15_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['사망자수', '사상자수', '경상자수'] [0, 1]\n",
      "2 ['사상자수', '중상자수', '부상신고자수'] [2, 3]\n",
      "3 ['사상자수', '중상자수', '경상자수'] [4, 6]\n",
      "4 ['사망자수', '사상자수', '중상자수'] [7, 9]\n",
      "5 ['사고유형_대분류', '사고유형_중분류', '법규위반'] [10, 19]\n",
      "6 ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류'] [20, 22]\n",
      "7 ['도로형태_대분류', '도로형태', '당사자종별_2당_대분류'] [23, 25]\n",
      "8 ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류'] [26, 29]\n",
      "9 ['사망자수', '사상자수', '발생지시군구'] [30, 31]\n",
      "10 ['중상자수', '경상자수', '발생지시군구'] [32, 34]\n",
      "11 ['발생지시도', '발생지시군구'] [35, 39]\n",
      "12 ['요일', '사고유형_대분류', '사고유형_중분류'] [40, 41]\n",
      "13 ['요일', '사고유형_중분류', '법규위반', '도로형태_대분류'] [42, 44]\n",
      "14 ['사망자수', '사상자수', '주야', '당사자종별_1당_대분류'] [45, 46]\n",
      "15 ['사상자수', '중상자수', '주야', '도로형태'] [47, 49]\n"
     ]
    }
   ],
   "source": [
    "# train, set result in new array\n",
    "for (idx, case), range_x in zip(enumerate(Cases), test_ranges):\n",
    "    print(idx+1, case, range_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result():\n",
    "    '''\n",
    "    test file에 있는 값을 result file에 저장\n",
    "    '''\n",
    "    test_file = pd.read_csv('./test_kor_1.csv', encoding='cp949', names= [chr(y) for y in range(ord('A'),ord('P')+1)])\n",
    "    result_file = pd.read_csv('./result_kor.csv', encoding='cp949')\n",
    "    \n",
    "    cols = result_file['열'].values\n",
    "    rows = result_file['행'].values\n",
    "    vals = result_file['값'].astype('str').values\n",
    "    \n",
    "    rows-=1\n",
    "    \n",
    "    for i, (row, col) in enumerate(zip(rows, cols)):      \n",
    "        vals[i] = test_file[col][row]\n",
    "\n",
    "    rows += 1\n",
    "\n",
    "    with open('./result_kor1.csv', 'wb') as f:\n",
    "        for i in result_file.index:\n",
    "            np.savetxt(f,  np.c_[rows,cols,vals],  delimiter=\",\", fmt='%s', encoding='cp949', header='행,열,값', comments='')\n",
    "    print('Save Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 데이터 Case 함수\n",
    "\n",
    "def numeric_case(case, start, end):\n",
    "    \n",
    "    K.clear_session()\n",
    "    case_copy=case.copy()\n",
    "    \n",
    "    # Case 확인\n",
    "    print(\"Case:\", case)\n",
    "    \n",
    "    # Train Data\n",
    "    X = x_train_num.drop(columns=case)\n",
    "    X = pd.concat([X, x_train_cat], axis=1).values\n",
    "    \n",
    "    # Test Data\n",
    "    X_test = x_test_num.drop(columns=case)\n",
    "    X_test = pd.concat([X_test, x_test_cat],axis=1).values\n",
    "    \n",
    "    # Label Data\n",
    "    if '사상자수' in case:       \n",
    "        case_copy.remove('사상자수')\n",
    "        print('사상자제거:', case_copy) \n",
    "    Y = x_train_num[case_copy].values\n",
    "    \n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    # Model define\n",
    "\n",
    "    num_input = Input(shape=( X.shape[1], 1), name='num_input')\n",
    "    x = LSTM(512, return_sequences=True)(num_input)\n",
    "    x = LSTM(512)(x)\n",
    "    x = Dense((int(len(X[0] + len(Y[0])) * 2 /3)), activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense((int(len(X[0] + len(Y[0])) * 2 /3)), activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense((int(len(X[0] + len(Y[0])) * 2 /3)), activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    num_output = Dense(len(Y[0]), name='num_output')(x)\n",
    "    \n",
    "    \n",
    "    # Model define\n",
    "#     num_input = Input(shape=(len(X[0]),), name='num_input')\n",
    "#     x = Dense((int(len(X[0] + len(Y[0])) * 2 /3)), activation='relu')(num_input)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = Dense((int(len(X[0] + len(Y[0])) * 2 /3)), activation='relu')(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = Dense((int(len(X[0] + len(Y[0])) * 2 /3)), activation='relu')(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     num_output = Dense(len(Y[0]), name='num_output')(x)\n",
    "\n",
    "    model = Model(inputs=num_input, outputs=num_output)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=25, verbose=1, factor=0.5, min_lr=0.00000001)\n",
    "\n",
    "    callbacks = [\n",
    "        learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "        EarlyStopping('val_loss', patience=15)# val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks, validation_split=0.2 )\n",
    "    \n",
    "    \n",
    "    # make a prediction\n",
    "    Y_test = model.predict(X_test[start:end+1])\n",
    "    \n",
    "    del model\n",
    "    \n",
    "    return Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 데이터 Case 함수\n",
    "\n",
    "def categorical_case(case, start, end):\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    # Case 확인\n",
    "    print(\"Case:\", case)\n",
    "    \n",
    "    col_name = [] # ex. '사고유형_대분류_차대차', '사고유형_대분류_차대사람', '사고유형_대분류_차량단독'\n",
    "    label_name = [] #  ex. '차대차', '차대사람', '차량단독\n",
    "    \n",
    "    # One Hot Encoding 후 Columns 이름과 Columns에 들어 있는 값 \n",
    "    for col in case:\n",
    "        label_name.extend(all_data[col].unique()) \n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)\n",
    "\n",
    "    # Train Data \n",
    "    X = x_train_cat.drop(columns=col_name)\n",
    "    X = pd.concat([X, x_train_num], axis=1).values\n",
    "\n",
    "    # Test Data\n",
    "    X_test = x_test_cat.drop(columns=col_name)\n",
    "    X_test = pd.concat([X_test, x_test_num],axis=1).values\n",
    "    \n",
    "    # Label Data\n",
    "    Y = x_train_cat[col_name].values\n",
    "    \n",
    "    \n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    \n",
    "    cat_input = Input(shape=( X.shape[1], 1), name='cat_input')\n",
    "    x = LSTM(512)(cat_input)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    cat_output = Dense(len(Y[0]), activation='sigmoid', name='cat_output')(x)\n",
    "    \n",
    "    # Model define\n",
    "#     cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "#     x = Dense(512, activation='relu')(cat_input)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = Dense(512, activation='relu')(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = Dense(512, activation='relu')(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = Dense(256, activation='relu')(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     cat_output = Dense(len(Y[0]), activation='sigmoid', name='cat_output')(x)\n",
    "\n",
    "    model = Model(inputs=cat_input, outputs=cat_output)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=25, verbose=1, factor=0.5, min_lr=0.00000001)\n",
    "\n",
    "    callbacks = [\n",
    "        learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "        EarlyStopping('val_loss', patience=15), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "        ]\n",
    "\n",
    "    history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )\n",
    "    \n",
    "    # make a prediction\n",
    "    Y_test = model.predict(X_test[start:end+1])\n",
    "    \n",
    "\n",
    "    '''\n",
    "    예시 출력:\n",
    "        사고유형_대분류 : 차량단독\n",
    "        사고유형_중분류 : 공작물충돌\n",
    "        법규위반 : 안전운전 의무 불이행\n",
    "    '''\n",
    "    result = []\n",
    "    for cat in Y_test: \n",
    "        x_list = list(cat)\n",
    "        label_name_x = label_name.copy()\n",
    "        temp = []\n",
    "        for col in case:\n",
    "#             print(col, ':', label_name_x[x_list.index(max(x_list[0:len(all_data[col].unique())]))] )\n",
    "            temp.append(label_name_x[x_list.index(max(x_list[0:len(all_data[col].unique())]))])\n",
    "            del x_list[:len(all_data[col].unique())]\n",
    "            del label_name_x[:len(all_data[col].unique())]\n",
    "        result.append(temp)\n",
    "        \n",
    "        \n",
    "    del model\n",
    "    \n",
    "    return np.array(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 믹스형 데이터 Case 함수\n",
    "\n",
    "def mix_case(case, n, start, end):\n",
    "    '''\n",
    "    case: Case에 해당되는 컬럼이 담긴 배열\n",
    "    n: 범주형 데이터 수\n",
    "    start: 해당 Case 테스트의 시작 인덱스\n",
    "    end: 해당 Case 테스트의 마지막 인덱스\n",
    "    '''\n",
    "    \n",
    "    case_copy=case.copy()\n",
    "    \n",
    "    # categorical\n",
    "    col_name = []\n",
    "    label_name = []\n",
    "    cat_name = case_copy[-n:]\n",
    "    \n",
    "    for col in case_copy[-n:]:\n",
    "        label_name.extend(all_data[col].unique()) \n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)\n",
    "    \n",
    "    Y_cat = x_train_cat[col_name].values\n",
    "    X1 = x_train_cat.drop(columns=col_name)\n",
    "    X_test1 = x_test_cat.drop(columns=col_name)\n",
    "    \n",
    "    # categorical columns 삭제\n",
    "    del case_copy[-n:]\n",
    "    \n",
    "    # numerical\n",
    "    X2 = x_train_num.drop(columns=case_copy)\n",
    "    X_test2 = x_test_num.drop(columns=case_copy)\n",
    "    \n",
    "    if '사상자수' in case: \n",
    "        case_copy.remove('사상자수')\n",
    "    Y_num = x_train_num[case_copy].values\n",
    "    \n",
    "    X = pd.concat([X1, X2], axis=1).values\n",
    "    X_test = pd.concat([X_test1, X_test2],axis=1).values\n",
    "    \n",
    "    \n",
    "    # Model define\n",
    "    cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "    x = Dense(1024, activation='relu')(cat_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    if n == 1:\n",
    "        cat_output = Dense(len(Y_cat[0]), activation='softmax', name='cat_output')(x)\n",
    "    elif n == 2:\n",
    "        cat_output = Dense(len(Y_cat[0]), activation='sigmoid', name='cat_output')(x)\n",
    "        \n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    num_output = Dense(len(Y_num[0]), name='num_output')(x)\n",
    "\n",
    "    model = Model(inputs=cat_input, outputs=[cat_output, num_output])\n",
    "\n",
    "    if n==1:\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss={'cat_output': 'categorical_crossentropy', 'num_output': 'mse'},\n",
    "                      metrics=['accuracy'])\n",
    "    elif n==2:\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss={'cat_output': 'binary_crossentropy', 'num_output': 'mse'},\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='cat_output_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "    callbacks = [\n",
    "        learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "        EarlyStopping('val_loss', patience=20), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "    ]\n",
    "\n",
    "    history = model.fit(X, {'cat_output':Y_cat, 'num_output':Y_num}, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )\n",
    "    \n",
    "    \n",
    "    # make a prediction\n",
    "    Y_test = model.predict(X_test[start:end+1])    \n",
    "    \n",
    "    result = []\n",
    "    for cat, num in zip(Y_test[0], Y_test[1]):\n",
    "        x_list = list(cat)\n",
    "        label_name_x = label_name.copy()\n",
    "        temp = []\n",
    "        for col in cat_name:\n",
    "            temp.append(label_name_x[x_list.index(max(x_list[0:len(all_data[col].unique())]))])\n",
    "            \n",
    "            # 출력한 Column과 데이터 삭제\n",
    "            del x_list[:len(all_data[col].unique())]\n",
    "            del label_name_x[:len(all_data[col].unique())]\n",
    "        temp.extend(num)\n",
    "        result.append(temp)\n",
    "        \n",
    "    \n",
    "    return np.array(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set result array to each cases\n",
    "def setResult(arr, predict, case):\n",
    "    result_arr = arr\n",
    "    \n",
    "    if case == [int(x) for x in range(0, 2)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 2] = predict[row, 0] # 사망자수\n",
    "            result_arr[row, 5] = predict[row, 1] # 사상자수            \n",
    "            result_arr[row, 3] = result_arr[row, 2] + result_arr[row, 4:7].sum() # 사상자수 = 사망자수 + (중상+경상+부상신고자수)\n",
    "            \n",
    "    elif case == [int(x) for x in range(2, 4)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 4] = predict[row, 0]\n",
    "            result_arr[row, 6] = predict[row, 1]\n",
    "            result_arr[row, 3] = result_arr[row, 2] + result_arr[row, 4:7].sum()\n",
    "            \n",
    "    elif case == [int(x) for x in range(4, 7)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 4] = predict[row, 0]\n",
    "            result_arr[row, 5] = predict[row, 1]\n",
    "            result_arr[row, 3] = result_arr[row, 2] + result_arr[row, 4:7].sum()\n",
    "            \n",
    "    elif case == [int(x) for x in range(7, 10)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 2] = predict[row, 0]\n",
    "            result_arr[row, 4] = predict[row, 1]\n",
    "            result_arr[row, 3] = result_arr[row, 2] + result_arr[row, 4:7].sum()\n",
    "            \n",
    "    elif case == [int(x) for x in range(10,20)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 9] = predict[row, 0] \n",
    "            result_arr[row, 10] = predict[row, 1] \n",
    "            result_arr[row, 11] = predict[row, 2] \n",
    "            print(result_arr[row, 11], predict[row, 2])\n",
    "            \n",
    "    elif case == [int(x) for x in range(20,23)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 12] = predict[row, 0] \n",
    "            result_arr[row, 13] = predict[row, 1] \n",
    "            result_arr[row, 14] = predict[row, 2] \n",
    "            \n",
    "    elif case == [int(x) for x in range(23,26)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 12] = predict[row, 0] \n",
    "            result_arr[row, 13] = predict[row, 1] \n",
    "            result_arr[row, 15] = predict[row, 2] \n",
    "    \n",
    "    elif case == [int(x) for x in range(26,30)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 12] = predict[row, 0] \n",
    "            result_arr[row, 13] = predict[row, 1] \n",
    "            result_arr[row, 14] = predict[row, 2] \n",
    "            result_arr[row, 15] = predict[row, 3] \n",
    "    \n",
    "    elif case == [int(x) for x in range(35,40)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 7] = predict[row, 0] \n",
    "            result_arr[row, 8] = predict[row, 1] \n",
    "        \n",
    "    elif case == [int(x) for x in range(40,42)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 1] = predict[row, 0] \n",
    "            result_arr[row, 9] = predict[row, 1] \n",
    "            result_arr[row, 10] = predict[row, 2] \n",
    "        \n",
    "    elif case == [int(x) for x in range(42,45)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 1] = predict[row, 0] \n",
    "            result_arr[row, 10] = predict[row, 1] \n",
    "            result_arr[row, 11] = predict[row, 2] \n",
    "            result_arr[row, 12] = predict[row, 3] \n",
    "    \n",
    "    elif case == [int(x) for x in range(30,32)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 2] = float(predict[row, 1])\n",
    "            result_arr[row, 3] = result_arr[row, 2] + result_arr[row, 4:7].sum()\n",
    "            result_arr[row, 8] = predict[row, 0]\n",
    "            \n",
    "    elif case == [int(x) for x in range(32,35)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 4] = predict[row, 1]\n",
    "            result_arr[row, 5] = predict[row, 2]\n",
    "            result_arr[row, 8] = predict[row, 0]\n",
    "            \n",
    "    elif case == [int(x) for x in range(45,47)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 0] = predict[row, 0]\n",
    "            result_arr[row, 2] = float(predict[row, 2])\n",
    "            result_arr[row, 14] = predict[row, 1]\n",
    "            result_arr[row, 3] = result_arr[row, 2] + result_arr[row, 4:7].sum()\n",
    "            \n",
    "    elif case == [int(x) for x in range(47,50)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 0] = predict[row, 0]\n",
    "            result_arr[row, 4] = float(predict[row, 2])\n",
    "            result_arr[row, 13] = predict[row, 1]\n",
    "            result_arr[row, 3] = result_arr[row, 2] + result_arr[row, 4:7].sum()\n",
    "    \n",
    "    print(result_arr)\n",
    "    return result_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test = pd.read_csv('./test_kor.csv',encoding='cp949')\n",
    "\n",
    "# setResult(each case array, predict array, start to end in each case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['주야' '요일' '사망자수' '사상자수' '중상자수' '경상자수' '부상신고자수' '발생지시도' '발생지시군구'\n",
      "  '사고유형_대분류' '사고유형_중분류' '법규위반' '도로형태_대분류' '도로형태' '당사자종별_1당_대분류'\n",
      "  '당사자종별_2당_대분류']]\n"
     ]
    }
   ],
   "source": [
    "test_arr = np.array([x_test.columns.values])\n",
    "print(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Case: ['사망자수', '사상자수', '경상자수']\n",
      "사상자제거: ['사망자수', '경상자수']\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 217s 11ms/step - loss: 0.7952 - acc: 0.9559 - val_loss: 0.7041 - val_acc: 0.9551\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 211s 11ms/step - loss: 0.6936 - acc: 0.9570 - val_loss: 0.7049 - val_acc: 0.9551\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 214s 11ms/step - loss: 0.6910 - acc: 0.9570 - val_loss: 0.7046 - val_acc: 0.9551\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 212s 11ms/step - loss: 0.6890 - acc: 0.9570 - val_loss: 0.7046 - val_acc: 0.9551\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 211s 11ms/step - loss: 0.6881 - acc: 0.9570 - val_loss: 0.7046 - val_acc: 0.9551\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 211s 11ms/step - loss: 0.6821 - acc: 0.9570 - val_loss: 0.7004 - val_acc: 0.9551\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 215s 11ms/step - loss: 0.6744 - acc: 0.9570 - val_loss: 0.6987 - val_acc: 0.9551\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 211s 11ms/step - loss: 0.6694 - acc: 0.9570 - val_loss: 0.6877 - val_acc: 0.9551\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 210s 10ms/step - loss: 0.6663 - acc: 0.9565 - val_loss: 0.6820 - val_acc: 0.9551\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 209s 10ms/step - loss: 0.6634 - acc: 0.9547 - val_loss: 0.6856 - val_acc: 0.9551\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 210s 10ms/step - loss: 0.6666 - acc: 0.9553 - val_loss: 0.6797 - val_acc: 0.9551\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 210s 10ms/step - loss: 0.6626 - acc: 0.9557 - val_loss: 0.6886 - val_acc: 0.9551\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 212s 11ms/step - loss: 0.6656 - acc: 0.9562 - val_loss: 0.7571 - val_acc: 0.9551\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 210s 10ms/step - loss: 0.6752 - acc: 0.9557 - val_loss: 0.6617 - val_acc: 0.9551\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 210s 10ms/step - loss: 0.6568 - acc: 0.9530 - val_loss: 0.6860 - val_acc: 0.9551\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 210s 10ms/step - loss: 0.6634 - acc: 0.9538 - val_loss: 0.6767 - val_acc: 0.9551\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 210s 10ms/step - loss: 0.6651 - acc: 0.9528 - val_loss: 0.6799 - val_acc: 0.9551\n",
      "Epoch 18/50\n",
      "20029/20029 [==============================] - 210s 10ms/step - loss: 0.6642 - acc: 0.9566 - val_loss: 0.6618 - val_acc: 0.9551\n",
      "Epoch 19/50\n",
      "20029/20029 [==============================] - 212s 11ms/step - loss: 0.6622 - acc: 0.9550 - val_loss: 0.6565 - val_acc: 0.9461\n",
      "Epoch 20/50\n",
      "20029/20029 [==============================] - 210s 10ms/step - loss: 0.6587 - acc: 0.9515 - val_loss: 0.6868 - val_acc: 0.9551\n",
      "Epoch 21/50\n",
      "20029/20029 [==============================] - 210s 10ms/step - loss: 0.6595 - acc: 0.9527 - val_loss: 0.6604 - val_acc: 0.9483\n",
      "Epoch 22/50\n",
      "20029/20029 [==============================] - 213s 11ms/step - loss: 0.6429 - acc: 0.9469 - val_loss: 0.6430 - val_acc: 0.9427\n",
      "Epoch 23/50\n",
      "20029/20029 [==============================] - 210s 10ms/step - loss: 0.6523 - acc: 0.9468 - val_loss: 0.6458 - val_acc: 0.9465\n",
      "Epoch 24/50\n",
      "20029/20029 [==============================] - 210s 10ms/step - loss: 0.6415 - acc: 0.9481 - val_loss: 0.6852 - val_acc: 0.9551\n",
      "Epoch 25/50\n",
      "20029/20029 [==============================] - 210s 10ms/step - loss: 0.6490 - acc: 0.9468 - val_loss: 0.6420 - val_acc: 0.9419\n",
      "Epoch 26/50\n",
      "20029/20029 [==============================] - 210s 10ms/step - loss: 0.6471 - acc: 0.9462 - val_loss: 0.6441 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 27/50\n",
      "20029/20029 [==============================] - 209s 10ms/step - loss: 0.6321 - acc: 0.9471 - val_loss: 0.6298 - val_acc: 0.9465\n",
      "Epoch 28/50\n",
      "20029/20029 [==============================] - 210s 10ms/step - loss: 0.6260 - acc: 0.9483 - val_loss: 0.6252 - val_acc: 0.9431\n",
      "Epoch 29/50\n",
      "20029/20029 [==============================] - 213s 11ms/step - loss: 0.6353 - acc: 0.9436 - val_loss: 0.6311 - val_acc: 0.9467\n",
      "Epoch 30/50\n",
      "20029/20029 [==============================] - 211s 11ms/step - loss: 0.6232 - acc: 0.9472 - val_loss: 0.6354 - val_acc: 0.9511\n",
      "Epoch 31/50\n",
      "20029/20029 [==============================] - 210s 10ms/step - loss: 0.6228 - acc: 0.9481 - val_loss: 0.6336 - val_acc: 0.9461\n",
      "Epoch 32/50\n",
      "20029/20029 [==============================] - 211s 11ms/step - loss: 0.6182 - acc: 0.9484 - val_loss: 0.6231 - val_acc: 0.9467\n",
      "Epoch 33/50\n",
      "20029/20029 [==============================] - 211s 11ms/step - loss: 0.6290 - acc: 0.9472 - val_loss: 0.6377 - val_acc: 0.9519\n",
      "Epoch 34/50\n",
      "18432/20029 [==========================>...] - ETA: 15s - loss: 0.6349 - acc: 0.9508"
     ]
    }
   ],
   "source": [
    "# train, set result in new array\n",
    "for (idx, case), case_range in zip(enumerate(Cases), test_ranges):\n",
    "    # for matching case number +1 to idx\n",
    "    print()\n",
    "    # numeric case\n",
    "    if (idx+1) <= 4:      \n",
    "#         print(idx+1, case, case_range)\n",
    "        Case_prediction = numeric_case(case, case_range[0], case_range[1])\n",
    "        answer = setResult(x_test.loc[case_range[0]:case_range[1]].values, Case_prediction, [int(x) for x in range(case_range[0], case_range[1]+1)])\n",
    "        test_arr = np.append(test_arr, answer, axis=0)\n",
    "        \n",
    "    # categorical case\n",
    "    elif ((idx+1) >= 5 and (idx+1) <= 8) or ((idx+1) >= 11 and (idx+1) <= 13):\n",
    "#         print(idx+1, case, case_range)\n",
    "        Case_prediction = categorical_case(case, case_range[0], case_range[1])\n",
    "        answer = setResult(x_test.loc[case_range[0]:case_range[1]].values, Case_prediction, [int(x) for x in range(case_range[0], case_range[1]+1)])\n",
    "        test_arr = np.append(test_arr, answer, axis=0)\n",
    "\n",
    "    # mixed case\n",
    "    elif (idx+1) == 9 or (idx+1) == 10 or (idx+1) >= 14:\n",
    "#         print(idx+1, case, case_range)\n",
    "        \n",
    "        if (idx+1) == 9 or (idx+1) == 10:\n",
    "            num_categories = 1  # number of categories for each case\n",
    "            \n",
    "        if (idx+1) == 14 or (idx+1) == 15:\n",
    "            num_categories = 2\n",
    "            \n",
    "        Case_prediction = mix_case(case, num_categories, case_range[0], case_range[1])\n",
    "        answer = setResult(x_test.loc[case_range[0]:case_range[1]].values, Case_prediction, [int(x) for x in range(case_range[0], case_range[1]+1)])\n",
    "        test_arr = np.append(test_arr, answer, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test_kor_1.csv','wb',) as f:\n",
    "        np.savetxt(f,  test_arr,  delimiter=\",\", fmt='%s', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
