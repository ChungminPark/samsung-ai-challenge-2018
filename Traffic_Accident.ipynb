{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리\n",
    "\n",
    "### 수치형\n",
    "사상자수, 사망자수, 중상자수, 경상자수, 부상신고자수\n",
    "\n",
    "### 범주형\n",
    "주야, 요일, 발생지시도, 발생지시군구, \n",
    "사고유형_대분류, 사고유형_중분류, 법규위반, 도로형태_대분류,\n",
    "도로형태, 당사자종별_1당_대분류, 당사자종별_2당_대분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, OneHotEncoder, MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical = ['주야', '요일', '발생지시도', '발생지시군구', '사고유형_대분류', '사고유형_중분류', '법규위반', \n",
    "            '도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류']\n",
    "numerical = ['사상자수', '사망자수', '중상자수', '경상자수','부상신고자수']\n",
    "x_train_num = pd.read_csv('./교통사망사고정보/Kor_Train_교통사망사고정보(12.1~17.6).csv',encoding='cp949', \n",
    "                              usecols=numerical)\n",
    "\n",
    "x_train_cat = pd.read_csv('./교통사망사고정보/Kor_Train_교통사망사고정보(12.1~17.6).csv',encoding='cp949',\n",
    "                               usecols=categorical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_num = pd.read_csv('./test_kor.csv',encoding='cp949', \n",
    "                              usecols=numerical)\n",
    "\n",
    "x_test_cat = pd.read_csv('./test_kor.csv',encoding='cp949',\n",
    "                               usecols=categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encdoing을 나열해서 만드는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat((x_test_cat.dropna(),x_train_cat))\n",
    "# for col in all_data.select_dtypes(include=[np.object]).columns:\n",
    "#     print(col, all_data[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iron/.local/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  \n",
      "/home/iron/.local/lib/python3.5/site-packages/ipykernel_launcher.py:3: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for column in all_data.select_dtypes(include=[np.object]).columns:\n",
    "    x_train_cat[column] = x_train_cat[column].astype('category', categories = all_data[column].unique())\n",
    "    x_test_cat[column] = x_test_cat[column].astype('category', categories = all_data[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cat = pd.get_dummies(data=x_train_cat)\n",
    "x_test_cat = pd.get_dummies(data=x_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 328)\n",
      "(50, 328)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_cat.shape)\n",
    "print(x_test_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Input, LSTM, concatenate, Dropout, Conv2D, MaxPool2D, Embedding, Reshape, Conv1D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras import metrics\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 328)\n",
      "(25037, 5)\n",
      "(50, 328)\n",
      "(50, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_cat.shape)\n",
    "print(x_train_num.shape)\n",
    "print(x_test_cat.shape)\n",
    "print(x_test_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Case1 = ['사망자수','사상자수','경상자수']\n",
    "Case2 = ['사상자수', '중상자수', '부상신고자수']\n",
    "Case3 = ['사상자수', '중상자수', '경상자수' ]\n",
    "Case4 = ['사망자수', '사상자수', '중상자수' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수치형 데이터 Case 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_case(case, start, end):\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    print(\"Case:\", case)\n",
    "    X = x_train_num.drop(columns=case)\n",
    "    X_test = x_test_num.drop(columns=case)\n",
    "    \n",
    "    case_copy=case.copy()\n",
    "    if '사상자수' in case:       \n",
    "        case_copy.remove('사상자수')\n",
    "    print('사상자제거:', case_copy)\n",
    "    Y = x_train_num[case_copy].values\n",
    "    \n",
    "    # 수치형 데이터와 범주형 데이터 합치기\n",
    "    X = pd.concat([X, x_train_cat], axis=1).values\n",
    "    X_test = pd.concat([X_test, x_test_cat],axis=1).values\n",
    "    \n",
    "    print(X)\n",
    "    print(Y)\n",
    "    \n",
    "    # 모델 정의\n",
    "    num_input = Input(shape=(len(X[0]),), name='num_input')\n",
    "    x = Dense(512, activation='relu')(num_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    num_output = Dense(len(Y[0]), name='num_output')(x)\n",
    "\n",
    "    model = Model(inputs=num_input, outputs=num_output)\n",
    "\n",
    "    model.compile(optimizer='sgd',\n",
    "                  loss='mse',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                        patience=25, \n",
    "                                        verbose=1, \n",
    "                                        factor=0.5, \n",
    "                                        min_lr=0.00000001)\n",
    "\n",
    "    callbacks = [\n",
    "    #         learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "        EarlyStopping('val_loss', patience=5)# val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )\n",
    "    \n",
    "    \n",
    "    # make a prediction\n",
    "    Y_test = model.predict(X_test[range(start, end+1)])\n",
    "    \n",
    "    # show the inputs and predicted outputs\n",
    "    print(\"X=%s, Predicted=%s\" % (X_test[range(start, end+1)],  Y_test ))\n",
    "    del model\n",
    "    \n",
    "    return Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case: ['사망자수', '사상자수', '경상자수']\n",
      "[[0 0 1 ... 0 0 0]\n",
      " [2 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [5 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]]\n",
      "[[1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " ...\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 1s 67us/step - loss: 0.7096 - acc: 0.9364 - val_loss: 0.6200 - val_acc: 0.9555\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 32us/step - loss: 0.6186 - acc: 0.9540 - val_loss: 0.5800 - val_acc: 0.9413\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.6067 - acc: 0.9463 - val_loss: 0.6301 - val_acc: 0.9499\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5999 - acc: 0.9475 - val_loss: 0.5553 - val_acc: 0.9303\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5969 - acc: 0.9441 - val_loss: 0.5633 - val_acc: 0.9399\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 32us/step - loss: 0.5911 - acc: 0.9454 - val_loss: 0.5546 - val_acc: 0.9367\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 32us/step - loss: 0.5865 - acc: 0.9430 - val_loss: 0.5842 - val_acc: 0.9433\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5856 - acc: 0.9482 - val_loss: 0.5448 - val_acc: 0.9371\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5859 - acc: 0.9477 - val_loss: 0.5401 - val_acc: 0.9323\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5801 - acc: 0.9463 - val_loss: 0.5488 - val_acc: 0.9429\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5792 - acc: 0.9464 - val_loss: 0.5372 - val_acc: 0.9369\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5642 - acc: 0.9440 - val_loss: 0.5369 - val_acc: 0.9367\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5728 - acc: 0.9442 - val_loss: 0.5546 - val_acc: 0.9483\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5630 - acc: 0.9466 - val_loss: 0.5308 - val_acc: 0.9405\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 1s 33us/step - loss: 0.5812 - acc: 0.9497 - val_loss: 0.5225 - val_acc: 0.9373\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5589 - acc: 0.9439 - val_loss: 0.5228 - val_acc: 0.9393\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5694 - acc: 0.9470 - val_loss: 0.5182 - val_acc: 0.9389\n",
      "Epoch 18/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5600 - acc: 0.9447 - val_loss: 0.5189 - val_acc: 0.9419\n",
      "Epoch 19/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5546 - acc: 0.9459 - val_loss: 0.5206 - val_acc: 0.9451\n",
      "Epoch 20/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5422 - acc: 0.9445 - val_loss: 0.5207 - val_acc: 0.9435\n",
      "Epoch 21/50\n",
      "20029/20029 [==============================] - 1s 32us/step - loss: 0.5500 - acc: 0.9478 - val_loss: 0.5124 - val_acc: 0.9389\n",
      "Epoch 22/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5529 - acc: 0.9450 - val_loss: 0.5594 - val_acc: 0.9503\n",
      "Epoch 23/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5456 - acc: 0.9454 - val_loss: 0.5262 - val_acc: 0.9401\n",
      "Epoch 24/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5438 - acc: 0.9429 - val_loss: 0.5468 - val_acc: 0.9499\n",
      "Epoch 25/50\n",
      "20029/20029 [==============================] - 1s 32us/step - loss: 0.5779 - acc: 0.9455 - val_loss: 0.7159 - val_acc: 0.9547\n",
      "Epoch 26/50\n",
      "20029/20029 [==============================] - 1s 32us/step - loss: 0.6026 - acc: 0.9540 - val_loss: 0.5734 - val_acc: 0.9527\n",
      "X=[[0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], Predicted=[[1.0239908  0.50320923]\n",
      " [0.95704246 0.04179108]]\n"
     ]
    }
   ],
   "source": [
    "Case1_pre = numerical_case(Case1, 0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case: ['사상자수', '중상자수', '부상신고자수']\n",
      "사상자제거: ['중상자수', '부상신고자수']\n",
      "[[1 0 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " ...\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]]\n",
      "[[0 0]\n",
      " [2 0]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [5 0]\n",
      " [0 0]]\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.5868 - acc: 0.9350 - val_loss: 0.9553 - val_acc: 0.9892\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.5523 - acc: 0.9065 - val_loss: 0.9362 - val_acc: 0.9048\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.5314 - acc: 0.8812 - val_loss: 0.9234 - val_acc: 0.8516\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 30us/step - loss: 0.5370 - acc: 0.8613 - val_loss: 0.9144 - val_acc: 0.8307\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.5319 - acc: 0.8345 - val_loss: 0.9187 - val_acc: 0.7346\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.5281 - acc: 0.8419 - val_loss: 0.9189 - val_acc: 0.7808\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.5227 - acc: 0.8583 - val_loss: 0.9119 - val_acc: 0.6893\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 30us/step - loss: 0.5237 - acc: 0.8341 - val_loss: 0.9140 - val_acc: 0.6370\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.5275 - acc: 0.8290 - val_loss: 0.8995 - val_acc: 0.8700\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 30us/step - loss: 0.5242 - acc: 0.8542 - val_loss: 0.8998 - val_acc: 0.7879\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 30us/step - loss: 0.5297 - acc: 0.8346 - val_loss: 0.9270 - val_acc: 0.6829\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.5265 - acc: 0.8595 - val_loss: 0.9066 - val_acc: 0.7226\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5166 - acc: 0.8399 - val_loss: 0.9078 - val_acc: 0.7566\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 30us/step - loss: 0.5144 - acc: 0.8442 - val_loss: 0.8998 - val_acc: 0.6424\n",
      "X=[[1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [2. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], Predicted=[[-0.00488086 -0.00935701]\n",
      " [ 1.1789904   0.09281182]]\n"
     ]
    }
   ],
   "source": [
    "numerical_case(Case2, 2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case: ['사상자수', '중상자수', '경상자수']\n",
      "사상자제거: ['중상자수', '경상자수']\n",
      "[[1 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " ...\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]]\n",
      "[[0 0]\n",
      " [2 1]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [5 0]\n",
      " [0 0]]\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 1s 72us/step - loss: 1.1981 - acc: 0.5969 - val_loss: 1.1850 - val_acc: 0.8205\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 32us/step - loss: 1.1693 - acc: 0.6264 - val_loss: 1.1498 - val_acc: 0.8161\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 1.1427 - acc: 0.6227 - val_loss: 1.1051 - val_acc: 0.8161\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 1.1166 - acc: 0.6242 - val_loss: 1.0792 - val_acc: 0.7802\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 1.1065 - acc: 0.6075 - val_loss: 1.0780 - val_acc: 0.8397\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 1.0919 - acc: 0.6234 - val_loss: 1.0784 - val_acc: 0.6663\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 32us/step - loss: 1.0878 - acc: 0.6209 - val_loss: 1.0694 - val_acc: 0.7187\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 1.0645 - acc: 0.6319 - val_loss: 1.0689 - val_acc: 0.6721\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 1.0627 - acc: 0.6344 - val_loss: 1.0564 - val_acc: 0.5503\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 1.0475 - acc: 0.6266 - val_loss: 1.0355 - val_acc: 0.5527\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 32us/step - loss: 1.0357 - acc: 0.6261 - val_loss: 1.0205 - val_acc: 0.5471\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 32us/step - loss: 1.0266 - acc: 0.6346 - val_loss: 1.0319 - val_acc: 0.6194\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 32us/step - loss: 1.0157 - acc: 0.6465 - val_loss: 1.0448 - val_acc: 0.5186\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 32us/step - loss: 1.0068 - acc: 0.6286 - val_loss: 1.0213 - val_acc: 0.5885\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.9945 - acc: 0.6527 - val_loss: 1.0191 - val_acc: 0.6066\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 1s 32us/step - loss: 0.9918 - acc: 0.6199 - val_loss: 1.0189 - val_acc: 0.7612\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 1s 33us/step - loss: 0.9844 - acc: 0.6529 - val_loss: 1.0427 - val_acc: 0.7089\n",
      "Epoch 18/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.9715 - acc: 0.6365 - val_loss: 1.0318 - val_acc: 0.5555\n",
      "Epoch 19/50\n",
      "20029/20029 [==============================] - 1s 32us/step - loss: 0.9662 - acc: 0.6364 - val_loss: 1.0520 - val_acc: 0.7676\n",
      "Epoch 20/50\n",
      "20029/20029 [==============================] - 1s 32us/step - loss: 0.9604 - acc: 0.6660 - val_loss: 1.0323 - val_acc: 0.6056\n",
      "Epoch 21/50\n",
      "20029/20029 [==============================] - 1s 32us/step - loss: 0.9532 - acc: 0.6421 - val_loss: 1.0931 - val_acc: 0.5306\n",
      "X=[[1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [2. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], Predicted=[[0.2545924  0.13924304]\n",
      " [0.20683599 0.19608526]\n",
      " [0.87691087 0.8917318 ]]\n"
     ]
    }
   ],
   "source": [
    "numerical_case(Case3, 4,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case: ['사망자수', '사상자수', '중상자수']\n",
      "사상자제거: ['사망자수', '중상자수']\n",
      "[[0 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]]\n",
      "[[1 0]\n",
      " [1 2]\n",
      " [1 0]\n",
      " ...\n",
      " [1 0]\n",
      " [1 5]\n",
      " [1 0]]\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 1s 32us/step - loss: 0.6125 - acc: 0.9332 - val_loss: 0.5379 - val_acc: 0.9397\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 0.5393 - acc: 0.9438 - val_loss: 0.5133 - val_acc: 0.9335\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 26us/step - loss: 0.5302 - acc: 0.9377 - val_loss: 0.5148 - val_acc: 0.9325\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 0.5245 - acc: 0.9383 - val_loss: 0.5146 - val_acc: 0.9329\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 0.5203 - acc: 0.9375 - val_loss: 0.5130 - val_acc: 0.9327\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 0.5040 - acc: 0.9376 - val_loss: 0.5161 - val_acc: 0.9171\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 0.5045 - acc: 0.9353 - val_loss: 0.5177 - val_acc: 0.9131\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 0.5015 - acc: 0.9333 - val_loss: 0.5151 - val_acc: 0.9247\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.5177 - acc: 0.9349 - val_loss: 0.5124 - val_acc: 0.9361\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.4900 - acc: 0.9366 - val_loss: 0.5148 - val_acc: 0.9275\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.5041 - acc: 0.9350 - val_loss: 0.5065 - val_acc: 0.9303\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 0.4842 - acc: 0.9321 - val_loss: 0.5120 - val_acc: 0.9345\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 0.4971 - acc: 0.9371 - val_loss: 0.5099 - val_acc: 0.9303\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.4960 - acc: 0.9370 - val_loss: 0.5086 - val_acc: 0.9295\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 0.4846 - acc: 0.9333 - val_loss: 0.5155 - val_acc: 0.9277\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.4827 - acc: 0.9348 - val_loss: 0.5305 - val_acc: 0.9171\n",
      "X=[[ 5.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [21.  4.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]], Predicted=[[1.005893   2.2682867 ]\n",
      " [1.2160703  9.523235  ]\n",
      " [0.96326005 0.02378242]]\n"
     ]
    }
   ],
   "source": [
    "numerical_case(Case4, 7, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 4\n",
    "'사망자수', '사상자수', '중상자수' 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = x_train_num[['사망자수', '중상자수']].values\n",
    "X = x_train_num.drop(columns=['사망자수', '사상자수', '중상자수'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, x_train_cat], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x_test_num.drop(columns=['사망자수', '사상자수', '중상자수'])\n",
    "X_test = pd.concat([X_test, x_test_cat],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 330)\n",
      "(25037, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = Input(shape=(len(X[0]),), name='num_input')\n",
    "x = Dense(512, activation='relu')(num_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "num_output = Dense(len(Y[0]), name='num_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=num_input, outputs=num_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "callbacks = [\n",
    "    learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "                                        # approach to get optimal value by gradually decreasing learning_rate\n",
    "    EarlyStopping('val_loss', patience=5), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "                                                            # If val_loss deviates from the optimal value, \n",
    "                                                            # learning stops even if epoch remains.\n",
    "    ModelCheckpoint('model.h5', save_best_only=True)] # 모델을 학습시키면서 지금까지 등장했던 최적의 weight들을 항상 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 0.5790 - acc: 0.9280 - val_loss: 0.5130 - val_acc: 0.9065\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.4934 - acc: 0.9273 - val_loss: 0.5085 - val_acc: 0.9187\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 35us/step - loss: 0.4872 - acc: 0.9289 - val_loss: 0.5204 - val_acc: 0.9283\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 36us/step - loss: 0.5168 - acc: 0.9328 - val_loss: 0.4991 - val_acc: 0.9151\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 35us/step - loss: 0.4498 - acc: 0.9331 - val_loss: 0.4840 - val_acc: 0.9303\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.3782 - acc: 0.9378 - val_loss: 0.5003 - val_acc: 0.9189\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.3553 - acc: 0.9418 - val_loss: 0.4645 - val_acc: 0.9343\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.3346 - acc: 0.9441 - val_loss: 0.5200 - val_acc: 0.9349\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.3222 - acc: 0.9467 - val_loss: 0.5033 - val_acc: 0.9239\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.3161 - acc: 0.9458 - val_loss: 0.5386 - val_acc: 0.9317\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 36us/step - loss: 0.3272 - acc: 0.9478 - val_loss: 0.5328 - val_acc: 0.9345\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 35us/step - loss: 0.2817 - acc: 0.9477 - val_loss: 0.6662 - val_acc: 0.9203\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[[ 5.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [21.  4.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]], Predicted=[[ 1.1411047   0.6463091 ]\n",
      " [ 1.6231983  22.70345   ]\n",
      " [ 0.9697906   0.06846951]]\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "Y_test = model.predict(X_test[7:10])\n",
    "\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (X_test[7:10],  Y_test ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "Case5 = ['사고유형_대분류', '사고유형_중분류', '법규위반']\n",
    "Case6 = ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류']\n",
    "Case7 = ['도로형태_대분류', '도로형태', '당사자종별_2당_대분류']\n",
    "Case8 = ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류']\n",
    "Case11 = ['발생지시도', '발생지시군구']\n",
    "Case12 = ['요일', '사고유형_대분류', '사고유형_중분류']\n",
    "Case13 = ['요일', '사고유형_중분류', '법규위반', '도로형태_대분류']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_case(case, start, end):\n",
    "    col_name = [] # ex. '사고유형_대분류_차대차', '사고유형_대분류_차대사람', '사고유형_대분류_차량단독'\n",
    "    label_name = [] #  ex. '차대차', '차대사람', '차량단독\n",
    "    \n",
    "    for col in case:\n",
    "        label_name.extend(all_data[col].unique()) \n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)\n",
    "    \n",
    "    print('col_name:',col_name)\n",
    "    print('label_name:', label_name)\n",
    "                \n",
    "    Y = x_train_cat[col_name].values\n",
    "    X = x_train_cat.drop(columns=col_name)\n",
    "    X = pd.concat([X, x_train_num], axis=1).values\n",
    "\n",
    "    X_test = x_test_cat.drop(columns=col_name)\n",
    "    X_test = pd.concat([X_test, x_test_num],axis=1).values\n",
    "\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "\n",
    "    cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "    x = Dense(512, activation='relu')(cat_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    cat_output = Dense(len(Y[0]), activation='sigmoid', name='cat_output')(x)\n",
    "\n",
    "    model = Model(inputs=cat_input, outputs=cat_output)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                                patience=25, \n",
    "                                                verbose=1, \n",
    "                                                factor=0.5, \n",
    "                                                min_lr=0.00000001)\n",
    "\n",
    "    callbacks = [\n",
    "        learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "        EarlyStopping('val_loss', patience=10), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "        ]\n",
    "\n",
    "    history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )\n",
    "    \n",
    "    \n",
    "    # make a prediction\n",
    "    Y_test = model.predict(X_test[range(start, end+1)])\n",
    "    \n",
    "    # show the inputs and predicted outputs\n",
    "#     print(\"X=%s, Predicted=%s\" % (X_test[range(start, end+1)],  Y_test ))\n",
    "    \n",
    "            \n",
    "        \n",
    "    '''\n",
    "    예시 출력:\n",
    "        사고유형_대분류 : 차량단독\n",
    "        사고유형_중분류 : 공작물충돌\n",
    "        법규위반 : 안전운전 의무 불이행\n",
    "    '''\n",
    "    for val in Y_test: \n",
    "        x_list = list(val)\n",
    "        label_name_x = label_name.copy()\n",
    "        for col in case:\n",
    "            print(col, ':',label_name_x[x_list.index(max(x_list[0:len(all_data[col].unique())]))] )\n",
    "            del x_list[:len(all_data[col].unique())]\n",
    "            del label_name_x[:len(all_data[col].unique())]\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_name: ['사고유형_대분류_차대차', '사고유형_대분류_차대사람', '사고유형_대분류_차량단독', '사고유형_대분류_건널목', '사고유형_중분류_측면충돌', '사고유형_중분류_차도통행중', '사고유형_중분류_전도전복', '사고유형_중분류_정면충돌', '사고유형_중분류_추돌', '사고유형_중분류_횡단중', '사고유형_중분류_기타', '사고유형_중분류_전도', '사고유형_중분류_도로이탈', '사고유형_중분류_길가장자리구역통행중', '사고유형_중분류_공작물충돌', '사고유형_중분류_전복', '사고유형_중분류_보도통행중', '사고유형_중분류_후진중충돌', '사고유형_중분류_주/정차차량 충돌', '사고유형_중분류_측면직각충돌', '사고유형_중분류_차단기돌파', '사고유형_중분류_직전진행', '사고유형_중분류_경보기무시', '법규위반_중앙선 침범', '법규위반_과속', '법규위반_안전운전 의무 불이행', '법규위반_안전거리 미확보', '법규위반_기타(운전자법규위반)', '법규위반_신호위반', '법규위반_직진 및 우회전차의 통행방해', '법규위반_교차로 통행방법 위반', '법규위반_보행자 보호의무 위반', '법규위반_부당한 회전', '법규위반_차로위반(진로변경 위반)', '법규위반_앞지르기 금지위반', '법규위반_앞지르기 방법위반', '법규위반_정비불량 제차의 운전금지위반', '법규위반_서행 및 일시정지위반', '법규위반_과로', '법규위반_철길건널목 통과방법위반', '법규위반_진로양보 의무 불이행', '법규위반_보행자과실', '법규위반_통행우선 순위위반']\n",
      "label_name: ['차대차', '차대사람', '차량단독', '건널목', '측면충돌', '차도통행중', '전도전복', '정면충돌', '추돌', '횡단중', '기타', '전도', '도로이탈', '길가장자리구역통행중', '공작물충돌', '전복', '보도통행중', '후진중충돌', '주/정차차량 충돌', '측면직각충돌', '차단기돌파', '직전진행', '경보기무시', '중앙선 침범', '과속', '안전운전 의무 불이행', '안전거리 미확보', '기타(운전자법규위반)', '신호위반', '직진 및 우회전차의 통행방해', '교차로 통행방법 위반', '보행자 보호의무 위반', '부당한 회전', '차로위반(진로변경 위반)', '앞지르기 금지위반', '앞지르기 방법위반', '정비불량 제차의 운전금지위반', '서행 및 일시정지위반', '과로', '철길건널목 통과방법위반', '진로양보 의무 불이행', '보행자과실', '통행우선 순위위반']\n",
      "(25037, 290)\n",
      "(25037, 43)\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 1s 65us/step - loss: 0.1463 - acc: 0.9460 - val_loss: 0.0810 - val_acc: 0.9666\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 0.0864 - acc: 0.9650 - val_loss: 0.0786 - val_acc: 0.9683\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0818 - acc: 0.9666 - val_loss: 0.0765 - val_acc: 0.9686\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.0800 - acc: 0.9674 - val_loss: 0.0764 - val_acc: 0.9683\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.0784 - acc: 0.9679 - val_loss: 0.0762 - val_acc: 0.9685\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.0769 - acc: 0.9686 - val_loss: 0.0765 - val_acc: 0.9686\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0758 - acc: 0.9690 - val_loss: 0.0766 - val_acc: 0.9683\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0747 - acc: 0.9695 - val_loss: 0.0771 - val_acc: 0.9678\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0733 - acc: 0.9700 - val_loss: 0.0781 - val_acc: 0.9672\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0721 - acc: 0.9707 - val_loss: 0.0791 - val_acc: 0.9669\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0706 - acc: 0.9712 - val_loss: 0.0783 - val_acc: 0.9679\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0695 - acc: 0.9718 - val_loss: 0.0798 - val_acc: 0.9670\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0686 - acc: 0.9721 - val_loss: 0.0792 - val_acc: 0.9675\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.0672 - acc: 0.9729 - val_loss: 0.0802 - val_acc: 0.9669\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0663 - acc: 0.9732 - val_loss: 0.0818 - val_acc: 0.9667\n",
      "사고유형_대분류 : 차대차\n",
      "사고유형_중분류 : 측면직각충돌\n",
      "법규위반 : 신호위반\n",
      "\n",
      "사고유형_대분류 : 차량단독\n",
      "사고유형_중분류 : 공작물충돌\n",
      "법규위반 : 안전운전 의무 불이행\n",
      "\n",
      "사고유형_대분류 : 차대차\n",
      "사고유형_중분류 : 추돌\n",
      "법규위반 : 안전운전 의무 불이행\n",
      "\n",
      "사고유형_대분류 : 차대사람\n",
      "사고유형_중분류 : 기타\n",
      "법규위반 : 안전운전 의무 불이행\n",
      "\n",
      "사고유형_대분류 : 차대차\n",
      "사고유형_중분류 : 정면충돌\n",
      "법규위반 : 중앙선 침범\n",
      "\n",
      "사고유형_대분류 : 차대사람\n",
      "사고유형_중분류 : 횡단중\n",
      "법규위반 : 보행자 보호의무 위반\n",
      "\n",
      "사고유형_대분류 : 차대차\n",
      "사고유형_중분류 : 측면직각충돌\n",
      "법규위반 : 신호위반\n",
      "\n",
      "사고유형_대분류 : 차대사람\n",
      "사고유형_중분류 : 기타\n",
      "법규위반 : 안전운전 의무 불이행\n",
      "\n",
      "사고유형_대분류 : 차대차\n",
      "사고유형_중분류 : 추돌\n",
      "법규위반 : 안전운전 의무 불이행\n",
      "\n",
      "사고유형_대분류 : 차대사람\n",
      "사고유형_중분류 : 횡단중\n",
      "법규위반 : 안전운전 의무 불이행\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_case(Case5, 10,19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_name: ['도로형태_대분류_단일로', '도로형태_대분류_교차로', '도로형태_대분류_기타', '도로형태_대분류_주차장', '도로형태_대분류_불명', '도로형태_대분류_기타/불명', '도로형태_대분류_고가도로위', '도로형태_대분류_지하도로내', '도로형태_대분류_건널목', '도로형태_기타단일로', '도로형태_교차로내', '도로형태_교차로부근', '도로형태_교량위', '도로형태_고가도로위', '도로형태_교차로횡단보도내', '도로형태_기타', '도로형태_지하차도(도로)내', '도로형태_주차장', '도로형태_터널안', '도로형태_불명', '도로형태_횡단보도상', '도로형태_횡단보도부근', '도로형태_기타/불명', '도로형태_지하도로내', '도로형태_건널목', '당사자종별_1당_대분류_승용차', '당사자종별_1당_대분류_자전거', '당사자종별_1당_대분류_화물차', '당사자종별_1당_대분류_승합차', '당사자종별_1당_대분류_건설기계', '당사자종별_1당_대분류_이륜차', '당사자종별_1당_대분류_특수차', '당사자종별_1당_대분류_원동기장치자전거', '당사자종별_1당_대분류_사륜오토바이(ATV)', '당사자종별_1당_대분류_농기계', '당사자종별_1당_대분류_개인형이동수단(PM)', '당사자종별_1당_대분류_불명']\n",
      "label_name: ['단일로', '교차로', '기타', '주차장', '불명', '기타/불명', '고가도로위', '지하도로내', '건널목', '기타단일로', '교차로내', '교차로부근', '교량위', '고가도로위', '교차로횡단보도내', '기타', '지하차도(도로)내', '주차장', '터널안', '불명', '횡단보도상', '횡단보도부근', '기타/불명', '지하도로내', '건널목', '승용차', '자전거', '화물차', '승합차', '건설기계', '이륜차', '특수차', '원동기장치자전거', '사륜오토바이(ATV)', '농기계', '개인형이동수단(PM)', '불명']\n",
      "(25037, 296)\n",
      "(25037, 37)\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 1s 66us/step - loss: 0.1815 - acc: 0.9293 - val_loss: 0.1389 - val_acc: 0.9464\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.1415 - acc: 0.9446 - val_loss: 0.1342 - val_acc: 0.9472\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.1367 - acc: 0.9463 - val_loss: 0.1334 - val_acc: 0.9475\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.1339 - acc: 0.9472 - val_loss: 0.1334 - val_acc: 0.9475\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.1318 - acc: 0.9479 - val_loss: 0.1340 - val_acc: 0.9472\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.1293 - acc: 0.9487 - val_loss: 0.1344 - val_acc: 0.9475\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.1272 - acc: 0.9493 - val_loss: 0.1346 - val_acc: 0.9471\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.1249 - acc: 0.9501 - val_loss: 0.1381 - val_acc: 0.9457\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.1226 - acc: 0.9511 - val_loss: 0.1374 - val_acc: 0.9473\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.1202 - acc: 0.9518 - val_loss: 0.1393 - val_acc: 0.9459\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.1178 - acc: 0.9527 - val_loss: 0.1429 - val_acc: 0.9452\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.1156 - acc: 0.9534 - val_loss: 0.1420 - val_acc: 0.9452\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.1133 - acc: 0.9542 - val_loss: 0.1443 - val_acc: 0.9448\n",
      "X=[[ 1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  1. 11.  0.  0. 10.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  1. 13.  3.  9.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  1.  1.  0.  0.  0.]], Predicted=[[9.99845624e-01 4.30125692e-05 1.72703079e-08 2.58618908e-12\n",
      "  5.14512521e-12 2.86592167e-05 1.34805688e-07 4.80087081e-09\n",
      "  6.19091475e-13 9.98945296e-01 9.36328706e-06 4.28196381e-06\n",
      "  2.76523089e-04 2.16398760e-07 9.23788362e-14 1.97577990e-08\n",
      "  2.86803270e-09 2.55320019e-11 1.50746801e-05 9.98431546e-12\n",
      "  9.26246724e-09 3.22019275e-07 3.01649106e-05 5.77131720e-09\n",
      "  3.24653580e-13 7.56317079e-01 1.07970607e-07 9.48771983e-02\n",
      "  5.89684546e-02 3.87735308e-05 1.64852172e-05 9.77335803e-05\n",
      "  4.54098790e-06 8.55000570e-10 3.10063541e-07 1.18230651e-11\n",
      "  9.84749704e-07]\n",
      " [7.39010632e-01 1.67139634e-01 3.56210629e-03 1.91576299e-04\n",
      "  3.73311312e-04 4.83840071e-02 3.01540946e-03 1.51086589e-02\n",
      "  2.55606690e-04 6.11101568e-01 5.78196123e-02 1.21598303e-01\n",
      "  9.89528522e-02 6.35827240e-03 3.19867075e-04 2.79134489e-03\n",
      "  1.25531817e-03 1.33177778e-03 2.67165422e-01 2.12546598e-04\n",
      "  9.23925603e-04 6.61168108e-03 4.76908535e-02 2.51188111e-02\n",
      "  3.54460673e-04 2.89138108e-01 9.45704640e-04 3.11601132e-01\n",
      "  4.66897368e-01 2.86219753e-02 4.22223099e-03 1.87451076e-02\n",
      "  1.95910526e-03 2.85053655e-04 1.84535387e-03 5.13314153e-04\n",
      "  2.38406472e-03]\n",
      " [5.89733183e-01 2.82453001e-01 6.65648747e-03 9.64487379e-04\n",
      "  5.94896846e-04 1.36627004e-01 2.87320698e-03 4.35088621e-03\n",
      "  3.14212608e-04 5.47533393e-01 1.33240446e-01 1.51948079e-01\n",
      "  1.79428030e-02 2.66519445e-03 1.61706109e-03 5.83608914e-03\n",
      "  9.93662048e-04 6.43762934e-04 1.11099891e-02 5.54648810e-04\n",
      "  8.33878666e-03 5.97732607e-03 1.36693016e-01 3.62240337e-03\n",
      "  3.86431464e-04 2.11553648e-01 1.86686888e-02 4.13990229e-01\n",
      "  7.16737285e-02 1.01450935e-01 5.10519445e-02 2.80916896e-02\n",
      "  4.00679670e-02 3.69395455e-03 7.93607011e-02 4.82465344e-04\n",
      "  4.57284832e-03]]\n",
      "도로형태_대분류 : 단일로\n",
      "도로형태 : 기타단일로\n",
      "당사자종별_1당_대분류 : 승용차\n",
      "\n",
      "도로형태_대분류 : 단일로\n",
      "도로형태 : 기타단일로\n",
      "당사자종별_1당_대분류 : 승합차\n",
      "\n",
      "도로형태_대분류 : 단일로\n",
      "도로형태 : 기타단일로\n",
      "당사자종별_1당_대분류 : 화물차\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_case(Case6, 20, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_name: ['도로형태_대분류_단일로', '도로형태_대분류_교차로', '도로형태_대분류_기타', '도로형태_대분류_주차장', '도로형태_대분류_불명', '도로형태_대분류_기타/불명', '도로형태_대분류_고가도로위', '도로형태_대분류_지하도로내', '도로형태_대분류_건널목', '도로형태_기타단일로', '도로형태_교차로내', '도로형태_교차로부근', '도로형태_교량위', '도로형태_고가도로위', '도로형태_교차로횡단보도내', '도로형태_기타', '도로형태_지하차도(도로)내', '도로형태_주차장', '도로형태_터널안', '도로형태_불명', '도로형태_횡단보도상', '도로형태_횡단보도부근', '도로형태_기타/불명', '도로형태_지하도로내', '도로형태_건널목', '당사자종별_2당_대분류_승합차', '당사자종별_2당_대분류_보행자', '당사자종별_2당_대분류_없음', '당사자종별_2당_대분류_화물차', '당사자종별_2당_대분류_특수차', '당사자종별_2당_대분류_승용차', '당사자종별_2당_대분류_이륜차', '당사자종별_2당_대분류_농기계', '당사자종별_2당_대분류_원동기장치자전거', '당사자종별_2당_대분류_자전거', '당사자종별_2당_대분류_사륜오토바이(ATV)', '당사자종별_2당_대분류_건설기계', '당사자종별_2당_대분류_불명', '당사자종별_2당_대분류_열차']\n",
      "label_name: ['단일로', '교차로', '기타', '주차장', '불명', '기타/불명', '고가도로위', '지하도로내', '건널목', '기타단일로', '교차로내', '교차로부근', '교량위', '고가도로위', '교차로횡단보도내', '기타', '지하차도(도로)내', '주차장', '터널안', '불명', '횡단보도상', '횡단보도부근', '기타/불명', '지하도로내', '건널목', '승합차', '보행자', '없음', '화물차', '특수차', '승용차', '이륜차', '농기계', '원동기장치자전거', '자전거', '사륜오토바이(ATV)', '건설기계', '불명', '열차']\n",
      "(25037, 294)\n",
      "(25037, 39)\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 1s 68us/step - loss: 0.1550 - acc: 0.9412 - val_loss: 0.1048 - val_acc: 0.9612\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.1060 - acc: 0.9600 - val_loss: 0.0992 - val_acc: 0.9619\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.1017 - acc: 0.9611 - val_loss: 0.0991 - val_acc: 0.9615\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0990 - acc: 0.9618 - val_loss: 0.0985 - val_acc: 0.9622\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0970 - acc: 0.9625 - val_loss: 0.0989 - val_acc: 0.9621\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0953 - acc: 0.9629 - val_loss: 0.1017 - val_acc: 0.9601\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0932 - acc: 0.9636 - val_loss: 0.1017 - val_acc: 0.9605\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0912 - acc: 0.9642 - val_loss: 0.1003 - val_acc: 0.9618\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0886 - acc: 0.9649 - val_loss: 0.1040 - val_acc: 0.9601\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0875 - acc: 0.9653 - val_loss: 0.1022 - val_acc: 0.9610\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.0850 - acc: 0.9662 - val_loss: 0.1055 - val_acc: 0.9608\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 0.0825 - acc: 0.9672 - val_loss: 0.1070 - val_acc: 0.9594\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.0803 - acc: 0.9679 - val_loss: 0.1111 - val_acc: 0.9590\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0779 - acc: 0.9689 - val_loss: 0.1161 - val_acc: 0.9585\n",
      "도로형태_대분류 : 교차로\n",
      "도로형태 : 교차로내\n",
      "당사자종별_2당_대분류 : 승용차\n",
      "\n",
      "도로형태_대분류 : 단일로\n",
      "도로형태 : 기타단일로\n",
      "당사자종별_2당_대분류 : 없음\n",
      "\n",
      "도로형태_대분류 : 단일로\n",
      "도로형태 : 횡단보도상\n",
      "당사자종별_2당_대분류 : 보행자\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_case(Case7, 23, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_name: ['도로형태_대분류_단일로', '도로형태_대분류_교차로', '도로형태_대분류_기타', '도로형태_대분류_주차장', '도로형태_대분류_불명', '도로형태_대분류_기타/불명', '도로형태_대분류_고가도로위', '도로형태_대분류_지하도로내', '도로형태_대분류_건널목', '도로형태_기타단일로', '도로형태_교차로내', '도로형태_교차로부근', '도로형태_교량위', '도로형태_고가도로위', '도로형태_교차로횡단보도내', '도로형태_기타', '도로형태_지하차도(도로)내', '도로형태_주차장', '도로형태_터널안', '도로형태_불명', '도로형태_횡단보도상', '도로형태_횡단보도부근', '도로형태_기타/불명', '도로형태_지하도로내', '도로형태_건널목', '당사자종별_1당_대분류_승용차', '당사자종별_1당_대분류_자전거', '당사자종별_1당_대분류_화물차', '당사자종별_1당_대분류_승합차', '당사자종별_1당_대분류_건설기계', '당사자종별_1당_대분류_이륜차', '당사자종별_1당_대분류_특수차', '당사자종별_1당_대분류_원동기장치자전거', '당사자종별_1당_대분류_사륜오토바이(ATV)', '당사자종별_1당_대분류_농기계', '당사자종별_1당_대분류_개인형이동수단(PM)', '당사자종별_1당_대분류_불명', '당사자종별_2당_대분류_승합차', '당사자종별_2당_대분류_보행자', '당사자종별_2당_대분류_없음', '당사자종별_2당_대분류_화물차', '당사자종별_2당_대분류_특수차', '당사자종별_2당_대분류_승용차', '당사자종별_2당_대분류_이륜차', '당사자종별_2당_대분류_농기계', '당사자종별_2당_대분류_원동기장치자전거', '당사자종별_2당_대분류_자전거', '당사자종별_2당_대분류_사륜오토바이(ATV)', '당사자종별_2당_대분류_건설기계', '당사자종별_2당_대분류_불명', '당사자종별_2당_대분류_열차']\n",
      "label_name: ['단일로', '교차로', '기타', '주차장', '불명', '기타/불명', '고가도로위', '지하도로내', '건널목', '기타단일로', '교차로내', '교차로부근', '교량위', '고가도로위', '교차로횡단보도내', '기타', '지하차도(도로)내', '주차장', '터널안', '불명', '횡단보도상', '횡단보도부근', '기타/불명', '지하도로내', '건널목', '승용차', '자전거', '화물차', '승합차', '건설기계', '이륜차', '특수차', '원동기장치자전거', '사륜오토바이(ATV)', '농기계', '개인형이동수단(PM)', '불명', '승합차', '보행자', '없음', '화물차', '특수차', '승용차', '이륜차', '농기계', '원동기장치자전거', '자전거', '사륜오토바이(ATV)', '건설기계', '불명', '열차']\n",
      "(25037, 282)\n",
      "(25037, 51)\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 1s 72us/step - loss: 0.1778 - acc: 0.9328 - val_loss: 0.1235 - val_acc: 0.9524\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.1271 - acc: 0.9513 - val_loss: 0.1199 - val_acc: 0.9539\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.1227 - acc: 0.9527 - val_loss: 0.1191 - val_acc: 0.9540\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 0.1200 - acc: 0.9534 - val_loss: 0.1179 - val_acc: 0.9540\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.1181 - acc: 0.9540 - val_loss: 0.1177 - val_acc: 0.9542\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.1168 - acc: 0.9544 - val_loss: 0.1183 - val_acc: 0.9538\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.1150 - acc: 0.9548 - val_loss: 0.1184 - val_acc: 0.9536\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.1138 - acc: 0.9554 - val_loss: 0.1179 - val_acc: 0.9541\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.1123 - acc: 0.9560 - val_loss: 0.1198 - val_acc: 0.9532\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.1108 - acc: 0.9563 - val_loss: 0.1191 - val_acc: 0.9538\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 0.1096 - acc: 0.9568 - val_loss: 0.1202 - val_acc: 0.9536\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.1081 - acc: 0.9571 - val_loss: 0.1199 - val_acc: 0.9534\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.1066 - acc: 0.9576 - val_loss: 0.1216 - val_acc: 0.9537\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.1051 - acc: 0.9581 - val_loss: 0.1226 - val_acc: 0.9525\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.1040 - acc: 0.9587 - val_loss: 0.1246 - val_acc: 0.9529\n",
      "도로형태_대분류 : 단일로\n",
      "도로형태 : 기타단일로\n",
      "당사자종별_1당_대분류 : 승용차\n",
      "당사자종별_2당_대분류 : 승용차\n",
      "\n",
      "도로형태_대분류 : 단일로\n",
      "도로형태 : 기타단일로\n",
      "당사자종별_1당_대분류 : 승용차\n",
      "당사자종별_2당_대분류 : 승용차\n",
      "\n",
      "도로형태_대분류 : 단일로\n",
      "도로형태 : 기타단일로\n",
      "당사자종별_1당_대분류 : 승용차\n",
      "당사자종별_2당_대분류 : 없음\n",
      "\n",
      "도로형태_대분류 : 단일로\n",
      "도로형태 : 기타단일로\n",
      "당사자종별_1당_대분류 : 화물차\n",
      "당사자종별_2당_대분류 : 화물차\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_case(Case8, 26, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_name: ['발생지시도_경기', '발생지시도_전남', '발생지시도_대구', '발생지시도_경북', '발생지시도_충남', '발생지시도_강원', '발생지시도_충북', '발생지시도_서울', '발생지시도_광주', '발생지시도_부산', '발생지시도_경남', '발생지시도_인천', '발생지시도_세종', '발생지시도_전북', '발생지시도_대전', '발생지시도_울산', '발생지시도_제주', '발생지시군구_화성시', '발생지시군구_영암군', '발생지시군구_곡성군', '발생지시군구_달성군', '발생지시군구_고흥군', '발생지시군구_영천시', '발생지시군구_아산시', '발생지시군구_서천군', '발생지시군구_평창군', '발생지시군구_음성군', '발생지시군구_성남시', '발생지시군구_서산시', '발생지시군구_서구', '발생지시군구_영등포구', '발생지시군구_용인시', '발생지시군구_광양시', '발생지시군구_광산구', '발생지시군구_중구', '발생지시군구_원주시', '발생지시군구_고양시', '발생지시군구_논산시', '발생지시군구_동구', '발생지시군구_고성군', '발생지시군구_안산시', '발생지시군구_목포시', '발생지시군구_강서구', '발생지시군구_시흥시', '발생지시군구_이천시', '발생지시군구_사상구', '발생지시군구_광진구', '발생지시군구_서대문구', '발생지시군구_양평군', '발생지시군구_남양주시', '발생지시군구_동작구', '발생지시군구_기장군', '발생지시군구_예산군', '발생지시군구_남구', '발생지시군구_여수시', '발생지시군구_제천시', '발생지시군구_세종', '발생지시군구_춘천시', '발생지시군구_의성군', '발생지시군구_충주시', '발생지시군구_서초구', '발생지시군구_금산군', '발생지시군구_밀양시', '발생지시군구_김천시', '발생지시군구_군산시', '발생지시군구_대덕구', '발생지시군구_파주시', '발생지시군구_진주시', '발생지시군구_김해시', '발생지시군구_북구', '발생지시군구_나주시', '발생지시군구_고창군', '발생지시군구_합천군', '발생지시군구_무주군', '발생지시군구_계양구', '발생지시군구_함양군', '발생지시군구_안동시', '발생지시군구_인제군', '발생지시군구_사하구', '발생지시군구_철원군', '발생지시군구_강동구', '발생지시군구_홍성군', '발생지시군구_안양시', '발생지시군구_정선군', '발생지시군구_용산구', '발생지시군구_구미시', '발생지시군구_부산진구', '발생지시군구_광명시', '발생지시군구_송파구', '발생지시군구_평택시', '발생지시군구_남원시', '발생지시군구_함안군', '발생지시군구_서귀포시', '발생지시군구_경산시', '발생지시군구_정읍시', '발생지시군구_청주시', '발생지시군구_상주시', '발생지시군구_삼척시', '발생지시군구_강릉시', '발생지시군구_양산시', '발생지시군구_제주시', '발생지시군구_달서구', '발생지시군구_영덕군', '발생지시군구_여주시', '발생지시군구_장성군', '발생지시군구_전주시', '발생지시군구_청도군', '발생지시군구_포항시', '발생지시군구_마포구', '발생지시군구_영광군', '발생지시군구_영주시', '발생지시군구_도봉구', '발생지시군구_당진시', '발생지시군구_부천시', '발생지시군구_수성구', '발생지시군구_봉화군', '발생지시군구_익산시', '발생지시군구_구로구', '발생지시군구_유성구', '발생지시군구_금천구', '발생지시군구_천안시', '발생지시군구_진도군', '발생지시군구_가평군', '발생지시군구_강화군', '발생지시군구_거창군', '발생지시군구_군위군', '발생지시군구_부평구', '발생지시군구_양주시', '발생지시군구_사천시', '발생지시군구_의정부시', '발생지시군구_영동군', '발생지시군구_광주시', '발생지시군구_창원시(통합)', '발생지시군구_울주군', '발생지시군구_진천군', '발생지시군구_김포시', '발생지시군구_동래구', '발생지시군구_강남구', '발생지시군구_보령시', '발생지시군구_강진군', '발생지시군구_보성군', '발생지시군구_화순군', '발생지시군구_순천시', '발생지시군구_보은군', '발생지시군구_양양군', '발생지시군구_군포시', '발생지시군구_청송군', '발생지시군구_통영시', '발생지시군구_수원시', '발생지시군구_경주시', '발생지시군구_하남시', '발생지시군구_완주군', '발생지시군구_양천구', '발생지시군구_함평군', '발생지시군구_의령군', '발생지시군구_공주시', '발생지시군구_성북구', '발생지시군구_부안군', '발생지시군구_예천군', '발생지시군구_안성시', '발생지시군구_중랑구', '발생지시군구_칠곡군', '발생지시군구_영월군', '발생지시군구_수영구', '발생지시군구_순창군', '발생지시군구_거제시', '발생지시군구_성주군', '발생지시군구_장수군', '발생지시군구_문경시', '발생지시군구_은평구', '발생지시군구_포천시', '발생지시군구_울진군', '발생지시군구_무안군', '발생지시군구_해남군', '발생지시군구_담양군', '발생지시군구_양구군', '발생지시군구_연천군', '발생지시군구_횡성군', '발생지시군구_장흥군', '발생지시군구_태백시', '발생지시군구_홍천군', '발생지시군구_하동군', '발생지시군구_남동구', '발생지시군구_의왕시', '발생지시군구_속초시', '발생지시군구_부여군', '발생지시군구_성동구', '발생지시군구_김제시', '발생지시군구_강북구', '발생지시군구_청양군', '발생지시군구_신안군', '발생지시군구_해운대구', '발생지시군구_종로구', '발생지시군구_동두천시', '발생지시군구_연제구', '발생지시군구_진안군', '발생지시군구_임실군', '발생지시군구_노원구', '발생지시군구_증평군', '발생지시군구_단양군', '발생지시군구_태안군', '발생지시군구_고령군', '발생지시군구_동해시', '발생지시군구_연수구', '발생지시군구_관악구', '발생지시군구_옥천군', '발생지시군구_동대문구', '발생지시군구_영양군', '발생지시군구_오산시', '발생지시군구_금정구', '발생지시군구_구례군', '발생지시군구_괴산군', '발생지시군구_계룡시', '발생지시군구_완도군', '발생지시군구_창녕군', '발생지시군구_화천군', '발생지시군구_남해군', '발생지시군구_구리시', '발생지시군구_산청군', '발생지시군구_옹진군', '발생지시군구_과천시', '발생지시군구_울릉군', '발생지시군구_영도구', '발생지시군구_청원군', '발생지시군구_연기군']\n",
      "label_name: ['경기', '전남', '대구', '경북', '충남', '강원', '충북', '서울', '광주', '부산', '경남', '인천', '세종', '전북', '대전', '울산', '제주', '화성시', '영암군', '곡성군', '달성군', '고흥군', '영천시', '아산시', '서천군', '평창군', '음성군', '성남시', '서산시', '서구', '영등포구', '용인시', '광양시', '광산구', '중구', '원주시', '고양시', '논산시', '동구', '고성군', '안산시', '목포시', '강서구', '시흥시', '이천시', '사상구', '광진구', '서대문구', '양평군', '남양주시', '동작구', '기장군', '예산군', '남구', '여수시', '제천시', '세종', '춘천시', '의성군', '충주시', '서초구', '금산군', '밀양시', '김천시', '군산시', '대덕구', '파주시', '진주시', '김해시', '북구', '나주시', '고창군', '합천군', '무주군', '계양구', '함양군', '안동시', '인제군', '사하구', '철원군', '강동구', '홍성군', '안양시', '정선군', '용산구', '구미시', '부산진구', '광명시', '송파구', '평택시', '남원시', '함안군', '서귀포시', '경산시', '정읍시', '청주시', '상주시', '삼척시', '강릉시', '양산시', '제주시', '달서구', '영덕군', '여주시', '장성군', '전주시', '청도군', '포항시', '마포구', '영광군', '영주시', '도봉구', '당진시', '부천시', '수성구', '봉화군', '익산시', '구로구', '유성구', '금천구', '천안시', '진도군', '가평군', '강화군', '거창군', '군위군', '부평구', '양주시', '사천시', '의정부시', '영동군', '광주시', '창원시(통합)', '울주군', '진천군', '김포시', '동래구', '강남구', '보령시', '강진군', '보성군', '화순군', '순천시', '보은군', '양양군', '군포시', '청송군', '통영시', '수원시', '경주시', '하남시', '완주군', '양천구', '함평군', '의령군', '공주시', '성북구', '부안군', '예천군', '안성시', '중랑구', '칠곡군', '영월군', '수영구', '순창군', '거제시', '성주군', '장수군', '문경시', '은평구', '포천시', '울진군', '무안군', '해남군', '담양군', '양구군', '연천군', '횡성군', '장흥군', '태백시', '홍천군', '하동군', '남동구', '의왕시', '속초시', '부여군', '성동구', '김제시', '강북구', '청양군', '신안군', '해운대구', '종로구', '동두천시', '연제구', '진안군', '임실군', '노원구', '증평군', '단양군', '태안군', '고령군', '동해시', '연수구', '관악구', '옥천군', '동대문구', '영양군', '오산시', '금정구', '구례군', '괴산군', '계룡시', '완도군', '창녕군', '화천군', '남해군', '구리시', '산청군', '옹진군', '과천시', '울릉군', '영도구', '청원군', '연기군']\n",
      "(25037, 108)\n",
      "(25037, 225)\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 2s 80us/step - loss: 0.0813 - acc: 0.9769 - val_loss: 0.0432 - val_acc: 0.9911\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0456 - acc: 0.9911 - val_loss: 0.0432 - val_acc: 0.9911\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.0447 - acc: 0.9911 - val_loss: 0.0431 - val_acc: 0.9911\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0441 - acc: 0.9911 - val_loss: 0.0431 - val_acc: 0.9911\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.0437 - acc: 0.9911 - val_loss: 0.0428 - val_acc: 0.9911\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 0.0433 - acc: 0.9911 - val_loss: 0.0426 - val_acc: 0.9911\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0431 - acc: 0.9911 - val_loss: 0.0426 - val_acc: 0.9911\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0429 - acc: 0.9911 - val_loss: 0.0423 - val_acc: 0.9911\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 0.0428 - acc: 0.9911 - val_loss: 0.0422 - val_acc: 0.9911\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0426 - acc: 0.9911 - val_loss: 0.0422 - val_acc: 0.9911\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 0.0425 - acc: 0.9911 - val_loss: 0.0423 - val_acc: 0.9911\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 0.0424 - acc: 0.9911 - val_loss: 0.0422 - val_acc: 0.9911\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0423 - acc: 0.9911 - val_loss: 0.0423 - val_acc: 0.9911\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0422 - acc: 0.9911 - val_loss: 0.0423 - val_acc: 0.9911\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0421 - acc: 0.9911 - val_loss: 0.0423 - val_acc: 0.9911\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0420 - acc: 0.9911 - val_loss: 0.0423 - val_acc: 0.9911\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0419 - acc: 0.9911 - val_loss: 0.0424 - val_acc: 0.9911\n",
      "Epoch 18/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0418 - acc: 0.9911 - val_loss: 0.0423 - val_acc: 0.9911\n",
      "Epoch 19/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0416 - acc: 0.9911 - val_loss: 0.0424 - val_acc: 0.9911\n",
      "Epoch 20/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0415 - acc: 0.9911 - val_loss: 0.0425 - val_acc: 0.9911\n",
      "Epoch 21/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 0.0414 - acc: 0.9911 - val_loss: 0.0425 - val_acc: 0.9911\n",
      "Epoch 22/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.0412 - acc: 0.9911 - val_loss: 0.0426 - val_acc: 0.9911\n",
      "발생지시도 : 경기\n",
      "발생지시군구 : 창원시(통합)\n",
      "\n",
      "발생지시도 : 경기\n",
      "발생지시군구 : 제주시\n",
      "\n",
      "발생지시도 : 경기\n",
      "발생지시군구 : 평택시\n",
      "\n",
      "발생지시도 : 경기\n",
      "발생지시군구 : 평택시\n",
      "\n",
      "발생지시도 : 경기\n",
      "발생지시군구 : 서구\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_case(Case11, 35, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_name: ['요일_금', '요일_월', '요일_일', '요일_목', '요일_수', '요일_화', '요일_토', '사고유형_대분류_차대차', '사고유형_대분류_차대사람', '사고유형_대분류_차량단독', '사고유형_대분류_건널목', '사고유형_중분류_측면충돌', '사고유형_중분류_차도통행중', '사고유형_중분류_전도전복', '사고유형_중분류_정면충돌', '사고유형_중분류_추돌', '사고유형_중분류_횡단중', '사고유형_중분류_기타', '사고유형_중분류_전도', '사고유형_중분류_도로이탈', '사고유형_중분류_길가장자리구역통행중', '사고유형_중분류_공작물충돌', '사고유형_중분류_전복', '사고유형_중분류_보도통행중', '사고유형_중분류_후진중충돌', '사고유형_중분류_주/정차차량 충돌', '사고유형_중분류_측면직각충돌', '사고유형_중분류_차단기돌파', '사고유형_중분류_직전진행', '사고유형_중분류_경보기무시']\n",
      "label_name: ['금', '월', '일', '목', '수', '화', '토', '차대차', '차대사람', '차량단독', '건널목', '측면충돌', '차도통행중', '전도전복', '정면충돌', '추돌', '횡단중', '기타', '전도', '도로이탈', '길가장자리구역통행중', '공작물충돌', '전복', '보도통행중', '후진중충돌', '주/정차차량 충돌', '측면직각충돌', '차단기돌파', '직전진행', '경보기무시']\n",
      "(25037, 303)\n",
      "(25037, 30)\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 2s 77us/step - loss: 0.2244 - acc: 0.9172 - val_loss: 0.1637 - val_acc: 0.9362\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.1696 - acc: 0.9363 - val_loss: 0.1604 - val_acc: 0.9384\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.1647 - acc: 0.9375 - val_loss: 0.1597 - val_acc: 0.9387\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.1624 - acc: 0.9383 - val_loss: 0.1589 - val_acc: 0.9390\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.1606 - acc: 0.9388 - val_loss: 0.1601 - val_acc: 0.9379\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.1595 - acc: 0.9393 - val_loss: 0.1595 - val_acc: 0.9381\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 0.1580 - acc: 0.9398 - val_loss: 0.1595 - val_acc: 0.9380\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.1566 - acc: 0.9405 - val_loss: 0.1601 - val_acc: 0.9377\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.1556 - acc: 0.9409 - val_loss: 0.1600 - val_acc: 0.9382\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.1539 - acc: 0.9415 - val_loss: 0.1602 - val_acc: 0.9379\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.1526 - acc: 0.9422 - val_loss: 0.1612 - val_acc: 0.9374\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.1512 - acc: 0.9429 - val_loss: 0.1620 - val_acc: 0.9375\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.1498 - acc: 0.9434 - val_loss: 0.1634 - val_acc: 0.9371\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.1485 - acc: 0.9440 - val_loss: 0.1641 - val_acc: 0.9365\n",
      "요일 : 금\n",
      "사고유형_대분류 : 차대차\n",
      "사고유형_중분류 : 측면직각충돌\n",
      "\n",
      "요일 : 일\n",
      "사고유형_대분류 : 차대차\n",
      "사고유형_중분류 : 추돌\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_case(Case12, 40, 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_name: ['요일_금', '요일_월', '요일_일', '요일_목', '요일_수', '요일_화', '요일_토', '사고유형_중분류_측면충돌', '사고유형_중분류_차도통행중', '사고유형_중분류_전도전복', '사고유형_중분류_정면충돌', '사고유형_중분류_추돌', '사고유형_중분류_횡단중', '사고유형_중분류_기타', '사고유형_중분류_전도', '사고유형_중분류_도로이탈', '사고유형_중분류_길가장자리구역통행중', '사고유형_중분류_공작물충돌', '사고유형_중분류_전복', '사고유형_중분류_보도통행중', '사고유형_중분류_후진중충돌', '사고유형_중분류_주/정차차량 충돌', '사고유형_중분류_측면직각충돌', '사고유형_중분류_차단기돌파', '사고유형_중분류_직전진행', '사고유형_중분류_경보기무시', '법규위반_중앙선 침범', '법규위반_과속', '법규위반_안전운전 의무 불이행', '법규위반_안전거리 미확보', '법규위반_기타(운전자법규위반)', '법규위반_신호위반', '법규위반_직진 및 우회전차의 통행방해', '법규위반_교차로 통행방법 위반', '법규위반_보행자 보호의무 위반', '법규위반_부당한 회전', '법규위반_차로위반(진로변경 위반)', '법규위반_앞지르기 금지위반', '법규위반_앞지르기 방법위반', '법규위반_정비불량 제차의 운전금지위반', '법규위반_서행 및 일시정지위반', '법규위반_과로', '법규위반_철길건널목 통과방법위반', '법규위반_진로양보 의무 불이행', '법규위반_보행자과실', '법규위반_통행우선 순위위반', '도로형태_대분류_단일로', '도로형태_대분류_교차로', '도로형태_대분류_기타', '도로형태_대분류_주차장', '도로형태_대분류_불명', '도로형태_대분류_기타/불명', '도로형태_대분류_고가도로위', '도로형태_대분류_지하도로내', '도로형태_대분류_건널목']\n",
      "label_name: ['금', '월', '일', '목', '수', '화', '토', '측면충돌', '차도통행중', '전도전복', '정면충돌', '추돌', '횡단중', '기타', '전도', '도로이탈', '길가장자리구역통행중', '공작물충돌', '전복', '보도통행중', '후진중충돌', '주/정차차량 충돌', '측면직각충돌', '차단기돌파', '직전진행', '경보기무시', '중앙선 침범', '과속', '안전운전 의무 불이행', '안전거리 미확보', '기타(운전자법규위반)', '신호위반', '직진 및 우회전차의 통행방해', '교차로 통행방법 위반', '보행자 보호의무 위반', '부당한 회전', '차로위반(진로변경 위반)', '앞지르기 금지위반', '앞지르기 방법위반', '정비불량 제차의 운전금지위반', '서행 및 일시정지위반', '과로', '철길건널목 통과방법위반', '진로양보 의무 불이행', '보행자과실', '통행우선 순위위반', '단일로', '교차로', '기타', '주차장', '불명', '기타/불명', '고가도로위', '지하도로내', '건널목']\n",
      "(25037, 278)\n",
      "(25037, 55)\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 2s 88us/step - loss: 0.1762 - acc: 0.9364 - val_loss: 0.1200 - val_acc: 0.9551\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.1252 - acc: 0.9539 - val_loss: 0.1150 - val_acc: 0.9570\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.1199 - acc: 0.9551 - val_loss: 0.1131 - val_acc: 0.9571\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 0.1171 - acc: 0.9559 - val_loss: 0.1125 - val_acc: 0.9570\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.1159 - acc: 0.9562 - val_loss: 0.1123 - val_acc: 0.9572\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 0.1145 - acc: 0.9568 - val_loss: 0.1125 - val_acc: 0.9569\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 0.1135 - acc: 0.9573 - val_loss: 0.1126 - val_acc: 0.9566\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.1126 - acc: 0.9574 - val_loss: 0.1122 - val_acc: 0.9569\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.1114 - acc: 0.9578 - val_loss: 0.1119 - val_acc: 0.9570\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.1105 - acc: 0.9583 - val_loss: 0.1123 - val_acc: 0.9568\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.1100 - acc: 0.9584 - val_loss: 0.1121 - val_acc: 0.9571\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.1089 - acc: 0.9590 - val_loss: 0.1129 - val_acc: 0.9565\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 0.1082 - acc: 0.9591 - val_loss: 0.1131 - val_acc: 0.9567\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 46us/step - loss: 0.1073 - acc: 0.9595 - val_loss: 0.1130 - val_acc: 0.9569\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 0.1064 - acc: 0.9599 - val_loss: 0.1139 - val_acc: 0.9561\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.1057 - acc: 0.9603 - val_loss: 0.1142 - val_acc: 0.9563\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 1s 46us/step - loss: 0.1047 - acc: 0.9607 - val_loss: 0.1148 - val_acc: 0.9559\n",
      "Epoch 18/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.1043 - acc: 0.9607 - val_loss: 0.1150 - val_acc: 0.9562\n",
      "Epoch 19/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.1035 - acc: 0.9611 - val_loss: 0.1156 - val_acc: 0.9563\n",
      "요일 : 수\n",
      "사고유형_중분류 : 측면직각충돌\n",
      "법규위반 : 신호위반\n",
      "도로형태_대분류 : 교차로\n",
      "\n",
      "요일 : 월\n",
      "사고유형_중분류 : 공작물충돌\n",
      "법규위반 : 안전운전 의무 불이행\n",
      "도로형태_대분류 : 단일로\n",
      "\n",
      "요일 : 일\n",
      "사고유형_중분류 : 횡단중\n",
      "법규위반 : 안전운전 의무 불이행\n",
      "도로형태_대분류 : 단일로\n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_case(Case13, 42, 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "Case9 = ['사망자수', '사상자수', '발생지시군구']\n",
    "Case10 = ['중상자수', '경상자수', '발생지시군구']\n",
    "Case11 = ['사망자수', '사상자수', '주야', '당사자종별_1당_대분류']\n",
    "Case12 = ['사상자수', '중상자수', '주야', '도로형태']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_case(case, n, start, end):\n",
    "    '''\n",
    "    case: Case에 해당되는 컬럼이 담긴 배열\n",
    "    n: 범주형 데이터 수\n",
    "    start: 해당 Case 테스트의 시작 인덱스\n",
    "    end: 해당 Case 테스트의 마지막 인덱스\n",
    "    '''\n",
    "    \n",
    "    case_copy=case.copy()\n",
    "    \n",
    "    # categorical\n",
    "    col_name = []\n",
    "    label_name = []\n",
    "    cat_name = case_copy[-n:]\n",
    "    \n",
    "    for col in case_copy[-n:]:\n",
    "        label_name.extend(all_data[col].unique()) \n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)\n",
    "    \n",
    "    Y_cat = x_train_cat[col_name].values\n",
    "    X1 = x_train_cat.drop(columns=col_name)\n",
    "    X_test1 = x_test_cat.drop(columns=col_name)\n",
    "    \n",
    "    # categorical columns 삭제\n",
    "    del case_copy[-n:]\n",
    "    \n",
    "    # numerical\n",
    "    X2 = x_train_num.drop(columns=case_copy)\n",
    "    X_test2 = x_test_num.drop(columns=case_copy)\n",
    "    if '사상자수' in case: \n",
    "        case_copy.remove('사상자수')\n",
    "    Y_num = x_train_num[case_copy].values\n",
    "    \n",
    "    X = pd.concat([X1, X2], axis=1).values\n",
    "    X_test = pd.concat([X_test1, X_test2],axis=1).values\n",
    "    print(Y_num.shape)\n",
    "    print(len(Y_num[0]))\n",
    "    \n",
    "    cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "    x = Dense(512, activation='relu')(cat_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    cat_output = Dense(len(Y_cat[0]), activation='softmax', name='cat_output')(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    num_output = Dense(len(Y_num[0]), name='num_output')(x)\n",
    "\n",
    "    model = Model(inputs=cat_input, outputs=[cat_output, num_output])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'cat_output': 'categorical_crossentropy', 'num_output': 'mse'},\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "    callbacks = [\n",
    "        learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "        EarlyStopping('val_loss', patience=20), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "    ]\n",
    "\n",
    "    history = model.fit(X, {'cat_output':Y_cat, 'num_output':Y_num}, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )\n",
    "    \n",
    "    \n",
    "    # make a prediction\n",
    "    Y_test = model.predict(X_test[start:end+1])\n",
    "    \n",
    "    # show the inputs and predicted outputs\n",
    "    print(\"X=%s, Predicted=%s\" % (X_test[start:end+1],  Y_test ))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for val in Y_test[0]:\n",
    "        x_list = list(val)\n",
    "        label_name_x = label_name.copy()\n",
    "        for col in cat_name:\n",
    "            print(col, ':', label_name_x[x_list.index(max(x_list[0:len(all_data[col].unique())]))] )\n",
    "            # 출력한 Column과 데이터 삭제\n",
    "            del x_list[:len(all_data[col].unique())]\n",
    "            del label_name_x[:len(all_data[col].unique())]\n",
    "        print()\n",
    "        \n",
    "    for num in Y_test[1]:\n",
    "        print(case_copy, ':', num)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 3s 129us/step - loss: 4.9586 - cat_output_loss: 4.8305 - num_output_loss: 0.1281 - cat_output_acc: 0.0414 - num_output_acc: 0.9312 - val_loss: 3.5859 - val_cat_output_loss: 3.4181 - val_num_output_loss: 0.1677 - val_cat_output_acc: 0.1122 - val_num_output_acc: 0.9587\n",
      "Epoch 2/50\n",
      " 3200/20029 [===>..........................] - ETA: 0s - loss: 3.5342 - cat_output_loss: 3.4233 - num_output_loss: 0.1109 - cat_output_acc: 0.1100 - num_output_acc: 0.9347"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:1043: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_num_output_acc,val_cat_output_loss,val_num_output_loss,lr,val_cat_output_acc,num_output_acc,num_output_loss,val_loss,loss,cat_output_loss,cat_output_acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20029/20029 [==============================] - 1s 56us/step - loss: 3.1700 - cat_output_loss: 3.0627 - num_output_loss: 0.1073 - cat_output_acc: 0.1259 - num_output_acc: 0.9481 - val_loss: 2.8688 - val_cat_output_loss: 2.7778 - val_num_output_loss: 0.0911 - val_cat_output_acc: 0.1430 - val_num_output_acc: 0.9629\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 56us/step - loss: 2.9094 - cat_output_loss: 2.8151 - num_output_loss: 0.0943 - cat_output_acc: 0.1469 - num_output_acc: 0.9593 - val_loss: 2.8215 - val_cat_output_loss: 2.7300 - val_num_output_loss: 0.0915 - val_cat_output_acc: 0.1544 - val_num_output_acc: 0.9631\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 61us/step - loss: 2.8485 - cat_output_loss: 2.7612 - num_output_loss: 0.0874 - cat_output_acc: 0.1508 - num_output_acc: 0.9623 - val_loss: 2.8139 - val_cat_output_loss: 2.7157 - val_num_output_loss: 0.0982 - val_cat_output_acc: 0.1488 - val_num_output_acc: 0.9629\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 63us/step - loss: 2.8082 - cat_output_loss: 2.7242 - num_output_loss: 0.0840 - cat_output_acc: 0.1586 - num_output_acc: 0.9632 - val_loss: 2.7824 - val_cat_output_loss: 2.7013 - val_num_output_loss: 0.0811 - val_cat_output_acc: 0.1556 - val_num_output_acc: 0.9629\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 62us/step - loss: 2.7865 - cat_output_loss: 2.7069 - num_output_loss: 0.0796 - cat_output_acc: 0.1621 - num_output_acc: 0.9653 - val_loss: 2.7687 - val_cat_output_loss: 2.6973 - val_num_output_loss: 0.0714 - val_cat_output_acc: 0.1538 - val_num_output_acc: 0.9629\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 60us/step - loss: 2.7610 - cat_output_loss: 2.6851 - num_output_loss: 0.0759 - cat_output_acc: 0.1625 - num_output_acc: 0.9658 - val_loss: 2.7637 - val_cat_output_loss: 2.6965 - val_num_output_loss: 0.0672 - val_cat_output_acc: 0.1534 - val_num_output_acc: 0.9629\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 59us/step - loss: 2.7379 - cat_output_loss: 2.6648 - num_output_loss: 0.0732 - cat_output_acc: 0.1664 - num_output_acc: 0.9658 - val_loss: 2.7702 - val_cat_output_loss: 2.7000 - val_num_output_loss: 0.0702 - val_cat_output_acc: 0.1524 - val_num_output_acc: 0.9629\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 59us/step - loss: 2.7193 - cat_output_loss: 2.6471 - num_output_loss: 0.0722 - cat_output_acc: 0.1765 - num_output_acc: 0.9665 - val_loss: 2.7626 - val_cat_output_loss: 2.6960 - val_num_output_loss: 0.0667 - val_cat_output_acc: 0.1524 - val_num_output_acc: 0.9629\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 59us/step - loss: 2.7034 - cat_output_loss: 2.6328 - num_output_loss: 0.0705 - cat_output_acc: 0.1738 - num_output_acc: 0.9668 - val_loss: 2.7674 - val_cat_output_loss: 2.6966 - val_num_output_loss: 0.0708 - val_cat_output_acc: 0.1548 - val_num_output_acc: 0.9629\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 59us/step - loss: 2.6863 - cat_output_loss: 2.6165 - num_output_loss: 0.0699 - cat_output_acc: 0.1810 - num_output_acc: 0.9672 - val_loss: 2.7537 - val_cat_output_loss: 2.6903 - val_num_output_loss: 0.0634 - val_cat_output_acc: 0.1579 - val_num_output_acc: 0.9629\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 60us/step - loss: 2.6692 - cat_output_loss: 2.6007 - num_output_loss: 0.0685 - cat_output_acc: 0.1874 - num_output_acc: 0.9671 - val_loss: 2.7539 - val_cat_output_loss: 2.6920 - val_num_output_loss: 0.0619 - val_cat_output_acc: 0.1597 - val_num_output_acc: 0.9629\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 59us/step - loss: 2.6431 - cat_output_loss: 2.5760 - num_output_loss: 0.0670 - cat_output_acc: 0.1897 - num_output_acc: 0.9670 - val_loss: 2.7744 - val_cat_output_loss: 2.7072 - val_num_output_loss: 0.0672 - val_cat_output_acc: 0.1605 - val_num_output_acc: 0.9629\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 59us/step - loss: 2.6283 - cat_output_loss: 2.5605 - num_output_loss: 0.0678 - cat_output_acc: 0.2021 - num_output_acc: 0.9673 - val_loss: 2.7715 - val_cat_output_loss: 2.7052 - val_num_output_loss: 0.0662 - val_cat_output_acc: 0.1601 - val_num_output_acc: 0.9629\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 1s 61us/step - loss: 2.6153 - cat_output_loss: 2.5490 - num_output_loss: 0.0663 - cat_output_acc: 0.2014 - num_output_acc: 0.9673 - val_loss: 2.7859 - val_cat_output_loss: 2.7214 - val_num_output_loss: 0.0645 - val_cat_output_acc: 0.1560 - val_num_output_acc: 0.9629\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 1s 64us/step - loss: 2.5957 - cat_output_loss: 2.5305 - num_output_loss: 0.0652 - cat_output_acc: 0.2069 - num_output_acc: 0.9674 - val_loss: 2.7799 - val_cat_output_loss: 2.7188 - val_num_output_loss: 0.0611 - val_cat_output_acc: 0.1492 - val_num_output_acc: 0.9625\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 1s 61us/step - loss: 2.5733 - cat_output_loss: 2.5081 - num_output_loss: 0.0652 - cat_output_acc: 0.2172 - num_output_acc: 0.9670 - val_loss: 2.7867 - val_cat_output_loss: 2.7225 - val_num_output_loss: 0.0642 - val_cat_output_acc: 0.1528 - val_num_output_acc: 0.9627\n",
      "Epoch 18/50\n",
      "20029/20029 [==============================] - 1s 59us/step - loss: 2.5582 - cat_output_loss: 2.4930 - num_output_loss: 0.0652 - cat_output_acc: 0.2156 - num_output_acc: 0.9671 - val_loss: 2.8042 - val_cat_output_loss: 2.7394 - val_num_output_loss: 0.0648 - val_cat_output_acc: 0.1569 - val_num_output_acc: 0.9629\n",
      "Epoch 19/50\n",
      "20029/20029 [==============================] - 1s 59us/step - loss: 2.5360 - cat_output_loss: 2.4716 - num_output_loss: 0.0644 - cat_output_acc: 0.2265 - num_output_acc: 0.9674 - val_loss: 2.8058 - val_cat_output_loss: 2.7422 - val_num_output_loss: 0.0636 - val_cat_output_acc: 0.1536 - val_num_output_acc: 0.9627\n",
      "Epoch 20/50\n",
      "20029/20029 [==============================] - 1s 63us/step - loss: 2.5182 - cat_output_loss: 2.4535 - num_output_loss: 0.0647 - cat_output_acc: 0.2281 - num_output_acc: 0.9672 - val_loss: 2.8100 - val_cat_output_loss: 2.7477 - val_num_output_loss: 0.0623 - val_cat_output_acc: 0.1510 - val_num_output_acc: 0.9629\n",
      "Epoch 21/50\n",
      "20029/20029 [==============================] - 1s 59us/step - loss: 2.4945 - cat_output_loss: 2.4307 - num_output_loss: 0.0638 - cat_output_acc: 0.2354 - num_output_acc: 0.9673 - val_loss: 2.8216 - val_cat_output_loss: 2.7599 - val_num_output_loss: 0.0617 - val_cat_output_acc: 0.1508 - val_num_output_acc: 0.9627\n",
      "Epoch 22/50\n",
      "20029/20029 [==============================] - 1s 59us/step - loss: 2.4797 - cat_output_loss: 2.4154 - num_output_loss: 0.0643 - cat_output_acc: 0.2394 - num_output_acc: 0.9670 - val_loss: 2.8474 - val_cat_output_loss: 2.7860 - val_num_output_loss: 0.0614 - val_cat_output_acc: 0.1520 - val_num_output_acc: 0.9627\n",
      "Epoch 23/50\n",
      "20029/20029 [==============================] - 1s 62us/step - loss: 2.4484 - cat_output_loss: 2.3839 - num_output_loss: 0.0646 - cat_output_acc: 0.2498 - num_output_acc: 0.9672 - val_loss: 2.8572 - val_cat_output_loss: 2.7899 - val_num_output_loss: 0.0672 - val_cat_output_acc: 0.1496 - val_num_output_acc: 0.9629\n",
      "Epoch 24/50\n",
      "20029/20029 [==============================] - 1s 63us/step - loss: 2.4380 - cat_output_loss: 2.3747 - num_output_loss: 0.0633 - cat_output_acc: 0.2524 - num_output_acc: 0.9673 - val_loss: 2.8725 - val_cat_output_loss: 2.8119 - val_num_output_loss: 0.0606 - val_cat_output_acc: 0.1456 - val_num_output_acc: 0.9621\n",
      "Epoch 25/50\n",
      "20029/20029 [==============================] - 1s 60us/step - loss: 2.4112 - cat_output_loss: 2.3484 - num_output_loss: 0.0628 - cat_output_acc: 0.2590 - num_output_acc: 0.9676 - val_loss: 2.8875 - val_cat_output_loss: 2.8213 - val_num_output_loss: 0.0662 - val_cat_output_acc: 0.1504 - val_num_output_acc: 0.9621\n",
      "Epoch 26/50\n",
      "20029/20029 [==============================] - 1s 63us/step - loss: 2.3912 - cat_output_loss: 2.3279 - num_output_loss: 0.0633 - cat_output_acc: 0.2705 - num_output_acc: 0.9668 - val_loss: 2.8823 - val_cat_output_loss: 2.8206 - val_num_output_loss: 0.0616 - val_cat_output_acc: 0.1512 - val_num_output_acc: 0.9625\n",
      "Epoch 27/50\n",
      "20029/20029 [==============================] - 1s 60us/step - loss: 2.3717 - cat_output_loss: 2.3084 - num_output_loss: 0.0633 - cat_output_acc: 0.2718 - num_output_acc: 0.9673 - val_loss: 2.9086 - val_cat_output_loss: 2.8488 - val_num_output_loss: 0.0598 - val_cat_output_acc: 0.1436 - val_num_output_acc: 0.9621\n",
      "Epoch 28/50\n",
      "20029/20029 [==============================] - 1s 59us/step - loss: 2.3508 - cat_output_loss: 2.2897 - num_output_loss: 0.0611 - cat_output_acc: 0.2797 - num_output_acc: 0.9667 - val_loss: 2.9116 - val_cat_output_loss: 2.8487 - val_num_output_loss: 0.0630 - val_cat_output_acc: 0.1414 - val_num_output_acc: 0.9625\n",
      "Epoch 29/50\n",
      "20029/20029 [==============================] - 1s 59us/step - loss: 2.3322 - cat_output_loss: 2.2713 - num_output_loss: 0.0609 - cat_output_acc: 0.2871 - num_output_acc: 0.9672 - val_loss: 2.9062 - val_cat_output_loss: 2.8452 - val_num_output_loss: 0.0610 - val_cat_output_acc: 0.1418 - val_num_output_acc: 0.9621\n",
      "Epoch 30/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 2.3109 - cat_output_loss: 2.2504 - num_output_loss: 0.0605 - cat_output_acc: 0.2934 - num_output_acc: 0.9672 - val_loss: 2.9479 - val_cat_output_loss: 2.8865 - val_num_output_loss: 0.0614 - val_cat_output_acc: 0.1488 - val_num_output_acc: 0.9623\n",
      "Epoch 31/50\n",
      "20029/20029 [==============================] - 1s 58us/step - loss: 2.2863 - cat_output_loss: 2.2270 - num_output_loss: 0.0593 - cat_output_acc: 0.2959 - num_output_acc: 0.9668 - val_loss: 2.9681 - val_cat_output_loss: 2.9066 - val_num_output_loss: 0.0615 - val_cat_output_acc: 0.1478 - val_num_output_acc: 0.9625\n",
      "X=[[0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 2. 0.]], Predicted=[array([[1.09501297e-09, 2.82352197e-11, 1.06683612e-11, 4.54096494e-08,\n",
      "        9.02206226e-11, 8.44732444e-12, 2.96747977e-08, 4.21735580e-09,\n",
      "        2.91429956e-08, 1.36486108e-07, 1.69389853e-08, 1.07191047e-08,\n",
      "        7.42612720e-01, 2.06405101e-11, 1.39836948e-10, 8.12152068e-10,\n",
      "        1.82015754e-07, 8.17255769e-03, 5.97089533e-09, 7.51500906e-09,\n",
      "        1.48255399e-08, 1.79424649e-03, 4.08833765e-11, 1.13492611e-08,\n",
      "        3.12619505e-07, 5.22571177e-08, 1.24933716e-10, 3.94019713e-12,\n",
      "        4.20122409e-10, 3.26835152e-12, 5.59317870e-12, 1.37864399e-11,\n",
      "        9.30190813e-10, 4.02421152e-10, 1.40795398e-09, 4.10795148e-10,\n",
      "        8.46005324e-03, 5.38905143e-09, 1.97789163e-08, 6.52877929e-09,\n",
      "        4.93553927e-08, 5.86255979e-13, 6.55369448e-09, 1.84494225e-11,\n",
      "        1.18386712e-09, 4.02434908e-14, 1.98927645e-11, 8.97053820e-10,\n",
      "        7.51033440e-06, 1.00749831e-09, 4.29840712e-11, 1.38037021e-11,\n",
      "        1.42017677e-06, 2.67422862e-09, 8.36047176e-10, 5.09572473e-13,\n",
      "        3.13365121e-07, 1.03351651e-02, 4.59891490e-14, 2.61800876e-11,\n",
      "        1.71006387e-09, 3.74942699e-09, 1.32534428e-10, 2.14372877e-11,\n",
      "        1.04289306e-10, 2.54771454e-10, 3.90661427e-11, 8.46964096e-11,\n",
      "        2.21464669e-09, 8.53776716e-10, 5.63451563e-10, 8.72487804e-10,\n",
      "        1.77623513e-10, 6.17572877e-12, 7.25762766e-13, 5.36944924e-07,\n",
      "        3.14615889e-09, 1.30414557e-09, 5.36579243e-08, 1.35447972e-11,\n",
      "        2.55259786e-10, 1.51522119e-08, 9.77949055e-10, 5.24632696e-07,\n",
      "        2.23558047e-07, 1.10371749e-12, 4.97804326e-13, 2.20136701e-10,\n",
      "        9.85883020e-09, 7.03073225e-11, 8.87047172e-11, 7.08901132e-11,\n",
      "        1.16310117e-09, 3.09475996e-13, 1.24725855e-10, 1.57949084e-10,\n",
      "        7.87141879e-11, 2.39424111e-07, 1.51538853e-16, 8.23307289e-09,\n",
      "        1.35637346e-09, 1.16657684e-04, 2.33911276e-11, 6.62428903e-08,\n",
      "        1.39886561e-10, 3.09778259e-10, 6.56556943e-03, 1.12433561e-13,\n",
      "        4.42178195e-13, 3.74827757e-02, 4.07229007e-11, 3.76709818e-12,\n",
      "        1.39420031e-08, 1.15321153e-09, 7.90160853e-11, 4.20801644e-10,\n",
      "        6.57199584e-09, 6.29865227e-08, 9.55576868e-11, 6.71405616e-08,\n",
      "        1.08307552e-09, 2.26196062e-09, 1.74304279e-10, 9.59626711e-10,\n",
      "        5.37579758e-09, 4.16913615e-09, 9.06463168e-11, 2.22972707e-09,\n",
      "        1.90523397e-09, 1.01945929e-14, 6.82535539e-12, 1.94873557e-08,\n",
      "        1.45885776e-10, 6.14415674e-09, 8.18220214e-11, 7.41917985e-11,\n",
      "        6.35642147e-13, 9.20792712e-14, 1.18828130e-08, 1.02900154e-12,\n",
      "        1.73207230e-11, 3.75224161e-15, 8.15035647e-13, 1.25413846e-10,\n",
      "        2.94985000e-12, 2.09118167e-09, 7.87147236e-09, 9.17754100e-14,\n",
      "        1.56104518e-09, 3.93484446e-11, 2.73450940e-13, 4.40542541e-13,\n",
      "        3.50629942e-10, 1.62728869e-12, 8.85135281e-12, 9.84583456e-11,\n",
      "        1.92683494e-10, 2.89504043e-09, 5.70221564e-14, 2.54482806e-11,\n",
      "        1.51608327e-11, 8.61105404e-13, 3.56608520e-09, 4.02638423e-10,\n",
      "        4.27665410e-15, 1.30816489e-01, 3.78081117e-12, 1.07058795e-09,\n",
      "        4.19362856e-09, 4.03727702e-12, 1.24319652e-11, 2.95287600e-10,\n",
      "        1.38931644e-11, 4.48646224e-11, 5.43941781e-08, 1.06294422e-08,\n",
      "        4.50007631e-09, 4.93844929e-08, 1.95132430e-12, 5.21630274e-11,\n",
      "        7.85081288e-12, 2.31171509e-08, 2.08851914e-09, 4.40197390e-09,\n",
      "        9.44761644e-14, 7.77375941e-09, 5.35208620e-02, 1.82166452e-11,\n",
      "        1.78469293e-08, 1.20908899e-11, 2.09476127e-14, 3.45410953e-08,\n",
      "        1.26070869e-08, 1.49737833e-10, 2.13921256e-10, 4.27887559e-10,\n",
      "        8.64523991e-12, 1.31241236e-13, 1.65142366e-09, 3.24157991e-13,\n",
      "        1.14904593e-10, 3.16954144e-16, 1.10626373e-04, 5.12749392e-11,\n",
      "        4.89312722e-11, 4.00367073e-10, 5.44530809e-10, 4.25603597e-14],\n",
      "       [2.04824508e-04, 1.73052802e-04, 5.08001467e-05, 3.67297835e-05,\n",
      "        1.12550595e-04, 1.02385689e-04, 1.37194334e-07, 1.62532316e-07,\n",
      "        7.61669799e-06, 1.09304805e-04, 3.22304222e-05, 2.10687986e-07,\n",
      "        4.20978977e-05, 1.34947604e-05, 1.75486304e-04, 8.72022501e-05,\n",
      "        5.27939073e-06, 4.73815671e-05, 7.18412423e-07, 1.59221629e-04,\n",
      "        5.87962745e-07, 7.78207541e-05, 9.33878473e-05, 4.10000561e-04,\n",
      "        4.54344154e-05, 2.65849758e-06, 3.17917846e-04, 7.65425095e-04,\n",
      "        3.29781329e-07, 3.01616092e-06, 3.47919604e-06, 1.26062878e-04,\n",
      "        1.33449648e-04, 1.00811412e-04, 2.56869953e-07, 5.91191487e-08,\n",
      "        1.74444431e-05, 4.36787232e-05, 8.18084154e-05, 4.12455956e-05,\n",
      "        2.21827099e-06, 2.15397071e-04, 3.61505154e-05, 3.25524729e-06,\n",
      "        9.77993935e-08, 6.62794264e-05, 3.17902071e-04, 9.06008705e-02,\n",
      "        2.73981044e-04, 7.60943512e-04, 1.13290473e-04, 2.10941129e-04,\n",
      "        7.86968303e-06, 3.27818270e-04, 1.76531374e-01, 1.12052738e-04,\n",
      "        4.15173434e-02, 3.39970427e-07, 1.06043888e-04, 1.58798779e-04,\n",
      "        8.89962166e-07, 3.48526186e-07, 8.39998165e-07, 2.70867599e-06,\n",
      "        2.06364206e-07, 4.91288411e-05, 2.54977721e-07, 7.11373161e-07,\n",
      "        4.08356500e-05, 1.07950555e-07, 1.22340462e-05, 9.76931369e-06,\n",
      "        4.34924237e-04, 5.58995195e-02, 5.44531722e-05, 1.17229647e-05,\n",
      "        2.76040810e-04, 7.10362494e-02, 1.36697534e-04, 7.22218188e-04,\n",
      "        1.03081391e-06, 6.05910554e-06, 1.95216326e-05, 1.50174101e-05,\n",
      "        2.70626279e-05, 1.32809568e-04, 4.39182710e-04, 1.40102478e-04,\n",
      "        3.20440345e-02, 2.52250611e-04, 2.94539001e-04, 8.51884215e-06,\n",
      "        3.30276758e-04, 3.78850207e-04, 4.08058895e-06, 1.24547580e-06,\n",
      "        9.88896045e-06, 7.65228651e-06, 6.73875329e-05, 8.10870454e-02,\n",
      "        1.39548747e-05, 3.24108296e-05, 4.04811135e-06, 1.42963324e-06,\n",
      "        1.50736945e-04, 3.07698559e-04, 1.04128576e-05, 6.53295021e-04,\n",
      "        1.02150196e-04, 7.05190314e-06, 1.72372049e-04, 7.66361773e-05,\n",
      "        3.28477472e-04, 8.59726279e-05, 6.90662942e-04, 2.23630661e-04,\n",
      "        3.54761578e-05, 3.06827387e-05, 3.34048091e-04, 2.25991471e-07,\n",
      "        6.77600201e-06, 4.53088404e-07, 3.33182688e-04, 2.83110217e-04,\n",
      "        7.32479893e-05, 1.49045474e-04, 2.94430993e-05, 1.94029354e-07,\n",
      "        4.67565114e-05, 3.99788114e-05, 1.72635191e-05, 2.01967123e-04,\n",
      "        7.54215347e-04, 6.19451457e-04, 9.74381194e-02, 1.44585993e-05,\n",
      "        2.19288107e-04, 3.93851697e-05, 4.53496881e-07, 8.46908188e-06,\n",
      "        1.30824536e-01, 2.66562914e-04, 5.54250553e-04, 1.82475651e-05,\n",
      "        1.46247985e-04, 8.36780714e-07, 1.88247753e-07, 3.67476605e-02,\n",
      "        7.76709130e-05, 9.85280712e-05, 3.54700647e-02, 5.00597351e-04,\n",
      "        9.82366964e-06, 8.43703383e-05, 5.07643599e-05, 1.06986350e-04,\n",
      "        1.60821262e-04, 1.48784733e-04, 2.53681549e-07, 1.94371241e-05,\n",
      "        7.82948575e-07, 3.66397173e-04, 5.55320298e-07, 1.66891323e-06,\n",
      "        1.86883393e-04, 3.83849829e-06, 2.09982143e-04, 1.58675078e-07,\n",
      "        5.84141731e-08, 9.53499330e-06, 7.80918300e-02, 1.06708267e-05,\n",
      "        1.84030156e-07, 2.72693724e-04, 1.59384008e-08, 4.94485948e-06,\n",
      "        1.83513494e-05, 2.47329623e-08, 3.45007218e-02, 1.67869125e-02,\n",
      "        6.43154908e-06, 9.12573614e-06, 8.34651219e-05, 7.36710888e-08,\n",
      "        4.53702407e-04, 1.32219526e-07, 3.67790813e-06, 1.14718364e-06,\n",
      "        8.01093265e-05, 4.98853979e-06, 1.10579604e-05, 6.17880578e-05,\n",
      "        8.76501858e-08, 6.61257873e-05, 4.74916815e-05, 1.77464110e-09,\n",
      "        1.25632563e-04, 5.48948534e-04, 1.34791765e-06, 4.40120857e-06,\n",
      "        9.15432702e-06, 1.29472697e-04, 2.68333770e-06, 3.82497965e-05,\n",
      "        1.85942770e-06, 7.40977981e-08, 7.41271069e-05, 1.81220301e-08]],\n",
      "      dtype=float32), array([[0.9937668],\n",
      "       [1.0201106]], dtype=float32)]\n",
      "발생지시군구 : 서구\n",
      "\n",
      "발생지시군구 : 고창군\n",
      "\n",
      "['사망자수'] : [0.9937668]\n",
      "['사망자수'] : [1.0201106]\n"
     ]
    }
   ],
   "source": [
    "mix_case(Case9, 1, 30,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 3s 140us/step - loss: 5.3993 - cat_output_loss: 4.8861 - num_output_loss: 0.5131 - cat_output_acc: 0.0391 - num_output_acc: 0.5722 - val_loss: 4.2457 - val_cat_output_loss: 3.8196 - val_num_output_loss: 0.4262 - val_cat_output_acc: 0.0984 - val_num_output_acc: 0.5539\n",
      "Epoch 2/50\n",
      " 3200/20029 [===>..........................] - ETA: 0s - loss: 4.2985 - cat_output_loss: 3.7370 - num_output_loss: 0.5615 - cat_output_acc: 0.1062 - num_output_acc: 0.5859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:1043: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_num_output_acc,val_cat_output_loss,val_num_output_loss,lr,val_cat_output_acc,num_output_acc,num_output_loss,val_loss,loss,cat_output_loss,cat_output_acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20029/20029 [==============================] - 1s 57us/step - loss: 3.7736 - cat_output_loss: 3.2362 - num_output_loss: 0.5374 - cat_output_acc: 0.1192 - num_output_acc: 0.6262 - val_loss: 3.2597 - val_cat_output_loss: 2.8280 - val_num_output_loss: 0.4318 - val_cat_output_acc: 0.1230 - val_num_output_acc: 0.8796\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 3.4209 - cat_output_loss: 2.8733 - num_output_loss: 0.5476 - cat_output_acc: 0.1372 - num_output_acc: 0.6897 - val_loss: 3.2478 - val_cat_output_loss: 2.7700 - val_num_output_loss: 0.4777 - val_cat_output_acc: 0.1358 - val_num_output_acc: 0.9087\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 3.3403 - cat_output_loss: 2.8011 - num_output_loss: 0.5392 - cat_output_acc: 0.1415 - num_output_acc: 0.7201 - val_loss: 3.4581 - val_cat_output_loss: 2.7404 - val_num_output_loss: 0.7176 - val_cat_output_acc: 0.1466 - val_num_output_acc: 0.7198\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 3.2988 - cat_output_loss: 2.7674 - num_output_loss: 0.5314 - cat_output_acc: 0.1501 - num_output_acc: 0.6815 - val_loss: 3.1608 - val_cat_output_loss: 2.7220 - val_num_output_loss: 0.4387 - val_cat_output_acc: 0.1468 - val_num_output_acc: 0.5962\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 3.2958 - cat_output_loss: 2.7494 - num_output_loss: 0.5464 - cat_output_acc: 0.1517 - num_output_acc: 0.7299 - val_loss: 3.1312 - val_cat_output_loss: 2.7143 - val_num_output_loss: 0.4170 - val_cat_output_acc: 0.1546 - val_num_output_acc: 0.6993\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 3.2056 - cat_output_loss: 2.7211 - num_output_loss: 0.4845 - cat_output_acc: 0.1558 - num_output_acc: 0.6740 - val_loss: 3.1480 - val_cat_output_loss: 2.7107 - val_num_output_loss: 0.4374 - val_cat_output_acc: 0.1611 - val_num_output_acc: 0.7430\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 3.3032 - cat_output_loss: 2.7148 - num_output_loss: 0.5883 - cat_output_acc: 0.1577 - num_output_acc: 0.6416 - val_loss: 3.3291 - val_cat_output_loss: 2.7044 - val_num_output_loss: 0.6247 - val_cat_output_acc: 0.1552 - val_num_output_acc: 0.9103\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 58us/step - loss: 3.3357 - cat_output_loss: 2.7064 - num_output_loss: 0.6293 - cat_output_acc: 0.1609 - num_output_acc: 0.7248 - val_loss: 3.2269 - val_cat_output_loss: 2.7224 - val_num_output_loss: 0.5045 - val_cat_output_acc: 0.1482 - val_num_output_acc: 0.3960\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 3.2287 - cat_output_loss: 2.6885 - num_output_loss: 0.5402 - cat_output_acc: 0.1639 - num_output_acc: 0.7081 - val_loss: 3.1257 - val_cat_output_loss: 2.6922 - val_num_output_loss: 0.4335 - val_cat_output_acc: 0.1567 - val_num_output_acc: 0.9016\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 56us/step - loss: 3.1583 - cat_output_loss: 2.6750 - num_output_loss: 0.4833 - cat_output_acc: 0.1643 - num_output_acc: 0.6724 - val_loss: 3.2812 - val_cat_output_loss: 2.6998 - val_num_output_loss: 0.5814 - val_cat_output_acc: 0.1593 - val_num_output_acc: 0.6573\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 3.1919 - cat_output_loss: 2.6703 - num_output_loss: 0.5216 - cat_output_acc: 0.1655 - num_output_acc: 0.6878 - val_loss: 3.1695 - val_cat_output_loss: 2.6947 - val_num_output_loss: 0.4748 - val_cat_output_acc: 0.1536 - val_num_output_acc: 0.7262\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 62us/step - loss: 3.2867 - cat_output_loss: 2.6683 - num_output_loss: 0.6184 - cat_output_acc: 0.1684 - num_output_acc: 0.7017 - val_loss: 3.3505 - val_cat_output_loss: 2.6918 - val_num_output_loss: 0.6587 - val_cat_output_acc: 0.1603 - val_num_output_acc: 0.2558\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 63us/step - loss: 3.1354 - cat_output_loss: 2.6559 - num_output_loss: 0.4795 - cat_output_acc: 0.1723 - num_output_acc: 0.5663 - val_loss: 3.1257 - val_cat_output_loss: 2.6977 - val_num_output_loss: 0.4280 - val_cat_output_acc: 0.1641 - val_num_output_acc: 0.5082\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 1s 60us/step - loss: 3.1596 - cat_output_loss: 2.6394 - num_output_loss: 0.5202 - cat_output_acc: 0.1745 - num_output_acc: 0.5659 - val_loss: 3.1228 - val_cat_output_loss: 2.6953 - val_num_output_loss: 0.4275 - val_cat_output_acc: 0.1627 - val_num_output_acc: 0.8900\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 1s 64us/step - loss: 3.1261 - cat_output_loss: 2.6340 - num_output_loss: 0.4920 - cat_output_acc: 0.1759 - num_output_acc: 0.5791 - val_loss: 3.1108 - val_cat_output_loss: 2.6927 - val_num_output_loss: 0.4181 - val_cat_output_acc: 0.1651 - val_num_output_acc: 0.8522\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 1s 59us/step - loss: 3.1213 - cat_output_loss: 2.6147 - num_output_loss: 0.5066 - cat_output_acc: 0.1823 - num_output_acc: 0.5996 - val_loss: 3.3109 - val_cat_output_loss: 2.7152 - val_num_output_loss: 0.5957 - val_cat_output_acc: 0.1567 - val_num_output_acc: 0.4657\n",
      "Epoch 18/50\n",
      "20029/20029 [==============================] - 1s 64us/step - loss: 3.1461 - cat_output_loss: 2.6156 - num_output_loss: 0.5305 - cat_output_acc: 0.1817 - num_output_acc: 0.4882 - val_loss: 3.6196 - val_cat_output_loss: 2.7032 - val_num_output_loss: 0.9164 - val_cat_output_acc: 0.1514 - val_num_output_acc: 0.8191\n",
      "Epoch 19/50\n",
      "20029/20029 [==============================] - 1s 59us/step - loss: 3.1998 - cat_output_loss: 2.6134 - num_output_loss: 0.5865 - cat_output_acc: 0.1815 - num_output_acc: 0.4837 - val_loss: 3.1552 - val_cat_output_loss: 2.7068 - val_num_output_loss: 0.4484 - val_cat_output_acc: 0.1571 - val_num_output_acc: 0.8494\n",
      "Epoch 20/50\n",
      "20029/20029 [==============================] - 1s 64us/step - loss: 3.0902 - cat_output_loss: 2.5965 - num_output_loss: 0.4937 - cat_output_acc: 0.1855 - num_output_acc: 0.5931 - val_loss: 3.2227 - val_cat_output_loss: 2.7174 - val_num_output_loss: 0.5053 - val_cat_output_acc: 0.1510 - val_num_output_acc: 0.5821\n",
      "Epoch 21/50\n",
      "20029/20029 [==============================] - 1s 64us/step - loss: 3.1348 - cat_output_loss: 2.5976 - num_output_loss: 0.5372 - cat_output_acc: 0.1879 - num_output_acc: 0.5823 - val_loss: 3.1921 - val_cat_output_loss: 2.7073 - val_num_output_loss: 0.4848 - val_cat_output_acc: 0.1565 - val_num_output_acc: 0.8063\n",
      "Epoch 22/50\n",
      "20029/20029 [==============================] - 1s 62us/step - loss: 3.0655 - cat_output_loss: 2.5887 - num_output_loss: 0.4768 - cat_output_acc: 0.1902 - num_output_acc: 0.6019 - val_loss: 3.1346 - val_cat_output_loss: 2.7141 - val_num_output_loss: 0.4206 - val_cat_output_acc: 0.1583 - val_num_output_acc: 0.8788\n",
      "Epoch 23/50\n",
      "20029/20029 [==============================] - 1s 64us/step - loss: 3.0588 - cat_output_loss: 2.5767 - num_output_loss: 0.4821 - cat_output_acc: 0.1927 - num_output_acc: 0.6144 - val_loss: 3.1544 - val_cat_output_loss: 2.7184 - val_num_output_loss: 0.4361 - val_cat_output_acc: 0.1593 - val_num_output_acc: 0.7744\n",
      "Epoch 24/50\n",
      "20029/20029 [==============================] - 1s 64us/step - loss: 3.0324 - cat_output_loss: 2.5745 - num_output_loss: 0.4579 - cat_output_acc: 0.1896 - num_output_acc: 0.5929 - val_loss: 3.1317 - val_cat_output_loss: 2.7133 - val_num_output_loss: 0.4184 - val_cat_output_acc: 0.1498 - val_num_output_acc: 0.8760\n",
      "Epoch 25/50\n",
      "20029/20029 [==============================] - 1s 65us/step - loss: 3.0375 - cat_output_loss: 2.5607 - num_output_loss: 0.4768 - cat_output_acc: 0.1955 - num_output_acc: 0.5827 - val_loss: 3.2458 - val_cat_output_loss: 2.7063 - val_num_output_loss: 0.5395 - val_cat_output_acc: 0.1609 - val_num_output_acc: 0.8910\n",
      "Epoch 26/50\n",
      "20029/20029 [==============================] - 1s 59us/step - loss: 3.0848 - cat_output_loss: 2.5540 - num_output_loss: 0.5307 - cat_output_acc: 0.1983 - num_output_acc: 0.6020 - val_loss: 3.2158 - val_cat_output_loss: 2.7262 - val_num_output_loss: 0.4896 - val_cat_output_acc: 0.1548 - val_num_output_acc: 0.8133\n",
      "Epoch 27/50\n",
      "20029/20029 [==============================] - 1s 56us/step - loss: 3.0536 - cat_output_loss: 2.5476 - num_output_loss: 0.5060 - cat_output_acc: 0.2062 - num_output_acc: 0.6258 - val_loss: 3.1759 - val_cat_output_loss: 2.7270 - val_num_output_loss: 0.4490 - val_cat_output_acc: 0.1591 - val_num_output_acc: 0.8864\n",
      "Epoch 28/50\n",
      "20029/20029 [==============================] - 1s 56us/step - loss: 3.0109 - cat_output_loss: 2.5315 - num_output_loss: 0.4794 - cat_output_acc: 0.2042 - num_output_acc: 0.5468 - val_loss: 3.1093 - val_cat_output_loss: 2.7233 - val_num_output_loss: 0.3860 - val_cat_output_acc: 0.1629 - val_num_output_acc: 0.8672\n",
      "Epoch 29/50\n",
      "20029/20029 [==============================] - 1s 56us/step - loss: 3.1266 - cat_output_loss: 2.5386 - num_output_loss: 0.5880 - cat_output_acc: 0.2063 - num_output_acc: 0.6276 - val_loss: 3.2769 - val_cat_output_loss: 2.7306 - val_num_output_loss: 0.5463 - val_cat_output_acc: 0.1605 - val_num_output_acc: 0.9067\n",
      "Epoch 30/50\n",
      "20029/20029 [==============================] - 1s 56us/step - loss: 3.0508 - cat_output_loss: 2.5273 - num_output_loss: 0.5235 - cat_output_acc: 0.2014 - num_output_acc: 0.4556 - val_loss: 3.1715 - val_cat_output_loss: 2.7437 - val_num_output_loss: 0.4279 - val_cat_output_acc: 0.1605 - val_num_output_acc: 0.8960\n",
      "Epoch 31/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 3.0141 - cat_output_loss: 2.5176 - num_output_loss: 0.4965 - cat_output_acc: 0.2109 - num_output_acc: 0.4738 - val_loss: 3.3340 - val_cat_output_loss: 2.7437 - val_num_output_loss: 0.5902 - val_cat_output_acc: 0.1631 - val_num_output_acc: 0.1705\n",
      "Epoch 32/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 3.0177 - cat_output_loss: 2.5141 - num_output_loss: 0.5037 - cat_output_acc: 0.2139 - num_output_acc: 0.4667 - val_loss: 3.1922 - val_cat_output_loss: 2.7283 - val_num_output_loss: 0.4639 - val_cat_output_acc: 0.1569 - val_num_output_acc: 0.2021\n",
      "Epoch 33/50\n",
      "20029/20029 [==============================] - 1s 56us/step - loss: 2.9216 - cat_output_loss: 2.4929 - num_output_loss: 0.4287 - cat_output_acc: 0.2177 - num_output_acc: 0.4996 - val_loss: 3.2915 - val_cat_output_loss: 2.7482 - val_num_output_loss: 0.5433 - val_cat_output_acc: 0.1565 - val_num_output_acc: 0.1851\n",
      "Epoch 34/50\n",
      "20029/20029 [==============================] - 1s 56us/step - loss: 2.9682 - cat_output_loss: 2.4973 - num_output_loss: 0.4708 - cat_output_acc: 0.2190 - num_output_acc: 0.5635 - val_loss: 3.2526 - val_cat_output_loss: 2.7377 - val_num_output_loss: 0.5149 - val_cat_output_acc: 0.1538 - val_num_output_acc: 0.9093\n",
      "Epoch 35/50\n",
      "20029/20029 [==============================] - 1s 56us/step - loss: 2.8792 - cat_output_loss: 2.4767 - num_output_loss: 0.4025 - cat_output_acc: 0.2214 - num_output_acc: 0.5298 - val_loss: 3.1989 - val_cat_output_loss: 2.7613 - val_num_output_loss: 0.4376 - val_cat_output_acc: 0.1587 - val_num_output_acc: 0.2931\n",
      "Epoch 36/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 2.8996 - cat_output_loss: 2.4755 - num_output_loss: 0.4241 - cat_output_acc: 0.2242 - num_output_acc: 0.4754 - val_loss: 3.1794 - val_cat_output_loss: 2.7603 - val_num_output_loss: 0.4191 - val_cat_output_acc: 0.1631 - val_num_output_acc: 0.7548\n",
      "Epoch 37/50\n",
      "20029/20029 [==============================] - 1s 58us/step - loss: 2.9174 - cat_output_loss: 2.4670 - num_output_loss: 0.4505 - cat_output_acc: 0.2254 - num_output_acc: 0.5118 - val_loss: 3.2507 - val_cat_output_loss: 2.7683 - val_num_output_loss: 0.4824 - val_cat_output_acc: 0.1544 - val_num_output_acc: 0.2498\n",
      "Epoch 38/50\n",
      "20029/20029 [==============================] - 1s 58us/step - loss: 2.8474 - cat_output_loss: 2.4598 - num_output_loss: 0.3876 - cat_output_acc: 0.2277 - num_output_acc: 0.5103 - val_loss: 3.1774 - val_cat_output_loss: 2.7761 - val_num_output_loss: 0.4012 - val_cat_output_acc: 0.1548 - val_num_output_acc: 0.4063\n",
      "Epoch 39/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 2.9168 - cat_output_loss: 2.4555 - num_output_loss: 0.4613 - cat_output_acc: 0.2300 - num_output_acc: 0.4897 - val_loss: 3.3834 - val_cat_output_loss: 2.7635 - val_num_output_loss: 0.6199 - val_cat_output_acc: 0.1577 - val_num_output_acc: 0.1627\n",
      "Epoch 40/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 2.9280 - cat_output_loss: 2.4414 - num_output_loss: 0.4866 - cat_output_acc: 0.2339 - num_output_acc: 0.4756 - val_loss: 3.2961 - val_cat_output_loss: 2.7682 - val_num_output_loss: 0.5279 - val_cat_output_acc: 0.1518 - val_num_output_acc: 0.3626\n",
      "Epoch 41/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 2.8926 - cat_output_loss: 2.4324 - num_output_loss: 0.4602 - cat_output_acc: 0.2346 - num_output_acc: 0.5441 - val_loss: 3.1480 - val_cat_output_loss: 2.7791 - val_num_output_loss: 0.3688 - val_cat_output_acc: 0.1597 - val_num_output_acc: 0.5639\n",
      "Epoch 42/50\n",
      "20029/20029 [==============================] - 1s 58us/step - loss: 2.8301 - cat_output_loss: 2.4294 - num_output_loss: 0.4008 - cat_output_acc: 0.2372 - num_output_acc: 0.5873 - val_loss: 3.2764 - val_cat_output_loss: 2.7707 - val_num_output_loss: 0.5057 - val_cat_output_acc: 0.1544 - val_num_output_acc: 0.9046\n",
      "Epoch 43/50\n",
      "20029/20029 [==============================] - 1s 58us/step - loss: 2.8396 - cat_output_loss: 2.4146 - num_output_loss: 0.4250 - cat_output_acc: 0.2416 - num_output_acc: 0.5604 - val_loss: 3.2793 - val_cat_output_loss: 2.7886 - val_num_output_loss: 0.4907 - val_cat_output_acc: 0.1522 - val_num_output_acc: 0.7502\n",
      "Epoch 44/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 2.8084 - cat_output_loss: 2.4121 - num_output_loss: 0.3963 - cat_output_acc: 0.2378 - num_output_acc: 0.6500 - val_loss: 3.2280 - val_cat_output_loss: 2.7918 - val_num_output_loss: 0.4362 - val_cat_output_acc: 0.1611 - val_num_output_acc: 0.1669\n",
      "Epoch 45/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 2.7671 - cat_output_loss: 2.3955 - num_output_loss: 0.3717 - cat_output_acc: 0.2476 - num_output_acc: 0.5160 - val_loss: 3.2647 - val_cat_output_loss: 2.8009 - val_num_output_loss: 0.4638 - val_cat_output_acc: 0.1528 - val_num_output_acc: 0.2278\n",
      "Epoch 46/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 2.7948 - cat_output_loss: 2.3911 - num_output_loss: 0.4036 - cat_output_acc: 0.2502 - num_output_acc: 0.5254 - val_loss: 3.2855 - val_cat_output_loss: 2.8155 - val_num_output_loss: 0.4699 - val_cat_output_acc: 0.1522 - val_num_output_acc: 0.1677\n",
      "Epoch 47/50\n",
      "20029/20029 [==============================] - 1s 58us/step - loss: 2.8963 - cat_output_loss: 2.3847 - num_output_loss: 0.5116 - cat_output_acc: 0.2492 - num_output_acc: 0.5569 - val_loss: 3.2749 - val_cat_output_loss: 2.8167 - val_num_output_loss: 0.4582 - val_cat_output_acc: 0.1480 - val_num_output_acc: 0.8880\n",
      "Epoch 48/50\n",
      "20029/20029 [==============================] - 1s 57us/step - loss: 2.7092 - cat_output_loss: 2.3786 - num_output_loss: 0.3307 - cat_output_acc: 0.2530 - num_output_acc: 0.6504 - val_loss: 3.2979 - val_cat_output_loss: 2.8156 - val_num_output_loss: 0.4823 - val_cat_output_acc: 0.1563 - val_num_output_acc: 0.9079\n",
      "X=[[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 2. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 6. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 4. 0.]], Predicted=[array([[3.36457233e-05, 3.27985417e-10, 3.12987171e-11, 1.17533326e-01,\n",
      "        3.00813042e-12, 8.11206713e-10, 3.11621932e-07, 4.29164970e-08,\n",
      "        5.94871583e-11, 2.25633678e-11, 4.02491111e-07, 1.25323061e-06,\n",
      "        4.54512462e-02, 7.19752480e-10, 9.23468724e-06, 3.70783647e-11,\n",
      "        6.53821189e-07, 2.41370760e-02, 3.56428667e-12, 1.01222786e-05,\n",
      "        8.62499235e-07, 1.10796660e-01, 5.22098560e-07, 1.31883303e-06,\n",
      "        3.92002993e-11, 5.15503089e-08, 1.20940547e-06, 1.46809199e-07,\n",
      "        6.72441258e-09, 3.39326206e-10, 2.18346660e-10, 1.88642595e-08,\n",
      "        4.37652261e-07, 1.09065465e-10, 3.78588538e-09, 9.94949829e-08,\n",
      "        3.38122970e-03, 7.64139529e-10, 2.07216369e-10, 7.25411051e-11,\n",
      "        2.24022038e-12, 1.02013120e-10, 9.02690492e-11, 1.39869383e-09,\n",
      "        1.94922034e-08, 1.70043293e-07, 1.18044227e-10, 3.40350503e-09,\n",
      "        1.36059944e-05, 9.56345389e-07, 2.34058871e-06, 5.16539058e-06,\n",
      "        3.62990759e-02, 5.96148908e-09, 2.04793738e-09, 1.51244251e-07,\n",
      "        5.77826054e-09, 6.67577780e-08, 1.13361170e-06, 4.51081306e-09,\n",
      "        1.96597533e-14, 9.64080460e-09, 1.60305363e-13, 1.07534881e-09,\n",
      "        4.24072049e-08, 1.07027381e-06, 1.58018848e-13, 2.89249069e-10,\n",
      "        2.75728884e-09, 1.66358749e-08, 4.67851078e-06, 2.49536697e-10,\n",
      "        6.47375884e-07, 1.01238029e-09, 3.08248275e-07, 1.68291280e-07,\n",
      "        1.18936825e-08, 1.39027775e-10, 9.55216808e-11, 1.69372427e-09,\n",
      "        2.51504980e-13, 2.73798449e-11, 3.03100587e-05, 8.89486728e-07,\n",
      "        4.78511482e-01, 2.99032110e-09, 2.84008834e-08, 7.16844917e-11,\n",
      "        8.06583671e-08, 2.61763222e-10, 2.11773195e-08, 7.95943034e-10,\n",
      "        5.34577591e-11, 4.11497281e-10, 5.58371482e-09, 1.59089282e-07,\n",
      "        3.93320420e-07, 1.83647409e-01, 4.98279890e-12, 6.23617824e-10,\n",
      "        1.29167024e-08, 1.07158385e-05, 2.27579733e-09, 1.62121660e-06,\n",
      "        2.58386390e-12, 4.31126892e-07, 7.35104466e-09, 2.63714899e-08,\n",
      "        1.24075383e-09, 6.16812841e-08, 5.59920068e-07, 3.67655531e-07,\n",
      "        1.63713012e-05, 1.59502259e-10, 2.06889581e-06, 8.57707710e-06,\n",
      "        3.26491227e-06, 2.82429809e-12, 2.39132055e-06, 1.08895124e-08,\n",
      "        5.73330494e-09, 8.88654995e-07, 6.10287862e-11, 2.35944542e-10,\n",
      "        1.14908343e-11, 2.83010160e-11, 5.96653022e-12, 5.64776633e-13,\n",
      "        5.39180519e-07, 1.38462696e-11, 2.75194975e-06, 3.41153864e-05,\n",
      "        3.83977250e-09, 1.92940153e-08, 1.91250282e-09, 7.30082617e-09,\n",
      "        1.08754791e-12, 1.45001904e-08, 2.88054821e-07, 3.37785622e-09,\n",
      "        4.72379136e-10, 3.77519682e-10, 2.85994190e-07, 1.06782486e-10,\n",
      "        1.70117076e-09, 6.87682604e-14, 5.32890496e-08, 5.72985513e-11,\n",
      "        9.13216718e-06, 3.42779249e-09, 2.31032316e-12, 5.72686454e-10,\n",
      "        4.62034722e-09, 5.18446711e-07, 1.26914357e-09, 1.18256906e-11,\n",
      "        1.03768868e-11, 8.19243701e-11, 6.76265684e-15, 4.27950567e-07,\n",
      "        7.76024956e-14, 1.07548727e-11, 1.24680626e-12, 2.38754414e-14,\n",
      "        3.65702668e-08, 1.35375245e-07, 4.76481539e-08, 2.94248377e-13,\n",
      "        1.82877056e-08, 9.89099774e-11, 7.56035512e-10, 3.45058879e-08,\n",
      "        4.48556534e-08, 7.10612016e-13, 4.37615899e-09, 8.63667093e-09,\n",
      "        2.19645312e-06, 1.98234567e-08, 1.46964680e-11, 9.91908067e-09,\n",
      "        4.17868240e-10, 2.12887582e-13, 1.48375853e-10, 1.86849718e-07,\n",
      "        1.85674226e-10, 2.91738205e-12, 2.23510440e-07, 1.09361531e-09,\n",
      "        4.32055548e-14, 1.29559530e-09, 1.07247311e-09, 1.03338016e-05,\n",
      "        1.23785657e-08, 1.76175064e-11, 5.44454846e-12, 2.23534204e-08,\n",
      "        1.74677319e-12, 7.96967754e-08, 2.96001529e-15, 2.43889690e-06,\n",
      "        8.21851609e-06, 7.69651121e-10, 5.66984737e-10, 2.68375500e-09,\n",
      "        4.00363438e-14, 6.44365339e-10, 8.21205465e-11, 1.40755871e-11],\n",
      "       [1.81452226e-04, 4.78530467e-07, 2.58874110e-07, 5.16537286e-04,\n",
      "        3.49956615e-08, 4.79933078e-07, 1.91891058e-06, 1.40323773e-05,\n",
      "        1.27782869e-06, 8.32925991e-07, 3.04053283e-05, 9.18742153e-05,\n",
      "        4.96046320e-02, 2.32617253e-06, 5.26443255e-05, 2.09980691e-08,\n",
      "        1.14750497e-01, 7.66440388e-03, 7.66352173e-08, 1.75042605e-05,\n",
      "        1.18286735e-04, 1.03474841e-01, 1.13176748e-06, 5.30290490e-05,\n",
      "        1.81899566e-07, 4.16742783e-04, 6.95519429e-06, 3.18682009e-06,\n",
      "        3.50953815e-05, 6.91954725e-08, 2.24235663e-07, 1.49675099e-08,\n",
      "        5.72048839e-06, 2.53043151e-08, 1.37153975e-05, 5.41869440e-06,\n",
      "        1.84044883e-01, 1.85182068e-06, 1.77996162e-06, 6.19854701e-09,\n",
      "        8.71659793e-08, 1.61895386e-08, 2.38716984e-05, 1.07542573e-05,\n",
      "        9.18550722e-06, 1.55769646e-06, 4.53821762e-08, 2.67527590e-04,\n",
      "        1.01320657e-04, 1.45180193e-05, 3.03931370e-06, 1.69105215e-06,\n",
      "        5.25892377e-01, 4.67657810e-06, 1.37255061e-04, 1.13474277e-06,\n",
      "        1.17184260e-04, 4.30130312e-04, 2.55215213e-07, 7.51884102e-07,\n",
      "        7.04418246e-10, 6.38068304e-05, 5.06870435e-10, 1.44976309e-06,\n",
      "        6.55934809e-06, 6.64373802e-05, 1.22893669e-08, 4.72285393e-08,\n",
      "        2.39074893e-07, 6.83022154e-05, 1.23341742e-04, 1.75469040e-06,\n",
      "        2.30735623e-05, 1.77439324e-05, 2.69820816e-07, 7.44274814e-07,\n",
      "        1.79808410e-06, 2.77017716e-05, 1.60942000e-05, 2.97231895e-06,\n",
      "        4.54830218e-09, 1.49915104e-06, 1.64139067e-06, 1.25102486e-06,\n",
      "        2.85937829e-04, 1.46756054e-06, 9.48638262e-06, 4.87533001e-08,\n",
      "        1.56036601e-03, 2.80829160e-09, 4.90957700e-06, 1.00381897e-07,\n",
      "        2.21305157e-07, 1.03615230e-06, 2.71696990e-07, 1.56867143e-04,\n",
      "        1.35239156e-06, 8.82964930e-04, 2.87629642e-10, 5.46083211e-05,\n",
      "        1.03687944e-05, 1.31152177e-04, 9.52916537e-07, 2.58614193e-04,\n",
      "        2.26064518e-08, 3.28284045e-07, 9.64349329e-06, 7.17174364e-09,\n",
      "        5.30393095e-07, 2.97095889e-04, 1.99140577e-05, 1.78194966e-07,\n",
      "        1.93279102e-05, 1.78515859e-06, 6.06685389e-05, 2.01828170e-05,\n",
      "        4.04305197e-03, 8.96426542e-08, 1.52575303e-05, 4.70360064e-05,\n",
      "        6.19609978e-07, 7.28834857e-06, 5.23003450e-07, 1.14697082e-06,\n",
      "        5.00443349e-08, 4.99533535e-08, 2.43187060e-06, 4.87990732e-08,\n",
      "        1.37247134e-05, 2.84789459e-09, 1.00028274e-06, 4.90508210e-05,\n",
      "        5.40699432e-07, 2.03421314e-06, 8.34299426e-04, 1.00249872e-05,\n",
      "        8.68342287e-09, 2.46263632e-09, 6.45128748e-05, 1.33632581e-08,\n",
      "        1.76240428e-05, 4.12568202e-09, 8.01080932e-06, 7.46389439e-09,\n",
      "        3.55539385e-07, 2.28570429e-09, 1.02277401e-04, 5.90635238e-07,\n",
      "        8.47148476e-06, 2.59151761e-07, 5.69812300e-07, 2.58379089e-07,\n",
      "        1.27126998e-06, 6.74715125e-07, 1.07584732e-07, 1.55167754e-07,\n",
      "        2.18915531e-07, 4.58892231e-07, 3.19527349e-10, 1.70688361e-06,\n",
      "        6.46219744e-09, 4.17982946e-08, 8.09782075e-10, 7.23921922e-10,\n",
      "        1.03668263e-07, 1.11496274e-03, 6.64354502e-06, 1.83197688e-08,\n",
      "        2.08737811e-06, 5.24022106e-08, 1.79882860e-04, 1.49676889e-05,\n",
      "        2.67038160e-07, 3.73912172e-08, 1.17318334e-04, 5.64828850e-09,\n",
      "        1.28759621e-05, 9.88290631e-05, 9.14970883e-07, 2.94704747e-04,\n",
      "        7.09502430e-08, 3.54033212e-08, 2.70810469e-05, 2.93529320e-06,\n",
      "        2.57065249e-08, 2.44726053e-08, 1.87084981e-04, 2.25515763e-07,\n",
      "        4.52986413e-08, 4.71715765e-07, 2.94738989e-09, 8.00609341e-05,\n",
      "        2.23051436e-04, 1.13211067e-08, 7.02421903e-06, 4.58326959e-08,\n",
      "        1.46858534e-08, 2.49035395e-07, 7.13865494e-11, 6.23023539e-07,\n",
      "        4.74557737e-06, 1.97705607e-09, 1.33314870e-06, 1.57254328e-06,\n",
      "        4.83174373e-13, 3.88073704e-06, 3.03975849e-05, 4.83476121e-08],\n",
      "       [3.51785820e-05, 7.10603781e-05, 6.11309733e-05, 2.40412362e-07,\n",
      "        1.81601263e-05, 1.86496909e-04, 4.83498210e-04, 3.16480291e-04,\n",
      "        5.31758298e-04, 7.01563181e-07, 1.87179267e-05, 2.59315275e-04,\n",
      "        7.73631400e-05, 6.45093247e-02, 8.50994456e-06, 2.15650671e-05,\n",
      "        3.04773877e-08, 1.57491416e-02, 1.15972036e-03, 1.96944220e-05,\n",
      "        4.64905432e-04, 4.62337630e-06, 3.35271034e-04, 1.39809745e-05,\n",
      "        1.25404149e-05, 4.98121232e-02, 1.09627092e-06, 3.99111468e-06,\n",
      "        7.13471809e-06, 4.48220409e-02, 3.67124304e-02, 1.40942097e-06,\n",
      "        9.27754081e-06, 8.29661917e-03, 3.69818445e-05, 1.31325258e-04,\n",
      "        8.30091012e-05, 1.05203428e-04, 2.95637847e-07, 2.03087875e-08,\n",
      "        1.58268667e-04, 2.25618769e-05, 2.63144784e-06, 6.09156452e-02,\n",
      "        4.15002374e-04, 5.26288582e-04, 2.08464953e-05, 2.76952160e-05,\n",
      "        3.83939437e-07, 4.66655274e-06, 1.83106051e-04, 4.44133766e-05,\n",
      "        4.88679943e-05, 1.20792844e-04, 6.01262072e-05, 8.14220461e-04,\n",
      "        1.25128900e-05, 1.19641426e-08, 8.68623029e-05, 1.11327987e-04,\n",
      "        9.76503215e-05, 9.32094190e-06, 1.99360686e-04, 3.80632021e-02,\n",
      "        1.26765051e-04, 1.00637726e-05, 6.40165308e-05, 2.19321083e-02,\n",
      "        4.00266617e-05, 9.11046955e-05, 1.03662069e-06, 1.14834391e-01,\n",
      "        1.82440726e-05, 2.35612915e-05, 9.99520198e-05, 3.10982045e-07,\n",
      "        7.42716220e-05, 1.28660531e-05, 3.75920854e-06, 1.80969437e-04,\n",
      "        1.81089345e-04, 4.67206002e-04, 5.68422583e-05, 1.89990416e-07,\n",
      "        2.56483503e-07, 3.44184431e-04, 2.77757681e-06, 4.73082810e-06,\n",
      "        8.54460886e-05, 3.60703370e-06, 1.98146925e-04, 4.05290835e-02,\n",
      "        7.26632643e-05, 2.00623675e-04, 4.26051999e-03, 9.95804789e-04,\n",
      "        2.02525644e-06, 6.31737862e-07, 7.15071837e-06, 6.43248131e-05,\n",
      "        4.68534380e-02, 3.18799778e-07, 8.29975083e-02, 3.34424112e-04,\n",
      "        8.99602037e-06, 5.56717987e-06, 6.10655038e-09, 1.32727946e-05,\n",
      "        3.81907041e-04, 2.22532526e-06, 1.49330333e-06, 1.04283630e-04,\n",
      "        6.85447776e-06, 4.66763225e-07, 1.66912469e-05, 2.40965717e-04,\n",
      "        5.63022809e-07, 1.93343830e-08, 2.14476950e-06, 5.77452738e-05,\n",
      "        5.38639426e-02, 2.52483558e-04, 3.79507001e-05, 6.12050062e-05,\n",
      "        4.37137533e-06, 1.76019021e-05, 1.59221520e-06, 2.13746796e-04,\n",
      "        1.12735177e-06, 1.32979058e-05, 6.97721916e-05, 8.34448929e-06,\n",
      "        6.47196066e-05, 9.23188327e-06, 3.99463570e-05, 6.98822141e-02,\n",
      "        5.94296171e-06, 6.31825242e-05, 3.47803434e-04, 1.62195563e-02,\n",
      "        1.73012013e-05, 3.51005656e-05, 7.12491328e-06, 3.66333174e-03,\n",
      "        5.29526333e-05, 1.84565317e-04, 2.06869900e-05, 4.24338505e-05,\n",
      "        4.71629828e-05, 1.22135039e-04, 1.60787804e-05, 1.78661780e-04,\n",
      "        4.68802452e-02, 2.62119147e-06, 6.51260489e-05, 4.26146216e-05,\n",
      "        1.60532527e-05, 1.70792300e-05, 1.92677617e-04, 2.23305938e-06,\n",
      "        2.57299631e-04, 8.46632174e-05, 7.15762362e-05, 2.24854535e-04,\n",
      "        1.40034317e-04, 5.03662875e-07, 3.57974329e-07, 4.83313088e-05,\n",
      "        3.20352614e-04, 1.31416637e-02, 1.38964569e-05, 2.74285581e-02,\n",
      "        2.52140540e-04, 1.30839408e-05, 2.96953920e-04, 4.62851627e-03,\n",
      "        3.19165270e-06, 1.55968755e-05, 6.92991443e-06, 3.07093287e-05,\n",
      "        9.65848789e-02, 1.12626211e-08, 2.96214557e-06, 4.04278311e-04,\n",
      "        1.70155981e-04, 2.03949559e-04, 2.86381379e-07, 1.12935752e-02,\n",
      "        2.60700745e-07, 8.81358143e-03, 1.06816685e-06, 9.87775024e-07,\n",
      "        8.04252631e-05, 1.68873848e-05, 1.48077049e-07, 3.38561449e-07,\n",
      "        1.50921742e-05, 1.11959045e-04, 6.31377361e-06, 1.52980181e-04,\n",
      "        1.54545614e-06, 2.30173173e-05, 4.88602492e-10, 9.88724622e-08,\n",
      "        1.33928495e-07, 3.39995017e-06, 4.59641115e-07, 1.12333083e-07]],\n",
      "      dtype=float32), array([[0.12958762, 0.08066732],\n",
      "       [1.003472  , 2.6967404 ],\n",
      "       [1.8937197 , 0.98326576]], dtype=float32)]\n",
      "발생지시군구 : 달서구\n",
      "\n",
      "발생지시군구 : 북구\n",
      "\n",
      "발생지시군구 : 송파구\n",
      "\n",
      "['중상자수', '경상자수'] : [0.12958762 0.08066732]\n",
      "['중상자수', '경상자수'] : [1.003472  2.6967404]\n",
      "['중상자수', '경상자수'] : [1.8937197  0.98326576]\n"
     ]
    }
   ],
   "source": [
    "mix_case(Case10, 1, 32, 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 1)\n",
      "1\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 3s 152us/step - loss: 3.7074 - cat_output_loss: 3.5869 - num_output_loss: 0.1205 - cat_output_acc: 0.4202 - num_output_acc: 0.9375 - val_loss: 3.6535 - val_cat_output_loss: 3.4586 - val_num_output_loss: 0.1949 - val_cat_output_acc: 0.3526 - val_num_output_acc: 0.9631\n",
      "Epoch 2/50\n",
      " 3072/20029 [===>..........................] - ETA: 0s - loss: 3.4750 - cat_output_loss: 3.4016 - num_output_loss: 0.0734 - cat_output_acc: 0.4118 - num_output_acc: 0.9593"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:1043: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_num_output_acc,val_cat_output_loss,val_num_output_loss,lr,val_cat_output_acc,num_output_acc,num_output_loss,val_loss,loss,cat_output_loss,cat_output_acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20029/20029 [==============================] - 1s 61us/step - loss: 3.4933 - cat_output_loss: 3.4030 - num_output_loss: 0.0903 - cat_output_acc: 0.4443 - num_output_acc: 0.9596 - val_loss: 3.4839 - val_cat_output_loss: 3.3793 - val_num_output_loss: 0.1046 - val_cat_output_acc: 0.5331 - val_num_output_acc: 0.9629\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 59us/step - loss: 3.4324 - cat_output_loss: 3.3519 - num_output_loss: 0.0805 - cat_output_acc: 0.4633 - num_output_acc: 0.9646 - val_loss: 3.4805 - val_cat_output_loss: 3.3927 - val_num_output_loss: 0.0877 - val_cat_output_acc: 0.5673 - val_num_output_acc: 0.9629\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 60us/step - loss: 3.3898 - cat_output_loss: 3.3116 - num_output_loss: 0.0781 - cat_output_acc: 0.4843 - num_output_acc: 0.9658 - val_loss: 3.4435 - val_cat_output_loss: 3.3777 - val_num_output_loss: 0.0658 - val_cat_output_acc: 0.4740 - val_num_output_acc: 0.9629\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 61us/step - loss: 3.3487 - cat_output_loss: 3.2760 - num_output_loss: 0.0727 - cat_output_acc: 0.4824 - num_output_acc: 0.9662 - val_loss: 3.4494 - val_cat_output_loss: 3.3839 - val_num_output_loss: 0.0655 - val_cat_output_acc: 0.5298 - val_num_output_acc: 0.9623\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 60us/step - loss: 3.3209 - cat_output_loss: 3.2484 - num_output_loss: 0.0725 - cat_output_acc: 0.4918 - num_output_acc: 0.9665 - val_loss: 3.4468 - val_cat_output_loss: 3.3833 - val_num_output_loss: 0.0634 - val_cat_output_acc: 0.5633 - val_num_output_acc: 0.9629\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 61us/step - loss: 3.2746 - cat_output_loss: 3.2045 - num_output_loss: 0.0700 - cat_output_acc: 0.5032 - num_output_acc: 0.9668 - val_loss: 3.4674 - val_cat_output_loss: 3.3941 - val_num_output_loss: 0.0733 - val_cat_output_acc: 0.4321 - val_num_output_acc: 0.9625\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 60us/step - loss: 3.2370 - cat_output_loss: 3.1687 - num_output_loss: 0.0683 - cat_output_acc: 0.5134 - num_output_acc: 0.9667 - val_loss: 3.4853 - val_cat_output_loss: 3.4190 - val_num_output_loss: 0.0663 - val_cat_output_acc: 0.5302 - val_num_output_acc: 0.9629\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 61us/step - loss: 3.1936 - cat_output_loss: 3.1244 - num_output_loss: 0.0691 - cat_output_acc: 0.5238 - num_output_acc: 0.9665 - val_loss: 3.5073 - val_cat_output_loss: 3.4473 - val_num_output_loss: 0.0600 - val_cat_output_acc: 0.4972 - val_num_output_acc: 0.9623\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 62us/step - loss: 3.1545 - cat_output_loss: 3.0865 - num_output_loss: 0.0680 - cat_output_acc: 0.5176 - num_output_acc: 0.9664 - val_loss: 3.5116 - val_cat_output_loss: 3.4523 - val_num_output_loss: 0.0593 - val_cat_output_acc: 0.3490 - val_num_output_acc: 0.9629\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 61us/step - loss: 3.1141 - cat_output_loss: 3.0460 - num_output_loss: 0.0681 - cat_output_acc: 0.5171 - num_output_acc: 0.9660 - val_loss: 3.5424 - val_cat_output_loss: 3.4782 - val_num_output_loss: 0.0642 - val_cat_output_acc: 0.3468 - val_num_output_acc: 0.9629\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 61us/step - loss: 3.0712 - cat_output_loss: 3.0044 - num_output_loss: 0.0668 - cat_output_acc: 0.5192 - num_output_acc: 0.9670 - val_loss: 3.5703 - val_cat_output_loss: 3.5068 - val_num_output_loss: 0.0636 - val_cat_output_acc: 0.4770 - val_num_output_acc: 0.9629\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 63us/step - loss: 3.0384 - cat_output_loss: 2.9708 - num_output_loss: 0.0676 - cat_output_acc: 0.5355 - num_output_acc: 0.9666 - val_loss: 3.6145 - val_cat_output_loss: 3.5516 - val_num_output_loss: 0.0629 - val_cat_output_acc: 0.4910 - val_num_output_acc: 0.9629\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 62us/step - loss: 2.9873 - cat_output_loss: 2.9209 - num_output_loss: 0.0664 - cat_output_acc: 0.5249 - num_output_acc: 0.9664 - val_loss: 3.6399 - val_cat_output_loss: 3.5788 - val_num_output_loss: 0.0611 - val_cat_output_acc: 0.4732 - val_num_output_acc: 0.9629\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 1s 61us/step - loss: 2.9447 - cat_output_loss: 2.8788 - num_output_loss: 0.0659 - cat_output_acc: 0.5207 - num_output_acc: 0.9667 - val_loss: 3.6597 - val_cat_output_loss: 3.5979 - val_num_output_loss: 0.0619 - val_cat_output_acc: 0.3888 - val_num_output_acc: 0.9629\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 1s 63us/step - loss: 2.9063 - cat_output_loss: 2.8406 - num_output_loss: 0.0657 - cat_output_acc: 0.5249 - num_output_acc: 0.9663 - val_loss: 3.7255 - val_cat_output_loss: 3.6649 - val_num_output_loss: 0.0607 - val_cat_output_acc: 0.4103 - val_num_output_acc: 0.9629\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 1s 61us/step - loss: 2.8742 - cat_output_loss: 2.8080 - num_output_loss: 0.0662 - cat_output_acc: 0.5200 - num_output_acc: 0.9667 - val_loss: 3.7433 - val_cat_output_loss: 3.6835 - val_num_output_loss: 0.0599 - val_cat_output_acc: 0.3956 - val_num_output_acc: 0.9629\n",
      "Epoch 18/50\n",
      "20029/20029 [==============================] - 1s 69us/step - loss: 2.8402 - cat_output_loss: 2.7749 - num_output_loss: 0.0653 - cat_output_acc: 0.5127 - num_output_acc: 0.9669 - val_loss: 3.7201 - val_cat_output_loss: 3.6609 - val_num_output_loss: 0.0592 - val_cat_output_acc: 0.4207 - val_num_output_acc: 0.9629\n",
      "Epoch 19/50\n",
      "20029/20029 [==============================] - 1s 69us/step - loss: 2.8008 - cat_output_loss: 2.7371 - num_output_loss: 0.0637 - cat_output_acc: 0.5105 - num_output_acc: 0.9666 - val_loss: 3.8068 - val_cat_output_loss: 3.7478 - val_num_output_loss: 0.0590 - val_cat_output_acc: 0.4696 - val_num_output_acc: 0.9625\n",
      "Epoch 20/50\n",
      "20029/20029 [==============================] - 1s 67us/step - loss: 2.7614 - cat_output_loss: 2.6987 - num_output_loss: 0.0627 - cat_output_acc: 0.5157 - num_output_acc: 0.9665 - val_loss: 3.8306 - val_cat_output_loss: 3.7702 - val_num_output_loss: 0.0604 - val_cat_output_acc: 0.4327 - val_num_output_acc: 0.9627\n",
      "Epoch 21/50\n",
      "20029/20029 [==============================] - 1s 70us/step - loss: 2.7372 - cat_output_loss: 2.6736 - num_output_loss: 0.0637 - cat_output_acc: 0.5056 - num_output_acc: 0.9666 - val_loss: 3.9151 - val_cat_output_loss: 3.8560 - val_num_output_loss: 0.0590 - val_cat_output_acc: 0.4401 - val_num_output_acc: 0.9617\n",
      "Epoch 22/50\n",
      "20029/20029 [==============================] - 1s 71us/step - loss: 2.7123 - cat_output_loss: 2.6494 - num_output_loss: 0.0629 - cat_output_acc: 0.5156 - num_output_acc: 0.9664 - val_loss: 3.9515 - val_cat_output_loss: 3.8912 - val_num_output_loss: 0.0604 - val_cat_output_acc: 0.3768 - val_num_output_acc: 0.9601\n",
      "Epoch 23/50\n",
      "20029/20029 [==============================] - 1s 63us/step - loss: 2.6814 - cat_output_loss: 2.6178 - num_output_loss: 0.0635 - cat_output_acc: 0.5195 - num_output_acc: 0.9662 - val_loss: 3.9191 - val_cat_output_loss: 3.8566 - val_num_output_loss: 0.0625 - val_cat_output_acc: 0.4095 - val_num_output_acc: 0.9633\n",
      "Epoch 24/50\n",
      "20029/20029 [==============================] - 1s 64us/step - loss: 2.6606 - cat_output_loss: 2.5982 - num_output_loss: 0.0624 - cat_output_acc: 0.4983 - num_output_acc: 0.9664 - val_loss: 4.0084 - val_cat_output_loss: 3.9467 - val_num_output_loss: 0.0617 - val_cat_output_acc: 0.4329 - val_num_output_acc: 0.9595\n",
      "X=[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 1. 0.]], Predicted=[array([[3.9919529e-02, 4.1736820e-01, 5.3462753e-04, 1.2513230e-11,\n",
      "        5.4217243e-01, 2.7503158e-06, 1.0881605e-06, 2.6242952e-09,\n",
      "        1.2828428e-06, 1.1407924e-08, 1.1321133e-12, 1.6087229e-08,\n",
      "        1.2695653e-14, 8.6143020e-10],\n",
      "       [5.0423205e-01, 1.4917097e-02, 1.8248391e-01, 1.4607179e-03,\n",
      "        7.0394808e-04, 2.4727004e-04, 9.1196671e-06, 1.4172661e-01,\n",
      "        1.4319207e-04, 1.5402877e-01, 7.3278466e-07, 1.8472319e-05,\n",
      "        1.8751397e-08, 2.8074801e-05]], dtype=float32), array([[0.9581888],\n",
      "       [0.9564483]], dtype=float32)]\n",
      "주야 : 주간\n",
      "당사자종별_1당_대분류 : 화물차\n",
      "\n",
      "주야 : 야간\n",
      "당사자종별_1당_대분류 : 승용차\n",
      "\n",
      "['사망자수'] : [0.9581888]\n",
      "['사망자수'] : [0.9564483]\n"
     ]
    }
   ],
   "source": [
    "mix_case(Case11, 2, 45, 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 1)\n",
      "1\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 3s 161us/step - loss: 3.8927 - cat_output_loss: 2.8815 - num_output_loss: 1.0112 - cat_output_acc: 0.1969 - num_output_acc: 0.7286 - val_loss: 3.6186 - val_cat_output_loss: 2.5954 - val_num_output_loss: 1.0231 - val_cat_output_acc: 0.1382 - val_num_output_acc: 0.8189\n",
      "Epoch 2/50\n",
      " 3072/20029 [===>..........................] - ETA: 0s - loss: 4.6016 - cat_output_loss: 2.5638 - num_output_loss: 2.0379 - cat_output_acc: 0.1901 - num_output_acc: 0.7809"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:1043: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_num_output_acc,val_cat_output_loss,val_num_output_loss,lr,val_cat_output_acc,num_output_acc,num_output_loss,val_loss,loss,cat_output_loss,cat_output_acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20029/20029 [==============================] - 1s 62us/step - loss: 3.5148 - cat_output_loss: 2.5432 - num_output_loss: 0.9716 - cat_output_acc: 0.1797 - num_output_acc: 0.7930 - val_loss: 3.3953 - val_cat_output_loss: 2.5001 - val_num_output_loss: 0.8952 - val_cat_output_acc: 0.0767 - val_num_output_acc: 0.7746\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 66us/step - loss: 3.4491 - cat_output_loss: 2.4859 - num_output_loss: 0.9632 - cat_output_acc: 0.1690 - num_output_acc: 0.8001 - val_loss: 3.4088 - val_cat_output_loss: 2.4858 - val_num_output_loss: 0.9230 - val_cat_output_acc: 0.1006 - val_num_output_acc: 0.7909\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 63us/step - loss: 3.4276 - cat_output_loss: 2.4559 - num_output_loss: 0.9718 - cat_output_acc: 0.1637 - num_output_acc: 0.8093 - val_loss: 3.4504 - val_cat_output_loss: 2.4945 - val_num_output_loss: 0.9559 - val_cat_output_acc: 0.1050 - val_num_output_acc: 0.7825\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 62us/step - loss: 3.2919 - cat_output_loss: 2.4330 - num_output_loss: 0.8590 - cat_output_acc: 0.1633 - num_output_acc: 0.8105 - val_loss: 3.6772 - val_cat_output_loss: 2.5064 - val_num_output_loss: 1.1709 - val_cat_output_acc: 0.1324 - val_num_output_acc: 0.8185\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 66us/step - loss: 3.3390 - cat_output_loss: 2.4416 - num_output_loss: 0.8974 - cat_output_acc: 0.1725 - num_output_acc: 0.8058 - val_loss: 3.3477 - val_cat_output_loss: 2.4846 - val_num_output_loss: 0.8631 - val_cat_output_acc: 0.1036 - val_num_output_acc: 0.8135\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 67us/step - loss: 3.1976 - cat_output_loss: 2.4151 - num_output_loss: 0.7825 - cat_output_acc: 0.1659 - num_output_acc: 0.8137 - val_loss: 3.3484 - val_cat_output_loss: 2.4765 - val_num_output_loss: 0.8719 - val_cat_output_acc: 0.1182 - val_num_output_acc: 0.7778\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 65us/step - loss: 3.2705 - cat_output_loss: 2.3955 - num_output_loss: 0.8750 - cat_output_acc: 0.1658 - num_output_acc: 0.8125 - val_loss: 4.4185 - val_cat_output_loss: 2.4748 - val_num_output_loss: 1.9437 - val_cat_output_acc: 0.1198 - val_num_output_acc: 0.8007\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 63us/step - loss: 3.1567 - cat_output_loss: 2.3830 - num_output_loss: 0.7737 - cat_output_acc: 0.1693 - num_output_acc: 0.8170 - val_loss: 3.3657 - val_cat_output_loss: 2.4856 - val_num_output_loss: 0.8801 - val_cat_output_acc: 0.1270 - val_num_output_acc: 0.8035\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 66us/step - loss: 3.0268 - cat_output_loss: 2.3598 - num_output_loss: 0.6670 - cat_output_acc: 0.1695 - num_output_acc: 0.8156 - val_loss: 3.5221 - val_cat_output_loss: 2.5048 - val_num_output_loss: 1.0173 - val_cat_output_acc: 0.1617 - val_num_output_acc: 0.8059\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 65us/step - loss: 2.8999 - cat_output_loss: 2.3542 - num_output_loss: 0.5457 - cat_output_acc: 0.1690 - num_output_acc: 0.8222 - val_loss: 3.6765 - val_cat_output_loss: 2.5116 - val_num_output_loss: 1.1649 - val_cat_output_acc: 0.1094 - val_num_output_acc: 0.7804\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 63us/step - loss: 2.9473 - cat_output_loss: 2.3375 - num_output_loss: 0.6098 - cat_output_acc: 0.1769 - num_output_acc: 0.8205 - val_loss: 3.5699 - val_cat_output_loss: 2.5174 - val_num_output_loss: 1.0525 - val_cat_output_acc: 0.1066 - val_num_output_acc: 0.8195\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 62us/step - loss: 2.9941 - cat_output_loss: 2.3224 - num_output_loss: 0.6717 - cat_output_acc: 0.1718 - num_output_acc: 0.8172 - val_loss: 3.6039 - val_cat_output_loss: 2.5185 - val_num_output_loss: 1.0854 - val_cat_output_acc: 0.1062 - val_num_output_acc: 0.8001\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 65us/step - loss: 3.0077 - cat_output_loss: 2.3125 - num_output_loss: 0.6951 - cat_output_acc: 0.1820 - num_output_acc: 0.8209 - val_loss: 3.4471 - val_cat_output_loss: 2.5159 - val_num_output_loss: 0.9312 - val_cat_output_acc: 0.1320 - val_num_output_acc: 0.7993\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 1s 67us/step - loss: 2.8603 - cat_output_loss: 2.2934 - num_output_loss: 0.5669 - cat_output_acc: 0.1857 - num_output_acc: 0.8274 - val_loss: 3.5767 - val_cat_output_loss: 2.5196 - val_num_output_loss: 1.0571 - val_cat_output_acc: 0.1024 - val_num_output_acc: 0.8113\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 1s 65us/step - loss: 2.8235 - cat_output_loss: 2.2847 - num_output_loss: 0.5388 - cat_output_acc: 0.1908 - num_output_acc: 0.8288 - val_loss: 3.5725 - val_cat_output_loss: 2.5556 - val_num_output_loss: 1.0169 - val_cat_output_acc: 0.1224 - val_num_output_acc: 0.8163\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 1s 64us/step - loss: 2.7256 - cat_output_loss: 2.2695 - num_output_loss: 0.4561 - cat_output_acc: 0.1923 - num_output_acc: 0.8276 - val_loss: 3.5169 - val_cat_output_loss: 2.5548 - val_num_output_loss: 0.9621 - val_cat_output_acc: 0.1613 - val_num_output_acc: 0.8025\n",
      "Epoch 18/50\n",
      "20029/20029 [==============================] - 1s 64us/step - loss: 2.7461 - cat_output_loss: 2.2483 - num_output_loss: 0.4979 - cat_output_acc: 0.1918 - num_output_acc: 0.8321 - val_loss: 3.5035 - val_cat_output_loss: 2.5838 - val_num_output_loss: 0.9196 - val_cat_output_acc: 0.1326 - val_num_output_acc: 0.7909\n",
      "Epoch 19/50\n",
      "20029/20029 [==============================] - 1s 64us/step - loss: 2.9253 - cat_output_loss: 2.2357 - num_output_loss: 0.6896 - cat_output_acc: 0.1995 - num_output_acc: 0.8337 - val_loss: 3.6668 - val_cat_output_loss: 2.6101 - val_num_output_loss: 1.0567 - val_cat_output_acc: 0.1623 - val_num_output_acc: 0.7875\n",
      "Epoch 20/50\n",
      "20029/20029 [==============================] - 1s 63us/step - loss: 2.7045 - cat_output_loss: 2.2241 - num_output_loss: 0.4804 - cat_output_acc: 0.2028 - num_output_acc: 0.8333 - val_loss: 3.5812 - val_cat_output_loss: 2.6057 - val_num_output_loss: 0.9755 - val_cat_output_acc: 0.1480 - val_num_output_acc: 0.8091\n",
      "Epoch 21/50\n",
      "20029/20029 [==============================] - 1s 66us/step - loss: 2.6681 - cat_output_loss: 2.2055 - num_output_loss: 0.4626 - cat_output_acc: 0.2115 - num_output_acc: 0.8329 - val_loss: 3.6573 - val_cat_output_loss: 2.6223 - val_num_output_loss: 1.0350 - val_cat_output_acc: 0.1166 - val_num_output_acc: 0.8035\n",
      "Epoch 22/50\n",
      "20029/20029 [==============================] - 1s 65us/step - loss: 2.5999 - cat_output_loss: 2.1874 - num_output_loss: 0.4125 - cat_output_acc: 0.2119 - num_output_acc: 0.8363 - val_loss: 3.5658 - val_cat_output_loss: 2.6419 - val_num_output_loss: 0.9239 - val_cat_output_acc: 0.1396 - val_num_output_acc: 0.7937\n",
      "Epoch 23/50\n",
      "20029/20029 [==============================] - 1s 64us/step - loss: 2.5933 - cat_output_loss: 2.1718 - num_output_loss: 0.4215 - cat_output_acc: 0.2111 - num_output_acc: 0.8371 - val_loss: 3.7006 - val_cat_output_loss: 2.6508 - val_num_output_loss: 1.0499 - val_cat_output_acc: 0.0855 - val_num_output_acc: 0.8089\n",
      "Epoch 24/50\n",
      "20029/20029 [==============================] - 1s 63us/step - loss: 2.5357 - cat_output_loss: 2.1588 - num_output_loss: 0.3770 - cat_output_acc: 0.2153 - num_output_acc: 0.8380 - val_loss: 3.6509 - val_cat_output_loss: 2.6863 - val_num_output_loss: 0.9646 - val_cat_output_acc: 0.1142 - val_num_output_acc: 0.8049\n",
      "Epoch 25/50\n",
      "20029/20029 [==============================] - 1s 61us/step - loss: 2.4570 - cat_output_loss: 2.1417 - num_output_loss: 0.3153 - cat_output_acc: 0.2190 - num_output_acc: 0.8414 - val_loss: 3.7290 - val_cat_output_loss: 2.7394 - val_num_output_loss: 0.9896 - val_cat_output_acc: 0.1679 - val_num_output_acc: 0.8099\n",
      "Epoch 26/50\n",
      "20029/20029 [==============================] - 1s 62us/step - loss: 2.4787 - cat_output_loss: 2.1291 - num_output_loss: 0.3495 - cat_output_acc: 0.2315 - num_output_acc: 0.8406 - val_loss: 3.5885 - val_cat_output_loss: 2.7111 - val_num_output_loss: 0.8773 - val_cat_output_acc: 0.1390 - val_num_output_acc: 0.7869\n",
      "X=[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 2. 9.\n",
      "  1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0.]], Predicted=[array([[1.8158238e-01, 3.6132705e-01, 5.4500779e-05, 4.3263716e-01,\n",
      "        2.3567105e-02, 1.3122079e-05, 1.5746974e-07, 7.4651756e-04,\n",
      "        7.7340900e-07, 2.2608853e-07, 3.8286430e-06, 6.1307060e-06,\n",
      "        7.3323463e-06, 3.3940334e-05, 8.5073334e-06, 2.0419975e-06,\n",
      "        2.6205129e-07, 8.9363448e-06],\n",
      "       [7.0121557e-02, 4.6468037e-01, 4.6175987e-01, 1.9989248e-11,\n",
      "        1.3897270e-14, 1.2143768e-03, 9.1689954e-11, 5.4535468e-18,\n",
      "        9.3756098e-14, 2.7189091e-07, 7.4809811e-17, 2.2235652e-03,\n",
      "        4.7874146e-14, 8.4472040e-13, 3.7584346e-08, 2.4066471e-11,\n",
      "        5.7691617e-15, 4.0426148e-12],\n",
      "       [1.6703665e-02, 4.9234432e-01, 3.5775229e-06, 4.8770848e-01,\n",
      "        3.2357825e-03, 1.8052124e-06, 1.4098359e-10, 1.5575905e-06,\n",
      "        2.4894884e-09, 2.1994387e-10, 2.1766793e-08, 3.7426724e-07,\n",
      "        1.2718436e-07, 2.6450149e-07, 4.1040206e-08, 4.5015600e-08,\n",
      "        2.8604352e-10, 3.2338349e-08]], dtype=float32), array([[0.11767267],\n",
      "       [7.009982  ],\n",
      "       [0.13696983]], dtype=float32)]\n",
      "주야 : 주간\n",
      "도로형태 : 교차로내\n",
      "\n",
      "주야 : 주간\n",
      "도로형태 : 기타단일로\n",
      "\n",
      "주야 : 주간\n",
      "도로형태 : 교차로내\n",
      "\n",
      "['중상자수'] : [0.11767267]\n",
      "['중상자수'] : [7.009982]\n",
      "['중상자수'] : [0.13696983]\n"
     ]
    }
   ],
   "source": [
    "mix_case(Case12, 2, 47, 49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"968pt\" viewBox=\"0.00 0.00 537.00 968.00\" width=\"537pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 964)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-964 533,-964 533,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139908656648320 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139908656648320</title>\n",
       "<polygon fill=\"none\" points=\"132.5,-913.5 132.5,-959.5 404.5,-959.5 404.5,-913.5 132.5,-913.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-932.8\">cat_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"266.5,-913.5 266.5,-959.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"294\" y=\"-944.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"266.5,-936.5 321.5,-936.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"294\" y=\"-921.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"321.5,-913.5 321.5,-959.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363\" y=\"-944.3\">(None, 123)</text>\n",
       "<polyline fill=\"none\" points=\"321.5,-936.5 404.5,-936.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"363\" y=\"-921.3\">(None, 123)</text>\n",
       "</g>\n",
       "<!-- 139908656648264 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139908656648264</title>\n",
       "<polygon fill=\"none\" points=\"145,-830.5 145,-876.5 392,-876.5 392,-830.5 145,-830.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-849.8\">dense_90: Dense</text>\n",
       "<polyline fill=\"none\" points=\"254,-830.5 254,-876.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"281.5\" y=\"-861.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"254,-853.5 309,-853.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"281.5\" y=\"-838.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"309,-830.5 309,-876.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"350.5\" y=\"-861.3\">(None, 123)</text>\n",
       "<polyline fill=\"none\" points=\"309,-853.5 392,-853.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"350.5\" y=\"-838.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139908656648320&#45;&gt;139908656648264 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139908656648320-&gt;139908656648264</title>\n",
       "<path d=\"M268.5,-913.366C268.5,-905.152 268.5,-895.658 268.5,-886.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"272,-886.607 268.5,-876.607 265,-886.607 272,-886.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139908656648488 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139908656648488</title>\n",
       "<polygon fill=\"none\" points=\"134,-747.5 134,-793.5 403,-793.5 403,-747.5 134,-747.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-766.8\">dropout_90: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"265,-747.5 265,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"265,-770.5 320,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"320,-747.5 320,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-778.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"320,-770.5 403,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-755.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139908656648264&#45;&gt;139908656648488 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139908656648264-&gt;139908656648488</title>\n",
       "<path d=\"M268.5,-830.366C268.5,-822.152 268.5,-812.658 268.5,-803.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"272,-803.607 268.5,-793.607 265,-803.607 272,-803.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139908656649440 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139908656649440</title>\n",
       "<polygon fill=\"none\" points=\"145,-664.5 145,-710.5 392,-710.5 392,-664.5 145,-664.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-683.8\">dense_91: Dense</text>\n",
       "<polyline fill=\"none\" points=\"254,-664.5 254,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"281.5\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"254,-687.5 309,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"281.5\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"309,-664.5 309,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"350.5\" y=\"-695.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"309,-687.5 392,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"350.5\" y=\"-672.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139908656648488&#45;&gt;139908656649440 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139908656648488-&gt;139908656649440</title>\n",
       "<path d=\"M268.5,-747.366C268.5,-739.152 268.5,-729.658 268.5,-720.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"272,-720.607 268.5,-710.607 265,-720.607 272,-720.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139908656649608 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139908656649608</title>\n",
       "<polygon fill=\"none\" points=\"134,-581.5 134,-627.5 403,-627.5 403,-581.5 134,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-600.8\">dropout_91: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"265,-581.5 265,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"265,-604.5 320,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"320,-581.5 320,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-612.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"320,-604.5 403,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-589.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139908656649440&#45;&gt;139908656649608 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139908656649440-&gt;139908656649608</title>\n",
       "<path d=\"M268.5,-664.366C268.5,-656.152 268.5,-646.658 268.5,-637.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"272,-637.607 268.5,-627.607 265,-637.607 272,-637.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139908656251568 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139908656251568</title>\n",
       "<polygon fill=\"none\" points=\"145,-498.5 145,-544.5 392,-544.5 392,-498.5 145,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-517.8\">dense_92: Dense</text>\n",
       "<polyline fill=\"none\" points=\"254,-498.5 254,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"281.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"254,-521.5 309,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"281.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"309,-498.5 309,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"350.5\" y=\"-529.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"309,-521.5 392,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"350.5\" y=\"-506.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139908656649608&#45;&gt;139908656251568 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139908656649608-&gt;139908656251568</title>\n",
       "<path d=\"M268.5,-581.366C268.5,-573.152 268.5,-563.658 268.5,-554.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"272,-554.607 268.5,-544.607 265,-554.607 272,-554.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139904049697176 -->\n",
       "<g class=\"node\" id=\"node7\"><title>139904049697176</title>\n",
       "<polygon fill=\"none\" points=\"134,-415.5 134,-461.5 403,-461.5 403,-415.5 134,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-434.8\">dropout_92: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"265,-415.5 265,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"265,-438.5 320,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"320,-415.5 320,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-446.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"320,-438.5 403,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-423.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139908656251568&#45;&gt;139904049697176 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>139908656251568-&gt;139904049697176</title>\n",
       "<path d=\"M268.5,-498.366C268.5,-490.152 268.5,-480.658 268.5,-471.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"272,-471.607 268.5,-461.607 265,-471.607 272,-471.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139908656233608 -->\n",
       "<g class=\"node\" id=\"node8\"><title>139908656233608</title>\n",
       "<polygon fill=\"none\" points=\"145,-332.5 145,-378.5 392,-378.5 392,-332.5 145,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-351.8\">dense_93: Dense</text>\n",
       "<polyline fill=\"none\" points=\"254,-332.5 254,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"281.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"254,-355.5 309,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"281.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"309,-332.5 309,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"350.5\" y=\"-363.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"309,-355.5 392,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"350.5\" y=\"-340.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139904049697176&#45;&gt;139908656233608 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>139904049697176-&gt;139908656233608</title>\n",
       "<path d=\"M268.5,-415.366C268.5,-407.152 268.5,-397.658 268.5,-388.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"272,-388.607 268.5,-378.607 265,-388.607 272,-388.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139908656233664 -->\n",
       "<g class=\"node\" id=\"node9\"><title>139908656233664</title>\n",
       "<polygon fill=\"none\" points=\"134,-249.5 134,-295.5 403,-295.5 403,-249.5 134,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-268.8\">dropout_93: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"265,-249.5 265,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"265,-272.5 320,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"292.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"320,-249.5 320,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-280.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"320,-272.5 403,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"361.5\" y=\"-257.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139908656233608&#45;&gt;139908656233664 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>139908656233608-&gt;139908656233664</title>\n",
       "<path d=\"M268.5,-332.366C268.5,-324.152 268.5,-314.658 268.5,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"272,-305.607 268.5,-295.607 265,-305.607 272,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139908656731864 -->\n",
       "<g class=\"node\" id=\"node10\"><title>139908656731864</title>\n",
       "<polygon fill=\"none\" points=\"11,-166.5 11,-212.5 258,-212.5 258,-166.5 11,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65.5\" y=\"-185.8\">dense_94: Dense</text>\n",
       "<polyline fill=\"none\" points=\"120,-166.5 120,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"120,-189.5 175,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"175,-166.5 175,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"216.5\" y=\"-197.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"175,-189.5 258,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"216.5\" y=\"-174.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139908656233664&#45;&gt;139908656731864 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>139908656233664-&gt;139908656731864</title>\n",
       "<path d=\"M231.884,-249.366C215.783,-239.634 196.712,-228.106 179.733,-217.842\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"181.44,-214.785 171.072,-212.607 177.819,-220.775 181.44,-214.785\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139908656730352 -->\n",
       "<g class=\"node\" id=\"node12\"><title>139908656730352</title>\n",
       "<polygon fill=\"none\" points=\"276,-166.5 276,-212.5 529,-212.5 529,-166.5 276,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-185.8\">cat_output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"391,-166.5 391,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"418.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"391,-189.5 446,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"418.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"446,-166.5 446,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"487.5\" y=\"-197.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"446,-189.5 529,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"487.5\" y=\"-174.3\">(None, 208)</text>\n",
       "</g>\n",
       "<!-- 139908656233664&#45;&gt;139908656730352 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>139908656233664-&gt;139908656730352</title>\n",
       "<path d=\"M305.116,-249.366C321.217,-239.634 340.288,-228.106 357.267,-217.842\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"359.181,-220.775 365.928,-212.607 355.56,-214.785 359.181,-220.775\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139908655592392 -->\n",
       "<g class=\"node\" id=\"node11\"><title>139908655592392</title>\n",
       "<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 269,-129.5 269,-83.5 0,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65.5\" y=\"-102.8\">dropout_94: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"131,-83.5 131,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"158.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"131,-106.5 186,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"158.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"186,-83.5 186,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"227.5\" y=\"-114.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"186,-106.5 269,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"227.5\" y=\"-91.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139908656731864&#45;&gt;139908655592392 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>139908656731864-&gt;139908655592392</title>\n",
       "<path d=\"M134.5,-166.366C134.5,-158.152 134.5,-148.658 134.5,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"138,-139.607 134.5,-129.607 131,-139.607 138,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139908655271272 -->\n",
       "<g class=\"node\" id=\"node13\"><title>139908655271272</title>\n",
       "<polygon fill=\"none\" points=\"3.5,-0.5 3.5,-46.5 265.5,-46.5 265.5,-0.5 3.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65.5\" y=\"-19.8\">num_output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"127.5,-0.5 127.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"127.5,-23.5 182.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"155\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"182.5,-0.5 182.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"224\" y=\"-31.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"182.5,-23.5 265.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"224\" y=\"-8.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 139908655592392&#45;&gt;139908655271272 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>139908655592392-&gt;139908655271272</title>\n",
       "<path d=\"M134.5,-83.3664C134.5,-75.1516 134.5,-65.6579 134.5,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"138,-56.6068 134.5,-46.6068 131,-56.6069 138,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set result array to each cases\n",
    "def setResult(arr, predict, case):\n",
    "\n",
    "    result_arr = arr\n",
    "    if case == 'Case1':\n",
    "        result_arr[:, 2] = predict[:, 0]\n",
    "        result_arr[:, 5] = predict[:, 1]\n",
    "\n",
    "        result_arr[:, 3] = result_arr[:, 2].sum() + result_arr[:, 4:6].sum()\n",
    "\n",
    "    print(result_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 사용예\n",
    "\n",
    "# x_test = pd.read_csv('./samsung_dataset/test_kor.csv',encoding='cp949')\n",
    "# print(x_test.loc[:0].values)\n",
    "\n",
    "# arr = x_test.loc[:0].values\n",
    "# # arr[:, 2] = predict[0]\n",
    "# print(arr[:, 2])\n",
    "\n",
    "# predict = np.array([[1.0412397 , 0.6131577 ]])\n",
    "# current_case = 'Case1'\n",
    "\n",
    "# a = MyModule()\n",
    "# a.setResult(arr, predict, current_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setResult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
