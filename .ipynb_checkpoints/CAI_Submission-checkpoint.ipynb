{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 사용할 패키지 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf) # print all numpy values\n",
    "\n",
    "# For deep learning model \n",
    "import keras\n",
    "from keras.layers import Dense, Input, concatenate, Dropout\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras import metrics\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비하기 - 학습 데이터, 테스트 데이터 로드\n",
    "categorical = ['발생지시도', '발생지시군구', '사고유형_대분류', '사고유형_중분류', '법규위반', \n",
    "            '도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류', '주야', '요일']\n",
    "numerical = ['사상자수', '사망자수', '중상자수', '경상자수','부상신고자수']\n",
    "\n",
    "x_train_num = pd.read_csv('./교통사망사고정보/Kor_Train_교통사망사고정보(12.1~17.6).csv',encoding='cp949', usecols=numerical)\n",
    "\n",
    "x_train_cat = pd.read_csv('./교통사망사고정보/Kor_Train_교통사망사고정보(12.1~17.6).csv',encoding='cp949', usecols=categorical)\n",
    "\n",
    "x_test = pd.read_csv('./test_kor.csv', encoding='cp949')\n",
    "\n",
    "x_test_num = pd.read_csv('./test_kor.csv', encoding='cp949', usecols=numerical)\n",
    "\n",
    "x_test_cat = pd.read_csv('./test_kor.csv', encoding='cp949', usecols=categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iron/.local/lib/python3.5/site-packages/ipykernel_launcher.py:8: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  \n",
      "/home/iron/.local/lib/python3.5/site-packages/ipykernel_launcher.py:9: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding\n",
    "\n",
    "# 모든 존재하는 column의 one hot encoding을 위해 train과 test의 카테고리 통합\n",
    "all_data = pd.concat((x_test_cat.dropna(), x_train_cat))\n",
    "\n",
    "# get_dummies가 가능하도록 type 설정\n",
    "for column in all_data.select_dtypes(include=[np.object]).columns:\n",
    "    x_train_cat[column] = x_train_cat[column].astype('category', categories = all_data[column].unique())\n",
    "    x_test_cat[column] = x_test_cat[column].astype('category', categories = all_data[column].unique())\n",
    "\n",
    "# 모든 column에 대해 one hot encoding 수행\n",
    "x_train_cat = pd.get_dummies(data=x_train_cat)\n",
    "x_test_cat = pd.get_dummies(data=x_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 328)\n",
      "(25037, 5)\n",
      "(50, 328)\n",
      "(50, 5)\n"
     ]
    }
   ],
   "source": [
    "# Train Data Shape check\n",
    "print(x_train_cat.shape)\n",
    "print(x_train_num.shape)\n",
    "\n",
    "# Test Data Shape check\n",
    "print(x_test_cat.shape)\n",
    "print(x_test_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test file에 있는 값을 result file에 저장\n",
    "\n",
    "def save_result(sheet_name_csv):\n",
    "    result_file_address = './result_kor.csv'\n",
    "    test_file = pd.read_csv(sheet_name_csv, encoding='cp949', names= [chr(y) for y in range(ord('A'),ord('P')+1)])\n",
    "    result_file = pd.read_csv(result_file_address, encoding='cp949')\n",
    "    print(sheet_name_csv)\n",
    "    \n",
    "    cols = result_file['열'].astype('str').values\n",
    "    rows = result_file['행'].astype('str').astype('int').values\n",
    "    vals = result_file['값'].astype('str').values\n",
    "\n",
    "    for i, (row, col) in enumerate(zip(rows, cols)):      \n",
    "        vals[i] = test_file[col][int(row)-1]\n",
    "\n",
    "\n",
    "    with open(result_file_address, 'wb+') as f:\n",
    "        np.savetxt(f,  np.c_[rows,cols,vals],  delimiter=\",\", fmt='%s', encoding='cp949', header='행,열,값', comments='')\n",
    "    print('Save Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters \n",
    "epochs = 1\n",
    "batch_size = 128\n",
    "optimizer = 'adam' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric case를 학습하고 예상값을 return\n",
    "\n",
    "# case: column명 array\n",
    "# start: 예측할 시작 row\n",
    "# end: 예측할 마지막 row\n",
    "def numeric_case(case, start, end):\n",
    "    \n",
    "    K.clear_session()\n",
    "    case_copy=case.copy()\n",
    "    \n",
    "    # Case 확인\n",
    "    print(\"Case:\", case)\n",
    "    \n",
    "    # Train Data\n",
    "    X = x_train_num.drop(columns=case)\n",
    "    X = pd.concat([X, x_train_cat], axis=1).values\n",
    "    \n",
    "    # Test Data\n",
    "    X_test = x_test_num.drop(columns=case)\n",
    "    X_test = pd.concat([X_test, x_test_cat],axis=1).values\n",
    "    \n",
    "    # Label Data\n",
    "    if '사상자수' in case:       \n",
    "        case_copy.remove('사상자수')\n",
    "        print('사상자제거:', case_copy) \n",
    "    Y = x_train_num[case_copy].values\n",
    "    \n",
    "    \n",
    "    # Model define(Ver. MP)\n",
    "    num_input = Input(shape=(len(X[0]),), name='num_input')\n",
    "    x = Dense((int(len(X[0] + len(Y[0])) * 2 /3)), activation='relu')(num_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense((int(len(X[0] + len(Y[0])) * 2 /3)), activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense((int(len(X[0] + len(Y[0])) * 2 /3)), activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    num_output = Dense(len(Y[0]), name='num_output')(x)\n",
    "\n",
    "    model = Model(inputs=num_input, outputs=num_output)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mse',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=10, verbose=1, factor=0.5, min_lr=0.00000001)\n",
    "\n",
    "    callbacks = [\n",
    "        learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "        EarlyStopping('val_loss', patience=15)# val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(X, Y, epochs=epochs, batch_size=batch_size, callbacks=callbacks, validation_split=0.2 )\n",
    "    \n",
    "    \n",
    "    # make a prediction\n",
    "    Y_test = model.predict(X_test[start:end+1])\n",
    "    \n",
    "    del model\n",
    "    \n",
    "    return Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical case를 학습하고 예상값을 return\n",
    "\n",
    "# case: column명 array\n",
    "# start: 예측할 시작 row\n",
    "# end: 예측할 마지막 row\n",
    "def categorical_case(case, start, end):\n",
    "    \n",
    "    # 기존 session 초기화\n",
    "    K.clear_session()\n",
    "    \n",
    "    # Case 확인\n",
    "    print(\"Case:\", case)\n",
    "    \n",
    "    col_name = [] # ex. '사고유형_대분류_차대차', '사고유형_대분류_차대사람', '사고유형_대분류_차량단독'\n",
    "    label_name = [] #  ex. '차대차', '차대사람', '차량단독\n",
    "    \n",
    "    # One Hot Encoding 후 Columns 이름과 Columns에 들어 있는 값 \n",
    "    for col in case:\n",
    "        label_name.extend(all_data[col].unique()) \n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)\n",
    "\n",
    "    # Train Data \n",
    "    X = x_train_cat.drop(columns=col_name)\n",
    "    X = pd.concat([X, x_train_num], axis=1).values\n",
    "\n",
    "    # Test Data\n",
    "    X_test = x_test_cat.drop(columns=col_name)\n",
    "    X_test = pd.concat([X_test, x_test_num],axis=1).values\n",
    "    \n",
    "    # Label Data\n",
    "    Y = x_train_cat[col_name].values\n",
    "    \n",
    "    # Model define(Ver. MP)\n",
    "    cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "    x = Dense(512, activation='relu')(cat_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    cat_output = Dense(len(Y[0]), activation='sigmoid', name='cat_output')(x)\n",
    "\n",
    "    model = Model(inputs=cat_input, outputs=cat_output)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=10, verbose=1, factor=0.5, min_lr=0.00000001)\n",
    "\n",
    "    callbacks = [\n",
    "        learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "        EarlyStopping('val_loss', patience=15), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "        ]\n",
    "\n",
    "    history = model.fit(X, Y, epochs=epochs, batch_size=batch_size, callbacks=callbacks,validation_split=0.2 )\n",
    "    \n",
    "    # make a prediction\n",
    "    Y_test = model.predict(X_test[start:end+1])\n",
    "    \n",
    "\n",
    "    '''\n",
    "    예시 출력:\n",
    "        사고유형_대분류 : 차량단독\n",
    "        사고유형_중분류 : 공작물충돌\n",
    "        법규위반 : 안전운전 의무 불이행\n",
    "    '''\n",
    "    result = []\n",
    "    for cat in Y_test: \n",
    "        x_list = list(cat)\n",
    "        label_name_x = label_name.copy()\n",
    "        temp = []\n",
    "        for col in case:\n",
    "#             print(col, ':', label_name_x[x_list.index(max(x_list[0:len(all_data[col].unique())]))] )\n",
    "            temp.append(label_name_x[x_list.index(max(x_list[0:len(all_data[col].unique())]))])\n",
    "            del x_list[:len(all_data[col].unique())]\n",
    "            del label_name_x[:len(all_data[col].unique())]\n",
    "        result.append(temp)\n",
    "        \n",
    "        \n",
    "    del model\n",
    "    \n",
    "    return np.array(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mix case를 학습하고 예상값을 return\n",
    "\n",
    "# case: column명 array\n",
    "# n: 범주형 데이터 수\n",
    "# start: 예측할 시작 row\n",
    "# end: 예측할 마지막 row\n",
    "def mix_case(case, n, start, end):\n",
    "\n",
    "    # 기존 session 초기화\n",
    "    K.clear_session()\n",
    "    \n",
    "    # Case 확인\n",
    "    print(\"Case:\", case)\n",
    "    \n",
    "    # list 값 복사\n",
    "    case_copy = case.copy()\n",
    "    \n",
    "    # categorical cases 처리\n",
    "    col_name = []\n",
    "    label_name = []\n",
    "    cat_name = []\n",
    "#     cat_name = case_copy[-n:]\n",
    "    \n",
    "    for col in case_copy:\n",
    "        if col in categorical:\n",
    "            cat_name.append(col)\n",
    "            label_name.extend(all_data[col].unique()) \n",
    "            for name in all_data[col].unique():\n",
    "                col_name.append(col+'_'+name)\n",
    "                \n",
    "                \n",
    "    \n",
    "\n",
    "    Y_cat = x_train_cat[col_name].values\n",
    "    X1 = x_train_cat.drop(columns=col_name)\n",
    "    X_test1 = x_test_cat.drop(columns=col_name)\n",
    "    \n",
    "\n",
    "    for remove_name in cat_name:\n",
    "        case_copy.remove(remove_name)\n",
    "    \n",
    "    print('해당 numberical 컬럼 순서', case_copy)\n",
    "    \n",
    "    \n",
    "    # numerical cases 처리\n",
    "    X2 = x_train_num.drop(columns=case_copy)\n",
    "    X_test2 = x_test_num.drop(columns=case_copy)\n",
    "    \n",
    "    if '사상자수' in case: \n",
    "        case_copy.remove('사상자수')\n",
    "        print('사상자제거:', case_copy) \n",
    "    Y_num = x_train_num[case_copy].values\n",
    "    \n",
    "    X = pd.concat([X1, X2], axis=1).values\n",
    "    X_test = pd.concat([X_test1, X_test2],axis=1).values\n",
    "    \n",
    "    \n",
    "    # Model define(Ver.MP)\n",
    "    cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "    x = Dense(1024, activation='relu')(cat_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    if n == 1:\n",
    "        cat_output = Dense(len(Y_cat[0]), activation='softmax', name='cat_output')(x)\n",
    "    elif n == 2:\n",
    "        cat_output = Dense(len(Y_cat[0]), activation='sigmoid', name='cat_output')(x)\n",
    "        \n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    num_output = Dense(len(Y_num[0]), name='num_output')(x)\n",
    "\n",
    "    model = Model(inputs=cat_input, outputs=[cat_output, num_output])\n",
    "\n",
    "    if n==1:\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss={'cat_output': 'categorical_crossentropy', 'num_output': 'mse'},\n",
    "                      metrics=['accuracy'])\n",
    "    elif n==2:\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss={'cat_output': 'binary_crossentropy', 'num_output': 'mse'},\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='cat_output_acc', \n",
    "                                            patience=10, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "    callbacks = [\n",
    "        learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "        EarlyStopping('val_loss', patience=20), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "    ]\n",
    "\n",
    "    history = model.fit(X, {'cat_output':Y_cat, 'num_output':Y_num}, epochs=epochs, batch_size=batch_size, callbacks=callbacks,validation_split=0.2 )\n",
    "    \n",
    "    \n",
    "    # make a prediction\n",
    "    Y_test = model.predict(X_test[start:end+1])    \n",
    "    \n",
    "    result = []\n",
    "    for cat, num in zip(Y_test[0], Y_test[1]):\n",
    "        x_list = list(cat)\n",
    "        label_name_x = label_name.copy()\n",
    "        temp = []\n",
    "        for col in cat_name:\n",
    "            temp.append(label_name_x[x_list.index(max(x_list[0:len(all_data[col].unique())]))])\n",
    "            \n",
    "            # 출력한 Column과 데이터 삭제\n",
    "            del x_list[:len(all_data[col].unique())]\n",
    "            del label_name_x[:len(all_data[col].unique())]\n",
    "        temp.extend(num)\n",
    "        result.append(temp)\n",
    "        \n",
    "    \n",
    "    return np.array(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set result array to each cases\n",
    "def setResult(arr, predict, extent, case):\n",
    "    result_arr = arr\n",
    "    print('setResult 호출')\n",
    "        \n",
    "    for xy in extent:\n",
    "        if 3 == xy[1]:\n",
    "            extent.remove(xy)\n",
    "    \n",
    "    for i, cell in enumerate(extent):\n",
    "        result_arr[cell[1]] = predict[0, i]\n",
    "    \n",
    "    # 사망자 수는 사망자, 중상자, 경상자, 부상신고자 수에 의해 영향을 받음.\n",
    "    if '사상자수' in case:\n",
    "        result_arr[2:7] = np.asarray(result_arr[2:7], dtype='float64')\n",
    "        result_arr[3] = result_arr[2] + result_arr[4:7].sum()\n",
    "    \n",
    "    \n",
    "    print('result_arr 결과:',result_arr)\n",
    "    \n",
    "    return result_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[0, 2], [0, 3], [0, 5]]\n",
      "Case: ['사망자수', '사상자수', '경상자수']\n",
      "사상자제거: ['사망자수', '경상자수']\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/1\n",
      "20029/20029 [==============================] - 1s 49us/step - loss: 0.6220 - acc: 0.9399 - val_loss: 0.5358 - val_acc: 0.9329\n",
      "예측값 출력:  [[0.92062664 0.4886908 ]]\n",
      "setResult 호출\n",
      "result_arr 결과: ['야간' '금' 0.9206266403198242 1.409317433834076 0.0 0.4886907935142517 0.0\n",
      " '경기' '화성시' '차대차' '측면충돌' '중앙선 침범' '단일로' '기타단일로' '승용차' '승합차']\n",
      "\n",
      "1\n",
      "[[1, 2], [1, 3], [1, 5]]\n",
      "Case: ['사망자수', '사상자수', '경상자수']\n",
      "사상자제거: ['사망자수', '경상자수']\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/1\n",
      "20029/20029 [==============================] - 1s 32us/step - loss: 0.6826 - acc: 0.9421 - val_loss: 0.5544 - val_acc: 0.9441\n",
      "예측값 출력:  [[0.90263057 0.06199617]]\n",
      "setResult 호출\n",
      "result_arr 결과: ['야간' '금' 0.9026305675506592 0.9646267332136631 0.0 0.06199616566300392\n",
      " 0.0 '전남' '영암군' '차대사람' '차도통행중' '과속' '단일로' '기타단일로' '승용차' '보행자']\n",
      "\n",
      "2\n",
      "[[2, 3], [2, 4], [2, 6]]\n",
      "Case: ['사상자수', '중상자수', '부상신고자수']\n",
      "사상자제거: ['중상자수', '부상신고자수']\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/1\n",
      "20029/20029 [==============================] - 1s 30us/step - loss: 0.5342 - acc: 0.8571 - val_loss: 0.9052 - val_acc: 0.9786\n",
      "예측값 출력:  [[0.04967534 0.01536297]]\n",
      "setResult 호출\n",
      "result_arr 결과: ['야간' '월' 1.0 1.065038312226534 0.049675337970256805 0.0\n",
      " 0.015362974256277084 '전남' '곡성군' '차량단독' '전도전복' '안전운전 의무 불이행' '단일로' '기타단일로'\n",
      " '자전거' '없음']\n",
      "\n",
      "3\n",
      "[[3, 3], [3, 4], [3, 6]]\n",
      "Case: ['사상자수', '중상자수', '부상신고자수']\n",
      "사상자제거: ['중상자수', '부상신고자수']\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/1\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.5380 - acc: 0.8495 - val_loss: 0.9105 - val_acc: 0.9902\n",
      "예측값 출력:  [[1.266251   0.21084535]]\n",
      "setResult 호출\n",
      "result_arr 결과: ['야간' '일' 2.0 4.477096319198608 1.2662509679794312 1.0 0.21084535121917725\n",
      " '대구' '달성군' '차대차' '측면충돌' '중앙선 침범' '단일로' '기타단일로' '승용차' '승합차']\n",
      "\n",
      "4\n",
      "[[4, 3], [4, 4], [4, 5]]\n",
      "Case: ['사상자수', '중상자수', '경상자수']\n",
      "사상자제거: ['중상자수', '경상자수']\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/1\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 1.0963 - acc: 0.5963 - val_loss: 0.9881 - val_acc: 0.7790\n",
      "예측값 출력:  [[0.40548307 0.38868487]]\n",
      "setResult 호출\n",
      "result_arr 결과: ['주간' '목' 1.0 1.794167935848236 0.40548306703567505 0.38868486881256104\n",
      " 0.0 '전남' '고흥군' '차대차' '정면충돌' '중앙선 침범' '단일로' '기타단일로' '화물차' '화물차']\n",
      "\n",
      "5\n",
      "[[5, 3], [5, 4], [5, 5]]\n",
      "Case: ['사상자수', '중상자수', '경상자수']\n",
      "사상자제거: ['중상자수', '경상자수']\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/1\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 1.0724 - acc: 0.6212 - val_loss: 1.0794 - val_acc: 0.7742\n",
      "예측값 출력:  [[0.8179569 0.7261509]]\n",
      "setResult 호출\n",
      "result_arr 결과: ['주간' '목' 2.0 3.5441077947616577 0.8179569244384766 0.7261508703231812 0.0\n",
      " '경북' '영천시' '차대차' '추돌' '안전운전 의무 불이행' '단일로' '기타단일로' '화물차' '화물차']\n",
      "\n",
      "6\n",
      "[[6, 3], [6, 4], [6, 5]]\n",
      "Case: ['사상자수', '중상자수', '경상자수']\n",
      "사상자제거: ['중상자수', '경상자수']\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/1\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 1.0839 - acc: 0.6056 - val_loss: 1.0270 - val_acc: 0.8059\n",
      "예측값 출력:  [[1.7504638 1.5337517]]\n",
      "setResult 호출\n",
      "result_arr 결과: ['야간' '수' 1.0 4.284215569496155 1.750463843345642 1.5337517261505127 0.0\n",
      " '충남' '아산시' '차대차' '추돌' '안전거리 미확보' '단일로' '기타단일로' '승합차' '화물차']\n",
      "\n",
      "7\n",
      "[[7, 2], [7, 3], [7, 4]]\n",
      "Case: ['사망자수', '사상자수', '중상자수']\n",
      "사상자제거: ['사망자수', '중상자수']\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/1\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.5485 - acc: 0.9325 - val_loss: 0.5065 - val_acc: 0.9291\n",
      "예측값 출력:  [[0.9206069 1.3549178]]\n",
      "setResult 호출\n",
      "result_arr 결과: ['주간' '월' 0.9206069111824036 7.2755246758461 1.3549177646636963 5.0 0.0\n",
      " '충남' '서천군' '차대차' '추돌' '안전운전 의무 불이행' '단일로' '기타단일로' '승용차' '특수차']\n",
      "\n",
      "8\n",
      "[[8, 2], [8, 3], [8, 4]]\n",
      "Case: ['사망자수', '사상자수', '중상자수']\n",
      "사상자제거: ['사망자수', '중상자수']\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/1\n",
      "20029/20029 [==============================] - 1s 30us/step - loss: 0.5335 - acc: 0.9343 - val_loss: 0.4882 - val_acc: 0.9201\n",
      "예측값 출력:  [[1.3995278 8.20388  ]]\n",
      "setResult 호출\n",
      "result_arr 결과: ['주간' '일' 1.3995277881622314 34.603408098220825 8.203880310058594 21.0 4.0\n",
      " '강원' '평창군' '차대차' '측면충돌' '기타(운전자법규위반)' '단일로' '기타단일로' '건설기계' '승합차']\n",
      "\n",
      "9\n",
      "[[9, 2], [9, 3], [9, 4]]\n",
      "Case: ['사망자수', '사상자수', '중상자수']\n",
      "사상자제거: ['사망자수', '중상자수']\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/1\n",
      "20029/20029 [==============================] - 1s 33us/step - loss: 0.5308 - acc: 0.9259 - val_loss: 0.4992 - val_acc: 0.9111\n",
      "예측값 출력:  [[0.8774942  0.04918509]]\n",
      "setResult 호출\n",
      "result_arr 결과: ['주간' '수' 0.877494215965271 0.9266793094575405 0.049185093492269516 0.0\n",
      " 0.0 '충북' '음성군' '차대사람' '횡단중' '과속' '교차로' '교차로내' '승용차' '보행자']\n",
      "\n",
      "10\n",
      "[[10, 9], [10, 10], [10, 11]]\n",
      "3\n",
      "\n",
      "11\n",
      "[[11, 9], [11, 10], [11, 11]]\n",
      "3\n",
      "\n",
      "12\n",
      "[[12, 9], [12, 10], [12, 11]]\n",
      "3\n",
      "\n",
      "13\n",
      "[[13, 9], [13, 10], [13, 11]]\n",
      "3\n",
      "\n",
      "14\n",
      "[[14, 9], [14, 10], [14, 11]]\n",
      "3\n",
      "\n",
      "15\n",
      "[[15, 9], [15, 10], [15, 11]]\n",
      "3\n",
      "\n",
      "16\n",
      "[[16, 9], [16, 10], [16, 11]]\n",
      "3\n",
      "\n",
      "17\n",
      "[[17, 9], [17, 10], [17, 11]]\n",
      "3\n",
      "\n",
      "18\n",
      "[[18, 9], [18, 10], [18, 11]]\n",
      "3\n",
      "\n",
      "19\n",
      "[[19, 9], [19, 10], [19, 11]]\n",
      "3\n",
      "\n",
      "20\n",
      "[[20, 12], [20, 13], [20, 14]]\n",
      "3\n",
      "\n",
      "21\n",
      "[[21, 12], [21, 13], [21, 14]]\n",
      "3\n",
      "\n",
      "22\n",
      "[[22, 12], [22, 13], [22, 14]]\n",
      "3\n",
      "\n",
      "23\n",
      "[[23, 12], [23, 13], [23, 15]]\n",
      "3\n",
      "\n",
      "24\n",
      "[[24, 12], [24, 13], [24, 15]]\n",
      "3\n",
      "\n",
      "25\n",
      "[[25, 12], [25, 13], [25, 15]]\n",
      "3\n",
      "\n",
      "26\n",
      "[[26, 12], [26, 13], [26, 14], [26, 15]]\n",
      "4\n",
      "\n",
      "27\n",
      "[[27, 12], [27, 13], [27, 14], [27, 15]]\n",
      "4\n",
      "\n",
      "28\n",
      "[[28, 12], [28, 13], [28, 14], [28, 15]]\n",
      "4\n",
      "\n",
      "29\n",
      "[[29, 12], [29, 13], [29, 14], [29, 15]]\n",
      "4\n",
      "\n",
      "30\n",
      "[[30, 2], [30, 3], [30, 8]]\n",
      "[[30, 2], [30, 3], [30, 8]]\n",
      "\n",
      "31\n",
      "[[31, 2], [31, 3], [31, 8]]\n",
      "[[31, 2], [31, 3], [31, 8]]\n",
      "\n",
      "32\n",
      "[[32, 4], [32, 5], [32, 8]]\n",
      "[[32, 4], [32, 5], [32, 8]]\n",
      "\n",
      "33\n",
      "[[33, 4], [33, 5], [33, 8]]\n",
      "[[33, 4], [33, 5], [33, 8]]\n",
      "\n",
      "34\n",
      "[[34, 4], [34, 5], [34, 8]]\n",
      "[[34, 4], [34, 5], [34, 8]]\n",
      "\n",
      "35\n",
      "[[35, 7], [35, 8]]\n",
      "2\n",
      "\n",
      "36\n",
      "[[36, 7], [36, 8]]\n",
      "2\n",
      "\n",
      "37\n",
      "[[37, 7], [37, 8]]\n",
      "2\n",
      "\n",
      "38\n",
      "[[38, 7], [38, 8]]\n",
      "2\n",
      "\n",
      "39\n",
      "[[39, 7], [39, 8]]\n",
      "2\n",
      "\n",
      "40\n",
      "[[40, 1], [40, 9], [40, 10]]\n",
      "3\n",
      "\n",
      "41\n",
      "[[41, 1], [41, 9], [41, 10]]\n",
      "3\n",
      "\n",
      "42\n",
      "[[42, 1], [42, 10], [42, 11], [42, 12]]\n",
      "4\n",
      "\n",
      "43\n",
      "[[43, 1], [43, 10], [43, 11], [43, 12]]\n",
      "4\n",
      "\n",
      "44\n",
      "[[44, 1], [44, 10], [44, 11], [44, 12]]\n",
      "4\n",
      "\n",
      "45\n",
      "[[45, 0], [45, 2], [45, 3], [45, 14]]\n",
      "[[45, 0], [45, 2], [45, 3], [45, 14]]\n",
      "\n",
      "46\n",
      "[[46, 0], [46, 2], [46, 3], [46, 14]]\n",
      "[[46, 0], [46, 2], [46, 3], [46, 14]]\n",
      "\n",
      "47\n",
      "[[47, 0], [47, 3], [47, 4], [47, 13]]\n",
      "[[47, 0], [47, 3], [47, 4], [47, 13]]\n",
      "\n",
      "48\n",
      "[[48, 0], [48, 3], [48, 4], [48, 13]]\n",
      "[[48, 0], [48, 3], [48, 4], [48, 13]]\n",
      "\n",
      "49\n",
      "[[49, 0], [49, 3], [49, 4], [49, 13]]\n",
      "[[49, 0], [49, 3], [49, 4], [49, 13]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np_x_test = x_test.isnull().values\n",
    "x_test_col_name = x_test.columns.values\n",
    "new_sheet = np.array([x_test.columns.values])\n",
    "Case_ex = []\n",
    "label_ex = []\n",
    "for row in range(len(np_x_test)):\n",
    "    temp_case = []\n",
    "    temp_label = []\n",
    "    for col in range(len(np_x_test[0])):\n",
    "        if np_x_test[row, col] == True:\n",
    "            temp_case.append(x_test_col_name[col])\n",
    "            temp_label.append([row, col])\n",
    "    Case_ex.append(temp_case)\n",
    "    label_ex.append(temp_label)\n",
    "\n",
    "# print(Case_ex)\n",
    "# print(label_ex)\n",
    "\n",
    "for idx, (case, cell) in enumerate(zip(Case_ex, label_ex)):\n",
    "    print(idx)\n",
    "    print(cell)\n",
    "    num = 0\n",
    "    cat = 0\n",
    "    for one_case in case:\n",
    "        if one_case in numerical:\n",
    "            num += 1\n",
    "        elif one_case in categorical:\n",
    "            cat += 1\n",
    "        \n",
    "    if len(case) == num:\n",
    "        Case_prediction = numeric_case(case, cell[0][0], cell[-1][0])\n",
    "        print(\"예측값 출력: \", Case_prediction)\n",
    "        answer = setResult(x_test.loc[cell[0][0]].values, Case_prediction, cell, case)\n",
    "        \n",
    "\n",
    "    elif len(case) == cat:\n",
    "        \n",
    "        Case_prediction = categorical_case(case, cell[0][0], cell[-1][0])\n",
    "        print(\"예측값 출력: \", Case_prediction)\n",
    "        answer = setResult(x_test.loc[cell[0][0]].values, Case_prediction, cell, case)\n",
    "        \n",
    "    else:\n",
    "        print(cell)\n",
    "        \n",
    "        temp_num = []\n",
    "        temp_cat = []\n",
    "        for one_case in case:\n",
    "            if one_case in numerical:\n",
    "                temp_num.append(cell[case.index(one_case)])\n",
    "                \n",
    "            if one_case in categorical:\n",
    "                temp_cat.append(cell[case.index(one_case)])\n",
    "                \n",
    "        temp_cat.extend(temp_num)\n",
    "        print(temp_cat)\n",
    "        \n",
    "        Case_prediction = mix_case(case, cat, cell[0][0], cell[-1][0])\n",
    "        print(\"예측값 출력: \", Case_prediction)\n",
    "        answer = setResult(x_test.loc[cell[0][0]].values, Case_prediction, temp_cat, case)\n",
    "            \n",
    "    print()\n",
    "    new_sheet = np.append(new_sheet, [answer], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['주야', '요일', '사망자수', '사상자수', '중상자수', '경상자수', '부상신고자수', '발생지시도',\n",
       "        '발생지시군구', '사고유형_대분류', '사고유형_중분류', '법규위반', '도로형태_대분류', '도로형태',\n",
       "        '당사자종별_1당_대분류', '당사자종별_2당_대분류'],\n",
       "       ['야간', '금', 0.9206266403198242, 1.409317433834076, 0.0,\n",
       "        0.4886907935142517, 0.0, '경기', '화성시', '차대차', '측면충돌', '중앙선 침범',\n",
       "        '단일로', '기타단일로', '승용차', '승합차'],\n",
       "       ['야간', '금', 0.9026305675506592, 0.9646267332136631, 0.0,\n",
       "        0.06199616566300392, 0.0, '전남', '영암군', '차대사람', '차도통행중', '과속',\n",
       "        '단일로', '기타단일로', '승용차', '보행자'],\n",
       "       ['야간', '월', 1.0, 1.065038312226534, 0.049675337970256805, 0.0,\n",
       "        0.015362974256277084, '전남', '곡성군', '차량단독', '전도전복', '안전운전 의무 불이행',\n",
       "        '단일로', '기타단일로', '자전거', '없음'],\n",
       "       ['야간', '일', 2.0, 4.477096319198608, 1.2662509679794312, 1.0,\n",
       "        0.21084535121917725, '대구', '달성군', '차대차', '측면충돌', '중앙선 침범', '단일로',\n",
       "        '기타단일로', '승용차', '승합차'],\n",
       "       ['주간', '목', 1.0, 1.794167935848236, 0.40548306703567505,\n",
       "        0.38868486881256104, 0.0, '전남', '고흥군', '차대차', '정면충돌', '중앙선 침범',\n",
       "        '단일로', '기타단일로', '화물차', '화물차'],\n",
       "       ['주간', '목', 2.0, 3.5441077947616577, 0.8179569244384766,\n",
       "        0.7261508703231812, 0.0, '경북', '영천시', '차대차', '추돌', '안전운전 의무 불이행',\n",
       "        '단일로', '기타단일로', '화물차', '화물차'],\n",
       "       ['야간', '수', 1.0, 4.284215569496155, 1.750463843345642,\n",
       "        1.5337517261505127, 0.0, '충남', '아산시', '차대차', '추돌', '안전거리 미확보',\n",
       "        '단일로', '기타단일로', '승합차', '화물차'],\n",
       "       ['주간', '월', 0.9206069111824036, 7.2755246758461,\n",
       "        1.3549177646636963, 5.0, 0.0, '충남', '서천군', '차대차', '추돌',\n",
       "        '안전운전 의무 불이행', '단일로', '기타단일로', '승용차', '특수차'],\n",
       "       ['주간', '일', 1.3995277881622314, 34.603408098220825,\n",
       "        8.203880310058594, 21.0, 4.0, '강원', '평창군', '차대차', '측면충돌',\n",
       "        '기타(운전자법규위반)', '단일로', '기타단일로', '건설기계', '승합차'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자'],\n",
       "       ['주간', '수', 0.877494215965271, 0.9266793094575405,\n",
       "        0.049185093492269516, 0.0, 0.0, '충북', '음성군', '차대사람', '횡단중', '과속',\n",
       "        '교차로', '교차로내', '승용차', '보행자']], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_name_csv = './test_kor_' +  str(epochs) + '.csv'\n",
    "with open(sheet_name_csv, 'wb') as f:\n",
    "        np.savetxt(f,  new_sheet,  delimiter=\",\", fmt='%s', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test_kor_1.csv\n",
      "Save Success\n"
     ]
    }
   ],
   "source": [
    "save_result(sheet_name_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
