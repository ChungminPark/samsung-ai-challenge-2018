{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일 불러오기\n",
    "학습 데이터, 테스트 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf) # print all numpy values\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, OneHotEncoder, MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['주야', '요일', '발생지시도', '발생지시군구', '사고유형_대분류', '사고유형_중분류', '법규위반', \n",
    "            '도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류']\n",
    "numerical = ['사상자수', '사망자수', '중상자수', '경상자수','부상신고자수']\n",
    "\n",
    "x_train_num = pd.read_csv('./교통사망사고정보/Kor_Train_교통사망사고정보(12.1~17.6).csv',encoding='cp949', usecols=numerical)\n",
    "\n",
    "x_train_cat = pd.read_csv('./교통사망사고정보/Kor_Train_교통사망사고정보(12.1~17.6).csv',encoding='cp949', usecols=categorical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_num = pd.read_csv('./test_kor.csv',encoding='cp949', usecols=numerical)\n",
    "\n",
    "x_test_cat = pd.read_csv('./test_kor.csv',encoding='cp949', usecols=categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encdoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat((x_test_cat.dropna(), x_train_cat))\n",
    "# for col in all_data.select_dtypes(include=[np.object]).columns:\n",
    "#     print(col, all_data[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chuck\\AppData\\Local\\conda\\conda\\envs\\sdc2018\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  \n",
      "C:\\Users\\Chuck\\AppData\\Local\\conda\\conda\\envs\\sdc2018\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for column in all_data.select_dtypes(include=[np.object]).columns:\n",
    "    x_train_cat[column] = x_train_cat[column].astype('category', categories = all_data[column].unique())\n",
    "    x_test_cat[column] = x_test_cat[column].astype('category', categories = all_data[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cat = pd.get_dummies(data=x_train_cat)\n",
    "x_test_cat = pd.get_dummies(data=x_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 328)\n",
      "(50, 328)\n"
     ]
    }
   ],
   "source": [
    "# One Encoding Shape 확인\n",
    "print(x_train_cat.shape)\n",
    "print(x_test_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Input, LSTM, concatenate, Dropout, Conv2D, MaxPool2D, Embedding, Reshape, Conv1D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras import metrics\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 328)\n",
      "(25037, 5)\n",
      "(50, 328)\n",
      "(50, 5)\n"
     ]
    }
   ],
   "source": [
    "# Train Data Shape\n",
    "print(x_train_cat.shape)\n",
    "print(x_train_num.shape)\n",
    "# Test Data Shape\n",
    "print(x_test_cat.shape)\n",
    "print(x_test_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric cases\n",
    "Case1 = ['사망자수','사상자수','경상자수']\n",
    "Case2 = ['사상자수', '중상자수', '부상신고자수']\n",
    "Case3 = ['사상자수', '중상자수', '경상자수' ]\n",
    "Case4 = ['사망자수', '사상자수', '중상자수' ]\n",
    "\n",
    "# Categorical cases\n",
    "Case5 = ['사고유형_대분류', '사고유형_중분류', '법규위반']\n",
    "Case6 = ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류']\n",
    "Case7 = ['도로형태_대분류', '도로형태', '당사자종별_2당_대분류']\n",
    "Case8 = ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류']\n",
    "Case11 = ['발생지시도', '발생지시군구']\n",
    "Case12 = ['요일', '사고유형_대분류', '사고유형_중분류']\n",
    "Case13 = ['요일', '사고유형_중분류', '법규위반', '도로형태_대분류']\n",
    "\n",
    "# Mixed cases\n",
    "Case9 = ['사망자수', '사상자수', '발생지시군구']\n",
    "Case10 = ['중상자수', '경상자수', '발생지시군구']\n",
    "Case14 = ['사망자수', '사상자수', '주야', '당사자종별_1당_대분류']\n",
    "Case15 = ['사상자수', '중상자수', '주야', '도로형태']\n",
    "\n",
    "Cases = [Case1, Case2, Case3, Case4, Case5, Case6, Case7, Case8, Case9, Case10,\n",
    "         Case11, Case12, Case13, Case14, Case15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case ranges\n",
    "\n",
    "case1_range = [0, 1]\n",
    "case2_range = [2, 3]\n",
    "case3_range = [4, 6]\n",
    "case4_range = [7, 9]\n",
    "case5_range = [10, 19]\n",
    "case6_range = [20, 22]\n",
    "case7_range = [23, 25]\n",
    "case8_range = [26, 29]\n",
    "case9_range = [30, 31]\n",
    "case10_range = [32, 34]\n",
    "case11_range = [35, 39]\n",
    "case12_range = [40, 41]\n",
    "case13_range = [42, 44]\n",
    "case14_range = [45, 46]\n",
    "case15_range = [47, 49]\n",
    "\n",
    "test_ranges = [case1_range, case2_range, case3_range, case4_range, case5_range, case6_range,\n",
    "             case7_range, case8_range, case9_range, case10_range, case11_range, case12_range,\n",
    "             case13_range, case14_range, case15_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['사망자수', '사상자수', '경상자수'] [0, 1]\n",
      "2 ['사상자수', '중상자수', '부상신고자수'] [2, 3]\n",
      "3 ['사상자수', '중상자수', '경상자수'] [4, 6]\n",
      "4 ['사망자수', '사상자수', '중상자수'] [7, 9]\n",
      "5 ['사고유형_대분류', '사고유형_중분류', '법규위반'] [10, 19]\n",
      "6 ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류'] [20, 22]\n",
      "7 ['도로형태_대분류', '도로형태', '당사자종별_2당_대분류'] [23, 25]\n",
      "8 ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류'] [26, 29]\n",
      "9 ['사망자수', '사상자수', '발생지시군구'] [30, 31]\n",
      "10 ['중상자수', '경상자수', '발생지시군구'] [32, 34]\n",
      "11 ['발생지시도', '발생지시군구'] [35, 39]\n",
      "12 ['요일', '사고유형_대분류', '사고유형_중분류'] [40, 41]\n",
      "13 ['요일', '사고유형_중분류', '법규위반', '도로형태_대분류'] [42, 44]\n",
      "14 ['사망자수', '사상자수', '주야', '당사자종별_1당_대분류'] [45, 46]\n",
      "15 ['사상자수', '중상자수', '주야', '도로형태'] [47, 49]\n"
     ]
    }
   ],
   "source": [
    "# train, set result in new array\n",
    "for (idx, case), range_x in zip(enumerate(Cases), test_ranges):\n",
    "    print(idx+1, case, range_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result():\n",
    "    '''\n",
    "    test file에 있는 값을 result file에 저장\n",
    "    '''\n",
    "    test_file = pd.read_csv('./test_kor_1.csv', encoding='cp949', names= [chr(y) for y in range(ord('A'),ord('P')+1)])\n",
    "    result_file = pd.read_csv('./result_kor.csv', encoding='cp949')\n",
    "    \n",
    "    cols = result_file['열'].values\n",
    "    rows = result_file['행'].values\n",
    "    vals = result_file['값'].astype('str').values\n",
    "    \n",
    "    rows-=1\n",
    "    \n",
    "    for i, (row, col) in enumerate(zip(rows, cols)):      \n",
    "        vals[i] = test_file[col][row]\n",
    "\n",
    "    rows += 1\n",
    "\n",
    "    with open('./result_kor1.csv', 'wb') as f:\n",
    "        for i in result_file.index:\n",
    "            np.savetxt(f,  np.c_[rows,cols,vals],  delimiter=\",\", fmt='%s', encoding='cp949', header='행,열,값', comments='')\n",
    "    print('Save Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 데이터 Case 함수\n",
    "\n",
    "def numeric_case(case, start, end):\n",
    "    \n",
    "    K.clear_session()\n",
    "    case_copy=case.copy()\n",
    "    \n",
    "    # Case 확인\n",
    "    print(\"Case:\", case)\n",
    "    \n",
    "    # Train Data\n",
    "    X = x_train_num.drop(columns=case)\n",
    "    X = pd.concat([X, x_train_cat], axis=1).values\n",
    "    \n",
    "    # Test Data\n",
    "    X_test = x_test_num.drop(columns=case)\n",
    "    X_test = pd.concat([X_test, x_test_cat],axis=1).values\n",
    "    \n",
    "    # Label Data\n",
    "#     if '사상자수' in case:       \n",
    "#         case_copy.remove('사상자수')\n",
    "#         print('사상자제거:', case_copy) \n",
    "    Y = x_train_num[case_copy].values\n",
    "    \n",
    "#     X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "#     X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    # Model define\n",
    "\n",
    "#     num_input = Input(shape=( X.shape[1], 1), name='num_input')\n",
    "#     x = LSTM(512)(num_input)\n",
    "#     x = Dense((int(len(X[0] + len(Y[0])) * 2 /3)), activation='relu')(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = Dense((int(len(X[0] + len(Y[0])) * 2 /3)), activation='relu')(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = Dense((int(len(X[0] + len(Y[0])) * 2 /3)), activation='relu')(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     num_output = Dense(len(Y[0]), name='num_output')(x)\n",
    "    \n",
    "    \n",
    "    # Model define\n",
    "    num_input = Input(shape=(len(X[0]),), name='num_input')\n",
    "    x = Dense((int(len(X[0] + len(Y[0])) * 2 /3)), activation='relu')(num_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense((int(len(X[0] + len(Y[0])) * 2 /3)), activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense((int(len(X[0] + len(Y[0])) * 2 /3)), activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    num_output = Dense(len(Y[0]), name='num_output')(x)\n",
    "\n",
    "    model = Model(inputs=num_input, outputs=num_output)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=25, verbose=1, factor=0.5, min_lr=0.00000001)\n",
    "\n",
    "    callbacks = [\n",
    "        learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "        EarlyStopping('val_loss', patience=15)# val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks, validation_split=0.2 )\n",
    "    \n",
    "    \n",
    "    # make a prediction\n",
    "    Y_test = model.predict(X_test[start:end+1])\n",
    "    \n",
    "    del model\n",
    "    \n",
    "    return Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 데이터 Case 함수\n",
    "\n",
    "def categorical_case(case, start, end):\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    # Case 확인\n",
    "    print(\"Case:\", case)\n",
    "    \n",
    "    col_name = [] # ex. '사고유형_대분류_차대차', '사고유형_대분류_차대사람', '사고유형_대분류_차량단독'\n",
    "    label_name = [] #  ex. '차대차', '차대사람', '차량단독\n",
    "    \n",
    "    # One Hot Encoding 후 Columns 이름과 Columns에 들어 있는 값 \n",
    "    for col in case:\n",
    "        label_name.extend(all_data[col].unique()) \n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)\n",
    "\n",
    "    # Train Data \n",
    "    X = x_train_cat.drop(columns=col_name)\n",
    "    X = pd.concat([X, x_train_num], axis=1).values\n",
    "\n",
    "    # Test Data\n",
    "    X_test = x_test_cat.drop(columns=col_name)\n",
    "    X_test = pd.concat([X_test, x_test_num],axis=1).values\n",
    "    \n",
    "    # Label Data\n",
    "    Y = x_train_cat[col_name].values\n",
    "    \n",
    "    \n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    \n",
    "    cat_input = Input(shape=( X.shape[1], 1), name='cat_input')\n",
    "    x = LSTM(512)(cat_input)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    cat_output = Dense(len(Y[0]), activation='sigmoid', name='cat_output')(x)\n",
    "    \n",
    "    # Model define\n",
    "#     cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "#     x = Dense(512, activation='relu')(cat_input)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = Dense(512, activation='relu')(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = Dense(512, activation='relu')(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     x = Dense(256, activation='relu')(x)\n",
    "#     x = Dropout(0.3)(x)\n",
    "#     cat_output = Dense(len(Y[0]), activation='sigmoid', name='cat_output')(x)\n",
    "\n",
    "    model = Model(inputs=cat_input, outputs=cat_output)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=25, verbose=1, factor=0.5, min_lr=0.00000001)\n",
    "\n",
    "    callbacks = [\n",
    "        learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "        EarlyStopping('val_loss', patience=15), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "        ]\n",
    "\n",
    "    history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )\n",
    "    \n",
    "    # make a prediction\n",
    "    Y_test = model.predict(X_test[start:end+1])\n",
    "    \n",
    "\n",
    "    '''\n",
    "    예시 출력:\n",
    "        사고유형_대분류 : 차량단독\n",
    "        사고유형_중분류 : 공작물충돌\n",
    "        법규위반 : 안전운전 의무 불이행\n",
    "    '''\n",
    "    result = []\n",
    "    for cat in Y_test: \n",
    "        x_list = list(cat)\n",
    "        label_name_x = label_name.copy()\n",
    "        temp = []\n",
    "        for col in case:\n",
    "#             print(col, ':', label_name_x[x_list.index(max(x_list[0:len(all_data[col].unique())]))] )\n",
    "            temp.append(label_name_x[x_list.index(max(x_list[0:len(all_data[col].unique())]))])\n",
    "            del x_list[:len(all_data[col].unique())]\n",
    "            del label_name_x[:len(all_data[col].unique())]\n",
    "        result.append(temp)\n",
    "        \n",
    "        \n",
    "    del model\n",
    "    \n",
    "    return np.array(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 믹스형 데이터 Case 함수\n",
    "\n",
    "def mix_case(case, n, start, end):\n",
    "    '''\n",
    "    case: Case에 해당되는 컬럼이 담긴 배열\n",
    "    n: 범주형 데이터 수\n",
    "    start: 해당 Case 테스트의 시작 인덱스\n",
    "    end: 해당 Case 테스트의 마지막 인덱스\n",
    "    '''\n",
    "    \n",
    "    case_copy=case.copy()\n",
    "    \n",
    "    # categorical\n",
    "    col_name = []\n",
    "    label_name = []\n",
    "    cat_name = case_copy[-n:]\n",
    "    \n",
    "    for col in case_copy[-n:]:\n",
    "        label_name.extend(all_data[col].unique()) \n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)\n",
    "    \n",
    "    Y_cat = x_train_cat[col_name].values\n",
    "    X1 = x_train_cat.drop(columns=col_name)\n",
    "    X_test1 = x_test_cat.drop(columns=col_name)\n",
    "    \n",
    "    # categorical columns 삭제\n",
    "    del case_copy[-n:]\n",
    "    \n",
    "    # numerical\n",
    "    X2 = x_train_num.drop(columns=case_copy)\n",
    "    X_test2 = x_test_num.drop(columns=case_copy)\n",
    "    \n",
    "#     if '사상자수' in case: \n",
    "#         case_copy.remove('사상자수')\n",
    "    Y_num = x_train_num[case_copy].values\n",
    "    \n",
    "    X = pd.concat([X1, X2], axis=1).values\n",
    "    X_test = pd.concat([X_test1, X_test2],axis=1).values\n",
    "    \n",
    "    \n",
    "    # Model define\n",
    "    cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "    x = Dense(1024, activation='relu')(cat_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    if n == 1:\n",
    "        cat_output = Dense(len(Y_cat[0]), activation='softmax', name='cat_output')(x)\n",
    "    elif n == 2:\n",
    "        cat_output = Dense(len(Y_cat[0]), activation='sigmoid', name='cat_output')(x)\n",
    "        \n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    num_output = Dense(len(Y_num[0]), name='num_output')(x)\n",
    "\n",
    "    model = Model(inputs=cat_input, outputs=[cat_output, num_output])\n",
    "\n",
    "    if n==1:\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss={'cat_output': 'categorical_crossentropy', 'num_output': 'mse'},\n",
    "                      metrics=['accuracy'])\n",
    "    elif n==2:\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss={'cat_output': 'binary_crossentropy', 'num_output': 'mse'},\n",
    "                      metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='cat_output_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "    callbacks = [\n",
    "        learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "        EarlyStopping('val_loss', patience=20), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "    ]\n",
    "\n",
    "    history = model.fit(X, {'cat_output':Y_cat, 'num_output':Y_num}, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )\n",
    "    \n",
    "    \n",
    "    # make a prediction\n",
    "    Y_test = model.predict(X_test[start:end+1])    \n",
    "    \n",
    "    result = []\n",
    "    for cat, num in zip(Y_test[0], Y_test[1]):\n",
    "        x_list = list(cat)\n",
    "        label_name_x = label_name.copy()\n",
    "        temp = []\n",
    "        for col in cat_name:\n",
    "            temp.append(label_name_x[x_list.index(max(x_list[0:len(all_data[col].unique())]))])\n",
    "            \n",
    "            # 출력한 Column과 데이터 삭제\n",
    "            del x_list[:len(all_data[col].unique())]\n",
    "            del label_name_x[:len(all_data[col].unique())]\n",
    "        temp.extend(num)\n",
    "        result.append(temp)\n",
    "        \n",
    "    \n",
    "    return np.array(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set result array to each cases\n",
    "def setResult(arr, predict, case):\n",
    "    result_arr = arr\n",
    "    \n",
    "    if case == [int(x) for x in range(0, 2)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 2] = predict[row, 0] # 사망자수\n",
    "            result_arr[row, 5] = predict[row, 2] # 사상자수            \n",
    "            result_arr[row, 3] = predict[row, 1] # 사상자수            \n",
    "            \n",
    "    elif case == [int(x) for x in range(2, 4)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 4] = predict[row, 1]\n",
    "            result_arr[row, 6] = predict[row, 2]\n",
    "            result_arr[row, 3] = predict[row, 0]\n",
    "            \n",
    "    elif case == [int(x) for x in range(4, 7)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 4] = predict[row, 1]\n",
    "            result_arr[row, 5] = predict[row, 2]\n",
    "            result_arr[row, 3] = predict[row, 0]\n",
    "            \n",
    "    elif case == [int(x) for x in range(7, 10)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 2] = predict[row, 0]\n",
    "            result_arr[row, 4] = predict[row, 2]\n",
    "            result_arr[row, 3] = predict[row, 1]\n",
    "            \n",
    "    elif case == [int(x) for x in range(10,20)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 9] = predict[row, 0] \n",
    "            result_arr[row, 10] = predict[row, 1] \n",
    "            result_arr[row, 11] = predict[row, 2] \n",
    "            \n",
    "    elif case == [int(x) for x in range(20,23)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 12] = predict[row, 0] \n",
    "            result_arr[row, 13] = predict[row, 1] \n",
    "            result_arr[row, 14] = predict[row, 2] \n",
    "            \n",
    "    elif case == [int(x) for x in range(23,26)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 12] = predict[row, 0] \n",
    "            result_arr[row, 13] = predict[row, 1] \n",
    "            result_arr[row, 15] = predict[row, 2] \n",
    "    \n",
    "    elif case == [int(x) for x in range(26,30)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 12] = predict[row, 0] \n",
    "            result_arr[row, 13] = predict[row, 1] \n",
    "            result_arr[row, 14] = predict[row, 2] \n",
    "            result_arr[row, 15] = predict[row, 3] \n",
    "    \n",
    "    elif case == [int(x) for x in range(35,40)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 7] = predict[row, 0] \n",
    "            result_arr[row, 8] = predict[row, 1] \n",
    "        \n",
    "    elif case == [int(x) for x in range(40,42)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 1] = predict[row, 0] \n",
    "            result_arr[row, 9] = predict[row, 1] \n",
    "            result_arr[row, 10] = predict[row, 2] \n",
    "        \n",
    "    elif case == [int(x) for x in range(42,45)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 1] = predict[row, 0] \n",
    "            result_arr[row, 10] = predict[row, 1] \n",
    "            result_arr[row, 11] = predict[row, 2] \n",
    "            result_arr[row, 12] = predict[row, 3] \n",
    "    \n",
    "    elif case == [int(x) for x in range(30,32)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 2] = float(predict[row, 1])\n",
    "            result_arr[row, 3] = predict[row, 2]\n",
    "            result_arr[row, 8] = predict[row, 0]\n",
    "            \n",
    "    elif case == [int(x) for x in range(32,35)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 4] = predict[row, 1]\n",
    "            result_arr[row, 5] = predict[row, 2]\n",
    "            result_arr[row, 8] = predict[row, 0]\n",
    "            \n",
    "    elif case == [int(x) for x in range(45,47)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 0] = predict[row, 0]\n",
    "            result_arr[row, 2] = float(predict[row, 2])\n",
    "            result_arr[row, 14] = predict[row, 1]\n",
    "            result_arr[row, 3] = predict[row, 3]\n",
    "            \n",
    "    elif case == [int(x) for x in range(47,50)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 0] = predict[row, 0]\n",
    "            result_arr[row, 4] = float(predict[row, 3])\n",
    "            result_arr[row, 13] = predict[row, 1]\n",
    "            result_arr[row, 3] = float(predict[row, 2])\n",
    "    \n",
    "    print(result_arr)\n",
    "    return result_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test = pd.read_csv('./test_kor.csv',encoding='cp949')\n",
    "\n",
    "# setResult(each case array, predict array, start to end in each case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['주야' '요일' '사망자수' '사상자수' '중상자수' '경상자수' '부상신고자수' '발생지시도' '발생지시군구'\n",
      "  '사고유형_대분류' '사고유형_중분류' '법규위반' '도로형태_대분류' '도로형태' '당사자종별_1당_대분류'\n",
      "  '당사자종별_2당_대분류']]\n"
     ]
    }
   ],
   "source": [
    "test_arr = np.array([x_test.columns.values])\n",
    "print(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 ['사망자수', '사상자수', '경상자수'] [0, 1]\n",
      "\n",
      "2 ['사상자수', '중상자수', '부상신고자수'] [2, 3]\n",
      "\n",
      "3 ['사상자수', '중상자수', '경상자수'] [4, 6]\n",
      "\n",
      "4 ['사망자수', '사상자수', '중상자수'] [7, 9]\n",
      "\n",
      "5 ['사고유형_대분류', '사고유형_중분류', '법규위반'] [10, 19]\n",
      "\n",
      "6 ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류'] [20, 22]\n",
      "\n",
      "7 ['도로형태_대분류', '도로형태', '당사자종별_2당_대분류'] [23, 25]\n",
      "\n",
      "8 ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류'] [26, 29]\n",
      "\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 3s 142us/step - loss: 5.4780 - cat_output_loss: 5.0942 - num_output_loss: 0.3838 - cat_output_acc: 0.0238 - num_output_acc: 0.4967 - val_loss: 5.0309 - val_cat_output_loss: 4.6403 - val_num_output_loss: 0.3906 - val_cat_output_acc: 0.0603 - val_num_output_acc: 0.7708\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 3.9842 - cat_output_loss: 3.6041 - num_output_loss: 0.3801 - cat_output_acc: 0.1062 - num_output_acc: 0.5021 - val_loss: 3.8758 - val_cat_output_loss: 2.9438 - val_num_output_loss: 0.9320 - val_cat_output_acc: 0.1378 - val_num_output_acc: 0.2600\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 3.3360 - cat_output_loss: 2.9212 - num_output_loss: 0.4148 - cat_output_acc: 0.1367 - num_output_acc: 0.4706 - val_loss: 3.0637 - val_cat_output_loss: 2.7975 - val_num_output_loss: 0.2662 - val_cat_output_acc: 0.1374 - val_num_output_acc: 0.3472\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 3.3126 - cat_output_loss: 2.8386 - num_output_loss: 0.4740 - cat_output_acc: 0.1406 - num_output_acc: 0.5284 - val_loss: 2.9609 - val_cat_output_loss: 2.7585 - val_num_output_loss: 0.2024 - val_cat_output_acc: 0.1444 - val_num_output_acc: 0.4543\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 3.1083 - cat_output_loss: 2.7969 - num_output_loss: 0.3113 - cat_output_acc: 0.1482 - num_output_acc: 0.5071 - val_loss: 3.0314 - val_cat_output_loss: 2.7327 - val_num_output_loss: 0.2987 - val_cat_output_acc: 0.1486 - val_num_output_acc: 0.8187\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 3.1206 - cat_output_loss: 2.7637 - num_output_loss: 0.3569 - cat_output_acc: 0.1515 - num_output_acc: 0.5560 - val_loss: 2.9836 - val_cat_output_loss: 2.7236 - val_num_output_loss: 0.2601 - val_cat_output_acc: 0.1548 - val_num_output_acc: 0.9876\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 3.1319 - cat_output_loss: 2.7490 - num_output_loss: 0.3829 - cat_output_acc: 0.1526 - num_output_acc: 0.5697 - val_loss: 3.2409 - val_cat_output_loss: 2.7287 - val_num_output_loss: 0.5122 - val_cat_output_acc: 0.1466 - val_num_output_acc: 0.2859\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 3.0335 - cat_output_loss: 2.7320 - num_output_loss: 0.3014 - cat_output_acc: 0.1553 - num_output_acc: 0.5587 - val_loss: 2.9542 - val_cat_output_loss: 2.7254 - val_num_output_loss: 0.2288 - val_cat_output_acc: 0.1472 - val_num_output_acc: 0.5467\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 3.1265 - cat_output_loss: 2.7259 - num_output_loss: 0.4005 - cat_output_acc: 0.1558 - num_output_acc: 0.5659 - val_loss: 3.0742 - val_cat_output_loss: 2.7172 - val_num_output_loss: 0.3570 - val_cat_output_acc: 0.1482 - val_num_output_acc: 0.8844\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 3.0273 - cat_output_loss: 2.6999 - num_output_loss: 0.3274 - cat_output_acc: 0.1616 - num_output_acc: 0.5926 - val_loss: 2.8103 - val_cat_output_loss: 2.7189 - val_num_output_loss: 0.0913 - val_cat_output_acc: 0.1538 - val_num_output_acc: 0.9669\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 3.0502 - cat_output_loss: 2.6865 - num_output_loss: 0.3637 - cat_output_acc: 0.1616 - num_output_acc: 0.5651 - val_loss: 2.9208 - val_cat_output_loss: 2.7182 - val_num_output_loss: 0.2027 - val_cat_output_acc: 0.1560 - val_num_output_acc: 0.3195\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 2.9780 - cat_output_loss: 2.6815 - num_output_loss: 0.2964 - cat_output_acc: 0.1643 - num_output_acc: 0.5718 - val_loss: 3.2196 - val_cat_output_loss: 2.7070 - val_num_output_loss: 0.5126 - val_cat_output_acc: 0.1556 - val_num_output_acc: 0.7901\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 3.0553 - cat_output_loss: 2.6764 - num_output_loss: 0.3789 - cat_output_acc: 0.1669 - num_output_acc: 0.5751 - val_loss: 3.5491 - val_cat_output_loss: 2.7153 - val_num_output_loss: 0.8338 - val_cat_output_acc: 0.1538 - val_num_output_acc: 0.7806\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 2.9376 - cat_output_loss: 2.6601 - num_output_loss: 0.2775 - cat_output_acc: 0.1719 - num_output_acc: 0.6070 - val_loss: 3.0609 - val_cat_output_loss: 2.7143 - val_num_output_loss: 0.3466 - val_cat_output_acc: 0.1534 - val_num_output_acc: 0.9958\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 3.0219 - cat_output_loss: 2.6603 - num_output_loss: 0.3616 - cat_output_acc: 0.1709 - num_output_acc: 0.6031 - val_loss: 3.2775 - val_cat_output_loss: 2.7080 - val_num_output_loss: 0.5695 - val_cat_output_acc: 0.1569 - val_num_output_acc: 0.9966\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 2.9051 - cat_output_loss: 2.6441 - num_output_loss: 0.2610 - cat_output_acc: 0.1736 - num_output_acc: 0.6026 - val_loss: 3.1541 - val_cat_output_loss: 2.7107 - val_num_output_loss: 0.4435 - val_cat_output_acc: 0.1510 - val_num_output_acc: 0.9852\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 2.9255 - cat_output_loss: 2.6243 - num_output_loss: 0.3011 - cat_output_acc: 0.1803 - num_output_acc: 0.5748 - val_loss: 2.9496 - val_cat_output_loss: 2.7017 - val_num_output_loss: 0.2479 - val_cat_output_acc: 0.1528 - val_num_output_acc: 0.9986\n",
      "Epoch 18/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 2.8246 - cat_output_loss: 2.6129 - num_output_loss: 0.2118 - cat_output_acc: 0.1834 - num_output_acc: 0.5724 - val_loss: 2.9302 - val_cat_output_loss: 2.7107 - val_num_output_loss: 0.2195 - val_cat_output_acc: 0.1560 - val_num_output_acc: 0.2614\n",
      "Epoch 19/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 2.9388 - cat_output_loss: 2.6116 - num_output_loss: 0.3272 - cat_output_acc: 0.1812 - num_output_acc: 0.6382 - val_loss: 2.9495 - val_cat_output_loss: 2.7164 - val_num_output_loss: 0.2331 - val_cat_output_acc: 0.1474 - val_num_output_acc: 0.7893\n",
      "Epoch 20/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 2.7792 - cat_output_loss: 2.5903 - num_output_loss: 0.1888 - cat_output_acc: 0.1882 - num_output_acc: 0.6015 - val_loss: 2.9574 - val_cat_output_loss: 2.7202 - val_num_output_loss: 0.2372 - val_cat_output_acc: 0.1544 - val_num_output_acc: 0.6202\n",
      "Epoch 21/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 2.7681 - cat_output_loss: 2.5725 - num_output_loss: 0.1956 - cat_output_acc: 0.1920 - num_output_acc: 0.6171 - val_loss: 2.8558 - val_cat_output_loss: 2.7171 - val_num_output_loss: 0.1387 - val_cat_output_acc: 0.1536 - val_num_output_acc: 0.9014\n",
      "Epoch 22/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 2.7651 - cat_output_loss: 2.5579 - num_output_loss: 0.2073 - cat_output_acc: 0.1978 - num_output_acc: 0.6086 - val_loss: 2.8640 - val_cat_output_loss: 2.7248 - val_num_output_loss: 0.1392 - val_cat_output_acc: 0.1603 - val_num_output_acc: 0.6773\n",
      "Epoch 23/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 2.9310 - cat_output_loss: 2.5608 - num_output_loss: 0.3702 - cat_output_acc: 0.1950 - num_output_acc: 0.6374 - val_loss: 2.9315 - val_cat_output_loss: 2.7453 - val_num_output_loss: 0.1862 - val_cat_output_acc: 0.1575 - val_num_output_acc: 0.9944\n",
      "Epoch 24/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 2.8870 - cat_output_loss: 2.5497 - num_output_loss: 0.3372 - cat_output_acc: 0.2010 - num_output_acc: 0.5758 - val_loss: 2.9013 - val_cat_output_loss: 2.7493 - val_num_output_loss: 0.1519 - val_cat_output_acc: 0.1554 - val_num_output_acc: 0.5889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 2.8231 - cat_output_loss: 2.5400 - num_output_loss: 0.2831 - cat_output_acc: 0.2021 - num_output_acc: 0.6034 - val_loss: 2.8660 - val_cat_output_loss: 2.7442 - val_num_output_loss: 0.1217 - val_cat_output_acc: 0.1593 - val_num_output_acc: 0.9860\n",
      "Epoch 26/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 2.9911 - cat_output_loss: 2.5289 - num_output_loss: 0.4622 - cat_output_acc: 0.2074 - num_output_acc: 0.6120 - val_loss: 3.3355 - val_cat_output_loss: 2.7568 - val_num_output_loss: 0.5786 - val_cat_output_acc: 0.1550 - val_num_output_acc: 0.7119\n",
      "Epoch 27/50\n",
      "20029/20029 [==============================] - 2s 96us/step - loss: 2.8395 - cat_output_loss: 2.5188 - num_output_loss: 0.3207 - cat_output_acc: 0.2135 - num_output_acc: 0.5599 - val_loss: 2.9394 - val_cat_output_loss: 2.7502 - val_num_output_loss: 0.1892 - val_cat_output_acc: 0.1597 - val_num_output_acc: 0.4319\n",
      "Epoch 28/50\n",
      "20029/20029 [==============================] - 2s 96us/step - loss: 3.1027 - cat_output_loss: 2.5127 - num_output_loss: 0.5900 - cat_output_acc: 0.2145 - num_output_acc: 0.5490 - val_loss: 3.8716 - val_cat_output_loss: 2.7511 - val_num_output_loss: 1.1205 - val_cat_output_acc: 0.1595 - val_num_output_acc: 0.4958\n",
      "Epoch 29/50\n",
      "20029/20029 [==============================] - 2s 96us/step - loss: 2.9391 - cat_output_loss: 2.5007 - num_output_loss: 0.4384 - cat_output_acc: 0.2193 - num_output_acc: 0.4075 - val_loss: 3.1921 - val_cat_output_loss: 2.7756 - val_num_output_loss: 0.4165 - val_cat_output_acc: 0.1565 - val_num_output_acc: 0.2620\n",
      "Epoch 30/50\n",
      "20029/20029 [==============================] - 2s 96us/step - loss: 2.7904 - cat_output_loss: 2.4784 - num_output_loss: 0.3120 - cat_output_acc: 0.2245 - num_output_acc: 0.3329 - val_loss: 3.0251 - val_cat_output_loss: 2.7775 - val_num_output_loss: 0.2476 - val_cat_output_acc: 0.1558 - val_num_output_acc: 0.3241\n",
      "[['주간' '수' 1.0078984 '1.0350806' 0.0 0.0 0.0 '인천' '서구' '차대차' '측면충돌'\n",
      "  '중앙선 침범' '단일로' '기타단일로' '자전거' '화물차']\n",
      " ['야간' '월' 1.3673661 '3.480938' 1.0 2.0 0.0 '전북' '익산시' '차대차' '기타'\n",
      "  '안전운전 의무 불이행' '단일로' '기타단일로' '승용차' '화물차']]\n",
      "\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 3s 143us/step - loss: 5.4139 - cat_output_loss: 4.8797 - num_output_loss: 0.5343 - cat_output_acc: 0.0338 - num_output_acc: 0.5962 - val_loss: 4.3757 - val_cat_output_loss: 3.9307 - val_num_output_loss: 0.4450 - val_cat_output_acc: 0.0938 - val_num_output_acc: 0.7566\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 3.8548 - cat_output_loss: 3.2557 - num_output_loss: 0.5992 - cat_output_acc: 0.1228 - num_output_acc: 0.6009 - val_loss: 3.3517 - val_cat_output_loss: 2.8425 - val_num_output_loss: 0.5093 - val_cat_output_acc: 0.1398 - val_num_output_acc: 0.6484\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 3.4105 - cat_output_loss: 2.8753 - num_output_loss: 0.5352 - cat_output_acc: 0.1360 - num_output_acc: 0.7246 - val_loss: 3.2969 - val_cat_output_loss: 2.7750 - val_num_output_loss: 0.5219 - val_cat_output_acc: 0.1410 - val_num_output_acc: 0.7372\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 3.2738 - cat_output_loss: 2.8002 - num_output_loss: 0.4737 - cat_output_acc: 0.1474 - num_output_acc: 0.6722 - val_loss: 3.2319 - val_cat_output_loss: 2.7612 - val_num_output_loss: 0.4707 - val_cat_output_acc: 0.1524 - val_num_output_acc: 0.8492\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 3.3298 - cat_output_loss: 2.7713 - num_output_loss: 0.5585 - cat_output_acc: 0.1522 - num_output_acc: 0.7371 - val_loss: 3.3168 - val_cat_output_loss: 2.7185 - val_num_output_loss: 0.5983 - val_cat_output_acc: 0.1516 - val_num_output_acc: 0.4619\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 3.2310 - cat_output_loss: 2.7366 - num_output_loss: 0.4944 - cat_output_acc: 0.1537 - num_output_acc: 0.6516 - val_loss: 3.2260 - val_cat_output_loss: 2.7137 - val_num_output_loss: 0.5123 - val_cat_output_acc: 0.1560 - val_num_output_acc: 0.8944\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 3.2136 - cat_output_loss: 2.7171 - num_output_loss: 0.4965 - cat_output_acc: 0.1590 - num_output_acc: 0.7371 - val_loss: 3.2665 - val_cat_output_loss: 2.7120 - val_num_output_loss: 0.5545 - val_cat_output_acc: 0.1508 - val_num_output_acc: 0.6917\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 3.1880 - cat_output_loss: 2.6968 - num_output_loss: 0.4911 - cat_output_acc: 0.1623 - num_output_acc: 0.6948 - val_loss: 3.1804 - val_cat_output_loss: 2.7154 - val_num_output_loss: 0.4650 - val_cat_output_acc: 0.1579 - val_num_output_acc: 0.6623\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 3.3290 - cat_output_loss: 2.6967 - num_output_loss: 0.6323 - cat_output_acc: 0.1572 - num_output_acc: 0.7194 - val_loss: 3.2129 - val_cat_output_loss: 2.7185 - val_num_output_loss: 0.4943 - val_cat_output_acc: 0.1562 - val_num_output_acc: 0.7650\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 3.1907 - cat_output_loss: 2.6780 - num_output_loss: 0.5128 - cat_output_acc: 0.1680 - num_output_acc: 0.6959 - val_loss: 3.1331 - val_cat_output_loss: 2.7051 - val_num_output_loss: 0.4280 - val_cat_output_acc: 0.1558 - val_num_output_acc: 0.4726\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 3.1889 - cat_output_loss: 2.6669 - num_output_loss: 0.5219 - cat_output_acc: 0.1675 - num_output_acc: 0.6596 - val_loss: 3.2295 - val_cat_output_loss: 2.7054 - val_num_output_loss: 0.5241 - val_cat_output_acc: 0.1577 - val_num_output_acc: 0.5425\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 3.1601 - cat_output_loss: 2.6546 - num_output_loss: 0.5055 - cat_output_acc: 0.1714 - num_output_acc: 0.6320 - val_loss: 3.0993 - val_cat_output_loss: 2.7039 - val_num_output_loss: 0.3954 - val_cat_output_acc: 0.1639 - val_num_output_acc: 0.5669\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 3.1947 - cat_output_loss: 2.6423 - num_output_loss: 0.5524 - cat_output_acc: 0.1788 - num_output_acc: 0.5624 - val_loss: 3.3483 - val_cat_output_loss: 2.7064 - val_num_output_loss: 0.6419 - val_cat_output_acc: 0.1603 - val_num_output_acc: 0.2664\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 3.1510 - cat_output_loss: 2.6324 - num_output_loss: 0.5186 - cat_output_acc: 0.1762 - num_output_acc: 0.5557 - val_loss: 3.1759 - val_cat_output_loss: 2.7020 - val_num_output_loss: 0.4739 - val_cat_output_acc: 0.1556 - val_num_output_acc: 0.3359\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 3.0957 - cat_output_loss: 2.6175 - num_output_loss: 0.4782 - cat_output_acc: 0.1800 - num_output_acc: 0.5822 - val_loss: 3.2659 - val_cat_output_loss: 2.7218 - val_num_output_loss: 0.5441 - val_cat_output_acc: 0.1494 - val_num_output_acc: 0.5274\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 3.1847 - cat_output_loss: 2.6076 - num_output_loss: 0.5771 - cat_output_acc: 0.1878 - num_output_acc: 0.5317 - val_loss: 3.1441 - val_cat_output_loss: 2.7033 - val_num_output_loss: 0.4408 - val_cat_output_acc: 0.1571 - val_num_output_acc: 0.7372\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 3.1508 - cat_output_loss: 2.5925 - num_output_loss: 0.5583 - cat_output_acc: 0.1898 - num_output_acc: 0.5961 - val_loss: 3.4545 - val_cat_output_loss: 2.7176 - val_num_output_loss: 0.7369 - val_cat_output_acc: 0.1550 - val_num_output_acc: 0.4960\n",
      "Epoch 18/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 3.1361 - cat_output_loss: 2.5909 - num_output_loss: 0.5452 - cat_output_acc: 0.1930 - num_output_acc: 0.4815 - val_loss: 3.1764 - val_cat_output_loss: 2.7110 - val_num_output_loss: 0.4654 - val_cat_output_acc: 0.1548 - val_num_output_acc: 0.3626\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20029/20029 [==============================] - 2s 95us/step - loss: 3.0903 - cat_output_loss: 2.5689 - num_output_loss: 0.5213 - cat_output_acc: 0.1930 - num_output_acc: 0.4890 - val_loss: 3.2173 - val_cat_output_loss: 2.7273 - val_num_output_loss: 0.4900 - val_cat_output_acc: 0.1528 - val_num_output_acc: 0.7187\n",
      "Epoch 20/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 3.1079 - cat_output_loss: 2.5622 - num_output_loss: 0.5457 - cat_output_acc: 0.1983 - num_output_acc: 0.4657 - val_loss: 3.4698 - val_cat_output_loss: 2.7159 - val_num_output_loss: 0.7539 - val_cat_output_acc: 0.1591 - val_num_output_acc: 0.3824\n",
      "Epoch 21/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 3.0485 - cat_output_loss: 2.5445 - num_output_loss: 0.5040 - cat_output_acc: 0.2060 - num_output_acc: 0.4295 - val_loss: 3.1415 - val_cat_output_loss: 2.7272 - val_num_output_loss: 0.4143 - val_cat_output_acc: 0.1577 - val_num_output_acc: 0.2578\n",
      "Epoch 22/50\n",
      "20029/20029 [==============================] - 2s 96us/step - loss: 3.1480 - cat_output_loss: 2.5416 - num_output_loss: 0.6064 - cat_output_acc: 0.2039 - num_output_acc: 0.4573 - val_loss: 3.1843 - val_cat_output_loss: 2.7365 - val_num_output_loss: 0.4478 - val_cat_output_acc: 0.1544 - val_num_output_acc: 0.1567\n",
      "Epoch 23/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 3.0137 - cat_output_loss: 2.5246 - num_output_loss: 0.4891 - cat_output_acc: 0.2142 - num_output_acc: 0.4110 - val_loss: 3.2338 - val_cat_output_loss: 2.7412 - val_num_output_loss: 0.4927 - val_cat_output_acc: 0.1510 - val_num_output_acc: 0.2624\n",
      "Epoch 24/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 2.9789 - cat_output_loss: 2.4979 - num_output_loss: 0.4810 - cat_output_acc: 0.2163 - num_output_acc: 0.4692 - val_loss: 3.1593 - val_cat_output_loss: 2.7580 - val_num_output_loss: 0.4014 - val_cat_output_acc: 0.1516 - val_num_output_acc: 0.2171\n",
      "Epoch 25/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 2.9185 - cat_output_loss: 2.4845 - num_output_loss: 0.4340 - cat_output_acc: 0.2229 - num_output_acc: 0.4338 - val_loss: 3.3741 - val_cat_output_loss: 2.7603 - val_num_output_loss: 0.6138 - val_cat_output_acc: 0.1522 - val_num_output_acc: 0.1847\n",
      "Epoch 26/50\n",
      "20029/20029 [==============================] - 2s 96us/step - loss: 2.9496 - cat_output_loss: 2.4696 - num_output_loss: 0.4801 - cat_output_acc: 0.2250 - num_output_acc: 0.4508 - val_loss: 3.3202 - val_cat_output_loss: 2.7814 - val_num_output_loss: 0.5388 - val_cat_output_acc: 0.1452 - val_num_output_acc: 0.1701\n",
      "Epoch 27/50\n",
      "20029/20029 [==============================] - 2s 96us/step - loss: 2.9124 - cat_output_loss: 2.4640 - num_output_loss: 0.4483 - cat_output_acc: 0.2298 - num_output_acc: 0.4470 - val_loss: 3.1542 - val_cat_output_loss: 2.7720 - val_num_output_loss: 0.3822 - val_cat_output_acc: 0.1506 - val_num_output_acc: 0.6643\n",
      "Epoch 28/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 2.9551 - cat_output_loss: 2.4438 - num_output_loss: 0.5113 - cat_output_acc: 0.2308 - num_output_acc: 0.5072 - val_loss: 3.2861 - val_cat_output_loss: 2.7904 - val_num_output_loss: 0.4958 - val_cat_output_acc: 0.1520 - val_num_output_acc: 0.2666\n",
      "Epoch 29/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 2.8718 - cat_output_loss: 2.4323 - num_output_loss: 0.4395 - cat_output_acc: 0.2405 - num_output_acc: 0.4940 - val_loss: 3.2125 - val_cat_output_loss: 2.7983 - val_num_output_loss: 0.4142 - val_cat_output_acc: 0.1474 - val_num_output_acc: 0.8982\n",
      "Epoch 30/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 2.9298 - cat_output_loss: 2.4301 - num_output_loss: 0.4998 - cat_output_acc: 0.2396 - num_output_acc: 0.5710 - val_loss: 3.2941 - val_cat_output_loss: 2.7949 - val_num_output_loss: 0.4992 - val_cat_output_acc: 0.1500 - val_num_output_acc: 0.3752\n",
      "Epoch 31/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 2.8238 - cat_output_loss: 2.3993 - num_output_loss: 0.4246 - cat_output_acc: 0.2503 - num_output_acc: 0.6229 - val_loss: 3.5742 - val_cat_output_loss: 2.8012 - val_num_output_loss: 0.7730 - val_cat_output_acc: 0.1474 - val_num_output_acc: 0.8586\n",
      "Epoch 32/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 3.1732 - cat_output_loss: 2.3982 - num_output_loss: 0.7750 - cat_output_acc: 0.2527 - num_output_acc: 0.6965 - val_loss: 3.2615 - val_cat_output_loss: 2.8324 - val_num_output_loss: 0.4292 - val_cat_output_acc: 0.1460 - val_num_output_acc: 0.9046\n",
      "[['야간' '일' 1.0 2.0 '0.19988191' '0.13439271' 0.0 '대구' '동구' '차대차' '측면충돌'\n",
      "  '안전운전 의무 불이행' '단일로' '기타단일로' '승용차' '승용차']\n",
      " ['주간' '일' 1.0 6.0 '1.228915' '3.0063574' 0.0 '광주' '북구' '차대차' '추돌'\n",
      "  '안전운전 의무 불이행' '교차로' '교차로부근' '승용차' '승용차']\n",
      " ['주간' '수' 1.0 4.0 '0.98057556' '0.6395524' 0.0 '서울' '영등포구' '차대차' '추돌'\n",
      "  '안전운전 의무 불이행' '단일로' '기타단일로' '화물차' '화물차']]\n",
      "\n",
      "11 ['발생지시도', '발생지시군구'] [35, 39]\n",
      "\n",
      "12 ['요일', '사고유형_대분류', '사고유형_중분류'] [40, 41]\n",
      "\n",
      "13 ['요일', '사고유형_중분류', '법규위반', '도로형태_대분류'] [42, 44]\n",
      "\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 3s 149us/step - loss: 0.7077 - cat_output_loss: 0.3252 - num_output_loss: 0.3825 - cat_output_acc: 0.8499 - num_output_acc: 0.5147 - val_loss: 0.5317 - val_cat_output_loss: 0.2716 - val_num_output_loss: 0.2600 - val_cat_output_acc: 0.8655 - val_num_output_acc: 0.2600\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 0.5093 - cat_output_loss: 0.2693 - num_output_loss: 0.2400 - cat_output_acc: 0.8664 - num_output_acc: 0.5265 - val_loss: 0.8696 - val_cat_output_loss: 0.2635 - val_num_output_loss: 0.6061 - val_cat_output_acc: 0.8727 - val_num_output_acc: 0.9523\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 0.6706 - cat_output_loss: 0.2646 - num_output_loss: 0.4060 - cat_output_acc: 0.8738 - num_output_acc: 0.5115 - val_loss: 0.3698 - val_cat_output_loss: 0.2588 - val_num_output_loss: 0.1110 - val_cat_output_acc: 0.8707 - val_num_output_acc: 0.8353\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 0.4872 - cat_output_loss: 0.2573 - num_output_loss: 0.2299 - cat_output_acc: 0.8755 - num_output_acc: 0.5612 - val_loss: 0.3679 - val_cat_output_loss: 0.2568 - val_num_output_loss: 0.1111 - val_cat_output_acc: 0.8700 - val_num_output_acc: 0.7268\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 0.5842 - cat_output_loss: 0.2553 - num_output_loss: 0.3290 - cat_output_acc: 0.8747 - num_output_acc: 0.6013 - val_loss: 0.5198 - val_cat_output_loss: 0.2554 - val_num_output_loss: 0.2644 - val_cat_output_acc: 0.8725 - val_num_output_acc: 0.9565\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 0.5447 - cat_output_loss: 0.2544 - num_output_loss: 0.2903 - cat_output_acc: 0.8760 - num_output_acc: 0.5810 - val_loss: 0.6347 - val_cat_output_loss: 0.2534 - val_num_output_loss: 0.3813 - val_cat_output_acc: 0.8756 - val_num_output_acc: 0.2600\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.6116 - cat_output_loss: 0.2528 - num_output_loss: 0.3588 - cat_output_acc: 0.8767 - num_output_acc: 0.5850 - val_loss: 1.1794 - val_cat_output_loss: 0.2528 - val_num_output_loss: 0.9266 - val_cat_output_acc: 0.8725 - val_num_output_acc: 0.9998\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.5204 - cat_output_loss: 0.2514 - num_output_loss: 0.2690 - cat_output_acc: 0.8778 - num_output_acc: 0.5910 - val_loss: 0.3656 - val_cat_output_loss: 0.2497 - val_num_output_loss: 0.1159 - val_cat_output_acc: 0.8795 - val_num_output_acc: 0.9998\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 0.5206 - cat_output_loss: 0.2486 - num_output_loss: 0.2719 - cat_output_acc: 0.8796 - num_output_acc: 0.5951 - val_loss: 0.9344 - val_cat_output_loss: 0.2486 - val_num_output_loss: 0.6858 - val_cat_output_acc: 0.8789 - val_num_output_acc: 0.9521\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 2s 91us/step - loss: 0.5702 - cat_output_loss: 0.2475 - num_output_loss: 0.3227 - cat_output_acc: 0.8814 - num_output_acc: 0.6325 - val_loss: 0.7410 - val_cat_output_loss: 0.2487 - val_num_output_loss: 0.4923 - val_cat_output_acc: 0.8798 - val_num_output_acc: 0.2602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 2s 91us/step - loss: 0.8651 - cat_output_loss: 0.2483 - num_output_loss: 0.6168 - cat_output_acc: 0.8816 - num_output_acc: 0.5935 - val_loss: 0.3742 - val_cat_output_loss: 0.2494 - val_num_output_loss: 0.1248 - val_cat_output_acc: 0.8801 - val_num_output_acc: 0.4343\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.5134 - cat_output_loss: 0.2453 - num_output_loss: 0.2681 - cat_output_acc: 0.8832 - num_output_acc: 0.6248 - val_loss: 0.3544 - val_cat_output_loss: 0.2480 - val_num_output_loss: 0.1064 - val_cat_output_acc: 0.8805 - val_num_output_acc: 0.9966\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.4476 - cat_output_loss: 0.2437 - num_output_loss: 0.2039 - cat_output_acc: 0.8845 - num_output_acc: 0.5882 - val_loss: 0.4467 - val_cat_output_loss: 0.2472 - val_num_output_loss: 0.1994 - val_cat_output_acc: 0.8811 - val_num_output_acc: 0.9980\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.5439 - cat_output_loss: 0.2429 - num_output_loss: 0.3010 - cat_output_acc: 0.8853 - num_output_acc: 0.6048 - val_loss: 0.3964 - val_cat_output_loss: 0.2481 - val_num_output_loss: 0.1483 - val_cat_output_acc: 0.8805 - val_num_output_acc: 0.6577\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 0.4761 - cat_output_loss: 0.2411 - num_output_loss: 0.2350 - cat_output_acc: 0.8865 - num_output_acc: 0.6075 - val_loss: 0.6765 - val_cat_output_loss: 0.2481 - val_num_output_loss: 0.4284 - val_cat_output_acc: 0.8805 - val_num_output_acc: 0.8702\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.5080 - cat_output_loss: 0.2398 - num_output_loss: 0.2681 - cat_output_acc: 0.8877 - num_output_acc: 0.6100 - val_loss: 1.2304 - val_cat_output_loss: 0.2484 - val_num_output_loss: 0.9820 - val_cat_output_acc: 0.8814 - val_num_output_acc: 0.9930\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 0.5386 - cat_output_loss: 0.2381 - num_output_loss: 0.3004 - cat_output_acc: 0.8895 - num_output_acc: 0.6027 - val_loss: 0.4749 - val_cat_output_loss: 0.2490 - val_num_output_loss: 0.2259 - val_cat_output_acc: 0.8801 - val_num_output_acc: 0.6014\n",
      "Epoch 18/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.6253 - cat_output_loss: 0.2366 - num_output_loss: 0.3887 - cat_output_acc: 0.8899 - num_output_acc: 0.6412 - val_loss: 0.6251 - val_cat_output_loss: 0.2489 - val_num_output_loss: 0.3761 - val_cat_output_acc: 0.8801 - val_num_output_acc: 0.8774\n",
      "Epoch 19/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.5506 - cat_output_loss: 0.2352 - num_output_loss: 0.3154 - cat_output_acc: 0.8917 - num_output_acc: 0.6134 - val_loss: 0.3872 - val_cat_output_loss: 0.2510 - val_num_output_loss: 0.1362 - val_cat_output_acc: 0.8791 - val_num_output_acc: 0.9834\n",
      "Epoch 20/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.3994 - cat_output_loss: 0.2337 - num_output_loss: 0.1658 - cat_output_acc: 0.8921 - num_output_acc: 0.5914 - val_loss: 0.3639 - val_cat_output_loss: 0.2496 - val_num_output_loss: 0.1143 - val_cat_output_acc: 0.8807 - val_num_output_acc: 0.3019\n",
      "Epoch 21/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.5219 - cat_output_loss: 0.2316 - num_output_loss: 0.2903 - cat_output_acc: 0.8939 - num_output_acc: 0.6339 - val_loss: 0.8525 - val_cat_output_loss: 0.2507 - val_num_output_loss: 0.6018 - val_cat_output_acc: 0.8790 - val_num_output_acc: 0.3005\n",
      "Epoch 22/50\n",
      "20029/20029 [==============================] - 2s 91us/step - loss: 0.5336 - cat_output_loss: 0.2316 - num_output_loss: 0.3020 - cat_output_acc: 0.8943 - num_output_acc: 0.5919 - val_loss: 0.3806 - val_cat_output_loss: 0.2534 - val_num_output_loss: 0.1272 - val_cat_output_acc: 0.8802 - val_num_output_acc: 0.7328\n",
      "Epoch 23/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 0.4228 - cat_output_loss: 0.2283 - num_output_loss: 0.1945 - cat_output_acc: 0.8968 - num_output_acc: 0.5864 - val_loss: 0.3615 - val_cat_output_loss: 0.2549 - val_num_output_loss: 0.1066 - val_cat_output_acc: 0.8785 - val_num_output_acc: 0.5046\n",
      "Epoch 24/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.6045 - cat_output_loss: 0.2271 - num_output_loss: 0.3774 - cat_output_acc: 0.8970 - num_output_acc: 0.6058 - val_loss: 0.5355 - val_cat_output_loss: 0.2540 - val_num_output_loss: 0.2815 - val_cat_output_acc: 0.8787 - val_num_output_acc: 0.2602\n",
      "Epoch 25/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 0.4656 - cat_output_loss: 0.2260 - num_output_loss: 0.2396 - cat_output_acc: 0.8983 - num_output_acc: 0.5778 - val_loss: 0.3686 - val_cat_output_loss: 0.2544 - val_num_output_loss: 0.1143 - val_cat_output_acc: 0.8783 - val_num_output_acc: 0.5685\n",
      "Epoch 26/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.5835 - cat_output_loss: 0.2245 - num_output_loss: 0.3590 - cat_output_acc: 0.8986 - num_output_acc: 0.6036 - val_loss: 0.8705 - val_cat_output_loss: 0.2556 - val_num_output_loss: 0.6149 - val_cat_output_acc: 0.8786 - val_num_output_acc: 0.6422\n",
      "Epoch 27/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.4489 - cat_output_loss: 0.2234 - num_output_loss: 0.2255 - cat_output_acc: 0.8996 - num_output_acc: 0.5630 - val_loss: 0.4783 - val_cat_output_loss: 0.2583 - val_num_output_loss: 0.2200 - val_cat_output_acc: 0.8766 - val_num_output_acc: 0.9659\n",
      "Epoch 28/50\n",
      "20029/20029 [==============================] - 2s 91us/step - loss: 0.4533 - cat_output_loss: 0.2219 - num_output_loss: 0.2314 - cat_output_acc: 0.9003 - num_output_acc: 0.5526 - val_loss: 0.3768 - val_cat_output_loss: 0.2576 - val_num_output_loss: 0.1193 - val_cat_output_acc: 0.8765 - val_num_output_acc: 0.7328\n",
      "Epoch 29/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.4069 - cat_output_loss: 0.2199 - num_output_loss: 0.1870 - cat_output_acc: 0.9015 - num_output_acc: 0.5345 - val_loss: 0.3559 - val_cat_output_loss: 0.2555 - val_num_output_loss: 0.1004 - val_cat_output_acc: 0.8769 - val_num_output_acc: 0.4079\n",
      "Epoch 30/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.3619 - cat_output_loss: 0.2181 - num_output_loss: 0.1437 - cat_output_acc: 0.9027 - num_output_acc: 0.5363 - val_loss: 0.3719 - val_cat_output_loss: 0.2586 - val_num_output_loss: 0.1132 - val_cat_output_acc: 0.8770 - val_num_output_acc: 0.2600\n",
      "Epoch 31/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.4174 - cat_output_loss: 0.2163 - num_output_loss: 0.2011 - cat_output_acc: 0.9030 - num_output_acc: 0.5302 - val_loss: 0.5023 - val_cat_output_loss: 0.2638 - val_num_output_loss: 0.2385 - val_cat_output_acc: 0.8760 - val_num_output_acc: 0.2664\n",
      "Epoch 32/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.5048 - cat_output_loss: 0.2156 - num_output_loss: 0.2892 - cat_output_acc: 0.9038 - num_output_acc: 0.4952 - val_loss: 0.6719 - val_cat_output_loss: 0.2573 - val_num_output_loss: 0.4146 - val_cat_output_acc: 0.8773 - val_num_output_acc: 0.2652\n",
      "[['주간' '일' 0.99682194 '1.0207752' 0.0 0.0 0.0 '전북' '고창군' '차대사람' '기타'\n",
      "  '부당한 회전' '교차로' '교차로내' '화물차' '보행자']\n",
      " ['야간' '일' 1.116251 '3.564905' 1.0 1.0 0.0 '서울' '은평구' '차대차' '기타' '신호위반'\n",
      "  '교차로' '교차로내' '승용차' '승용차']]\n",
      "\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 3s 152us/step - loss: 1.5727 - cat_output_loss: 0.2855 - num_output_loss: 1.2872 - cat_output_acc: 0.8853 - num_output_acc: 0.9970 - val_loss: 1.1456 - val_cat_output_loss: 0.1940 - val_num_output_loss: 0.9516 - val_cat_output_acc: 0.9037 - val_num_output_acc: 1.0000\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 2s 97us/step - loss: 1.3769 - cat_output_loss: 0.1935 - num_output_loss: 1.1834 - cat_output_acc: 0.9030 - num_output_acc: 1.0000 - val_loss: 1.9100 - val_cat_output_loss: 0.1946 - val_num_output_loss: 1.7154 - val_cat_output_acc: 0.9062 - val_num_output_acc: 1.0000\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20029/20029 [==============================] - 2s 97us/step - loss: 1.3081 - cat_output_loss: 0.1651 - num_output_loss: 1.1430 - cat_output_acc: 0.9187 - num_output_acc: 1.0000 - val_loss: 2.8510 - val_cat_output_loss: 0.1479 - val_num_output_loss: 2.7031 - val_cat_output_acc: 0.9247 - val_num_output_acc: 1.0000\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 2s 94us/step - loss: 1.2373 - cat_output_loss: 0.1489 - num_output_loss: 1.0884 - cat_output_acc: 0.9244 - num_output_acc: 1.0000 - val_loss: 1.2341 - val_cat_output_loss: 0.1438 - val_num_output_loss: 1.0903 - val_cat_output_acc: 0.9273 - val_num_output_acc: 1.0000\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 1.1162 - cat_output_loss: 0.1433 - num_output_loss: 0.9729 - cat_output_acc: 0.9253 - num_output_acc: 1.0000 - val_loss: 1.0447 - val_cat_output_loss: 0.1394 - val_num_output_loss: 0.9053 - val_cat_output_acc: 0.9275 - val_num_output_acc: 1.0000\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 1.1069 - cat_output_loss: 0.1404 - num_output_loss: 0.9665 - cat_output_acc: 0.9279 - num_output_acc: 1.0000 - val_loss: 1.2178 - val_cat_output_loss: 0.1380 - val_num_output_loss: 1.0798 - val_cat_output_acc: 0.9313 - val_num_output_acc: 1.0000\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.9770 - cat_output_loss: 0.1366 - num_output_loss: 0.8404 - cat_output_acc: 0.9308 - num_output_acc: 1.0000 - val_loss: 1.2857 - val_cat_output_loss: 0.1345 - val_num_output_loss: 1.1512 - val_cat_output_acc: 0.9332 - val_num_output_acc: 1.0000\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 1.0877 - cat_output_loss: 0.1363 - num_output_loss: 0.9514 - cat_output_acc: 0.9323 - num_output_acc: 1.0000 - val_loss: 1.2705 - val_cat_output_loss: 0.1344 - val_num_output_loss: 1.1361 - val_cat_output_acc: 0.9347 - val_num_output_acc: 1.0000\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.9055 - cat_output_loss: 0.1329 - num_output_loss: 0.7726 - cat_output_acc: 0.9336 - num_output_acc: 1.0000 - val_loss: 1.1740 - val_cat_output_loss: 0.1312 - val_num_output_loss: 1.0428 - val_cat_output_acc: 0.9362 - val_num_output_acc: 1.0000\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 0.9524 - cat_output_loss: 0.1332 - num_output_loss: 0.8192 - cat_output_acc: 0.9331 - num_output_acc: 1.0000 - val_loss: 1.2240 - val_cat_output_loss: 0.1294 - val_num_output_loss: 1.0946 - val_cat_output_acc: 0.9371 - val_num_output_acc: 1.0000\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.9799 - cat_output_loss: 0.1306 - num_output_loss: 0.8493 - cat_output_acc: 0.9347 - num_output_acc: 1.0000 - val_loss: 1.7115 - val_cat_output_loss: 0.1285 - val_num_output_loss: 1.5830 - val_cat_output_acc: 0.9345 - val_num_output_acc: 1.0000\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 0.9125 - cat_output_loss: 0.1299 - num_output_loss: 0.7827 - cat_output_acc: 0.9349 - num_output_acc: 1.0000 - val_loss: 1.6983 - val_cat_output_loss: 0.1262 - val_num_output_loss: 1.5721 - val_cat_output_acc: 0.9378 - val_num_output_acc: 1.0000\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 0.6921 - cat_output_loss: 0.1272 - num_output_loss: 0.5649 - cat_output_acc: 0.9359 - num_output_acc: 1.0000 - val_loss: 1.2949 - val_cat_output_loss: 0.1231 - val_num_output_loss: 1.1719 - val_cat_output_acc: 0.9386 - val_num_output_acc: 1.0000\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.6675 - cat_output_loss: 0.1246 - num_output_loss: 0.5430 - cat_output_acc: 0.9374 - num_output_acc: 0.9999 - val_loss: 1.8770 - val_cat_output_loss: 0.1233 - val_num_output_loss: 1.7537 - val_cat_output_acc: 0.9390 - val_num_output_acc: 1.0000\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 1.2341 - cat_output_loss: 0.1260 - num_output_loss: 1.1081 - cat_output_acc: 0.9370 - num_output_acc: 0.9999 - val_loss: 1.8123 - val_cat_output_loss: 0.1238 - val_num_output_loss: 1.6885 - val_cat_output_acc: 0.9379 - val_num_output_acc: 1.0000\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.7210 - cat_output_loss: 0.1245 - num_output_loss: 0.5965 - cat_output_acc: 0.9381 - num_output_acc: 0.9998 - val_loss: 1.7261 - val_cat_output_loss: 0.1229 - val_num_output_loss: 1.6032 - val_cat_output_acc: 0.9390 - val_num_output_acc: 1.0000\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.6916 - cat_output_loss: 0.1236 - num_output_loss: 0.5680 - cat_output_acc: 0.9380 - num_output_acc: 0.9998 - val_loss: 1.1184 - val_cat_output_loss: 0.1218 - val_num_output_loss: 0.9967 - val_cat_output_acc: 0.9396 - val_num_output_acc: 1.0000\n",
      "Epoch 18/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.6696 - cat_output_loss: 0.1225 - num_output_loss: 0.5472 - cat_output_acc: 0.9389 - num_output_acc: 1.0000 - val_loss: 1.1871 - val_cat_output_loss: 0.1215 - val_num_output_loss: 1.0656 - val_cat_output_acc: 0.9394 - val_num_output_acc: 1.0000\n",
      "Epoch 19/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.7718 - cat_output_loss: 0.1218 - num_output_loss: 0.6499 - cat_output_acc: 0.9385 - num_output_acc: 0.9996 - val_loss: 1.3087 - val_cat_output_loss: 0.1212 - val_num_output_loss: 1.1874 - val_cat_output_acc: 0.9396 - val_num_output_acc: 1.0000\n",
      "Epoch 20/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.6818 - cat_output_loss: 0.1215 - num_output_loss: 0.5602 - cat_output_acc: 0.9396 - num_output_acc: 0.9999 - val_loss: 1.2687 - val_cat_output_loss: 0.1213 - val_num_output_loss: 1.1473 - val_cat_output_acc: 0.9400 - val_num_output_acc: 1.0000\n",
      "Epoch 21/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 0.5751 - cat_output_loss: 0.1205 - num_output_loss: 0.4546 - cat_output_acc: 0.9397 - num_output_acc: 1.0000 - val_loss: 1.1676 - val_cat_output_loss: 0.1203 - val_num_output_loss: 1.0473 - val_cat_output_acc: 0.9412 - val_num_output_acc: 1.0000\n",
      "Epoch 22/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 0.6007 - cat_output_loss: 0.1199 - num_output_loss: 0.4807 - cat_output_acc: 0.9400 - num_output_acc: 1.0000 - val_loss: 1.4233 - val_cat_output_loss: 0.1197 - val_num_output_loss: 1.3036 - val_cat_output_acc: 0.9404 - val_num_output_acc: 1.0000\n",
      "Epoch 23/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 0.5301 - cat_output_loss: 0.1190 - num_output_loss: 0.4111 - cat_output_acc: 0.9403 - num_output_acc: 1.0000 - val_loss: 1.3832 - val_cat_output_loss: 0.1202 - val_num_output_loss: 1.2630 - val_cat_output_acc: 0.9406 - val_num_output_acc: 1.0000\n",
      "Epoch 24/50\n",
      "20029/20029 [==============================] - 2s 93us/step - loss: 0.5206 - cat_output_loss: 0.1197 - num_output_loss: 0.4009 - cat_output_acc: 0.9401 - num_output_acc: 1.0000 - val_loss: 1.1369 - val_cat_output_loss: 0.1197 - val_num_output_loss: 1.0172 - val_cat_output_acc: 0.9409 - val_num_output_acc: 1.0000\n",
      "Epoch 25/50\n",
      "20029/20029 [==============================] - 2s 92us/step - loss: 0.6191 - cat_output_loss: 0.1186 - num_output_loss: 0.5005 - cat_output_acc: 0.9402 - num_output_acc: 1.0000 - val_loss: 1.5091 - val_cat_output_loss: 0.1199 - val_num_output_loss: 1.3892 - val_cat_output_acc: 0.9405 - val_num_output_acc: 1.0000\n",
      "[['주간' '목' 1.0 0.98429453 0.07271293 0.0 0.0 '서울' '성동구' '차대차' '측면충돌'\n",
      "  '안전운전 의무 불이행' '교차로' '교차로내' '자전거' '승용차']\n",
      " ['주간' '일' 2.0 24.775509 7.6173716 9.0 1.0 '서울' '서초구' '차대차' '추돌'\n",
      "  '안전운전 의무 불이행' '단일로' '기타단일로' '승합차' '승용차']\n",
      " ['주간' '화' 1.0 0.9836405 0.081796944 0.0 0.0 '경북' '의성군' '차대차' '측면충돌'\n",
      "  '안전운전 의무 불이행' '교차로' '교차로내' '승용차' '원동기장치자전거']]\n"
     ]
    }
   ],
   "source": [
    "# train, set result in new array\n",
    "for (idx, case), case_range in zip(enumerate(Cases), test_ranges):\n",
    "    # for matching case number +1 to idx\n",
    "    print()\n",
    "    # numeric case\n",
    "    if (idx+1) <= 4:      \n",
    "        print(idx+1, case, case_range)\n",
    "#         Case_prediction = numeric_case(case, case_range[0], case_range[1])\n",
    "#         answer = setResult(x_test.loc[case_range[0]:case_range[1]].values, Case_prediction, [int(x) for x in range(case_range[0], case_range[1]+1)])\n",
    "#         test_arr = np.append(test_arr, answer, axis=0)\n",
    "        \n",
    "    # categorical case\n",
    "    elif ((idx+1) >= 5 and (idx+1) <= 8) or ((idx+1) >= 11 and (idx+1) <= 13):\n",
    "        print(idx+1, case, case_range)\n",
    "#         Case_prediction = categorical_case(case, case_range[0], case_range[1])\n",
    "#         answer = setResult(x_test.loc[case_range[0]:case_range[1]].values, Case_prediction, [int(x) for x in range(case_range[0], case_range[1]+1)])\n",
    "#         test_arr = np.append(test_arr, answer, axis=0)\n",
    "\n",
    "    # mixed case\n",
    "    elif (idx+1) == 9 or (idx+1) == 10 or (idx+1) >= 14:\n",
    "#         print(idx+1, case, case_range)\n",
    "        \n",
    "        if (idx+1) == 9 or (idx+1) == 10:\n",
    "            num_categories = 1  # number of categories for each case\n",
    "            \n",
    "        if (idx+1) == 14 or (idx+1) == 15:\n",
    "            num_categories = 2\n",
    "            \n",
    "        Case_prediction = mix_case(case, num_categories, case_range[0], case_range[1])\n",
    "        answer = setResult(x_test.loc[case_range[0]:case_range[1]].values, Case_prediction, [int(x) for x in range(case_range[0], case_range[1]+1)])\n",
    "        test_arr = np.append(test_arr, answer, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test_kor_1.csv','wb',) as f:\n",
    "        np.savetxt(f,  test_arr,  delimiter=\",\", fmt='%s', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
