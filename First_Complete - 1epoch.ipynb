{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일 불러오기\n",
    "학습 데이터, 테스트 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf) # print all numpy values\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, OneHotEncoder, MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['주야', '요일', '발생지시도', '발생지시군구', '사고유형_대분류', '사고유형_중분류', '법규위반', \n",
    "            '도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류']\n",
    "numerical = ['사상자수', '사망자수', '중상자수', '경상자수','부상신고자수']\n",
    "\n",
    "x_train_num = pd.read_csv('./교통사망사고정보/Kor_Train_교통사망사고정보(12.1~17.6).csv',encoding='cp949', usecols=numerical)\n",
    "\n",
    "x_train_cat = pd.read_csv('./교통사망사고정보/Kor_Train_교통사망사고정보(12.1~17.6).csv',encoding='cp949', usecols=categorical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_num = pd.read_csv('./test_kor.csv',encoding='cp949', usecols=numerical)\n",
    "\n",
    "x_test_cat = pd.read_csv('./test_kor.csv',encoding='cp949', usecols=categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encdoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat((x_test_cat.dropna(), x_train_cat))\n",
    "# for col in all_data.select_dtypes(include=[np.object]).columns:\n",
    "#     print(col, all_data[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iron/.local/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  \n",
      "/home/iron/.local/lib/python3.5/site-packages/ipykernel_launcher.py:3: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for column in all_data.select_dtypes(include=[np.object]).columns:\n",
    "    x_train_cat[column] = x_train_cat[column].astype('category', categories = all_data[column].unique())\n",
    "    x_test_cat[column] = x_test_cat[column].astype('category', categories = all_data[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cat = pd.get_dummies(data=x_train_cat)\n",
    "x_test_cat = pd.get_dummies(data=x_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 328)\n",
      "(50, 328)\n"
     ]
    }
   ],
   "source": [
    "# One Encoding Shape 확인\n",
    "print(x_train_cat.shape)\n",
    "print(x_test_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Input, LSTM, concatenate, Dropout, Conv2D, MaxPool2D, Embedding, Reshape, Conv1D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras import metrics\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 328)\n",
      "(25037, 5)\n",
      "(50, 328)\n",
      "(50, 5)\n"
     ]
    }
   ],
   "source": [
    "# Train Data Shape\n",
    "print(x_train_cat.shape)\n",
    "print(x_train_num.shape)\n",
    "# Test Data Shape\n",
    "print(x_test_cat.shape)\n",
    "print(x_test_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric cases\n",
    "Case1 = ['사망자수','사상자수','경상자수']\n",
    "Case2 = ['사상자수', '중상자수', '부상신고자수']\n",
    "Case3 = ['사상자수', '중상자수', '경상자수' ]\n",
    "Case4 = ['사망자수', '사상자수', '중상자수' ]\n",
    "\n",
    "# Categorical cases\n",
    "Case5 = ['사고유형_대분류', '사고유형_중분류', '법규위반']\n",
    "Case6 = ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류']\n",
    "Case7 = ['도로형태_대분류', '도로형태', '당사자종별_2당_대분류']\n",
    "Case8 = ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류']\n",
    "Case11 = ['발생지시도', '발생지시군구']\n",
    "Case12 = ['요일', '사고유형_대분류', '사고유형_중분류']\n",
    "Case13 = ['요일', '사고유형_중분류', '법규위반', '도로형태_대분류']\n",
    "\n",
    "# Mixed cases\n",
    "Case9 = ['사망자수', '사상자수', '발생지시군구']\n",
    "Case10 = ['중상자수', '경상자수', '발생지시군구']\n",
    "Case14 = ['사망자수', '사상자수', '주야', '당사자종별_1당_대분류']\n",
    "Case15 = ['사상자수', '중상자수', '주야', '도로형태']\n",
    "\n",
    "Cases = [Case1, Case2, Case3, Case4, Case5, Case6, Case7, Case8, Case9, Case10,\n",
    "         Case11, Case12, Case13, Case14, Case15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case ranges\n",
    "\n",
    "case1_range = [0, 1]\n",
    "case2_range = [2, 3]\n",
    "case3_range = [4, 6]\n",
    "case4_range = [7, 9]\n",
    "case5_range = [10, 19]\n",
    "case6_range = [20, 22]\n",
    "case7_range = [23, 25]\n",
    "case8_range = [26, 29]\n",
    "case9_range = [30, 31]\n",
    "case10_range = [32, 34]\n",
    "case11_range = [35, 39]\n",
    "case12_range = [40, 41]\n",
    "case13_range = [42, 44]\n",
    "case14_range = [45, 46]\n",
    "case15_range = [47, 49]\n",
    "\n",
    "test_ranges = [case1_range, case2_range, case3_range, case4_range, case5_range, case6_range,\n",
    "             case7_range, case8_range, case9_range, case10_range, case11_range, case12_range,\n",
    "             case13_range, case14_range, case15_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['사망자수', '사상자수', '경상자수'] [0, 1]\n",
      "2 ['사상자수', '중상자수', '부상신고자수'] [2, 3]\n",
      "3 ['사상자수', '중상자수', '경상자수'] [4, 6]\n",
      "4 ['사망자수', '사상자수', '중상자수'] [7, 9]\n",
      "5 ['사고유형_대분류', '사고유형_중분류', '법규위반'] [10, 19]\n",
      "6 ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류'] [20, 22]\n",
      "7 ['도로형태_대분류', '도로형태', '당사자종별_2당_대분류'] [23, 25]\n",
      "8 ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류'] [26, 29]\n",
      "9 ['사망자수', '사상자수', '발생지시군구'] [30, 31]\n",
      "10 ['중상자수', '경상자수', '발생지시군구'] [32, 34]\n",
      "11 ['발생지시도', '발생지시군구'] [35, 39]\n",
      "12 ['요일', '사고유형_대분류', '사고유형_중분류'] [40, 41]\n",
      "13 ['요일', '사고유형_중분류', '법규위반', '도로형태_대분류'] [42, 44]\n",
      "14 ['사망자수', '사상자수', '주야', '당사자종별_1당_대분류'] [45, 46]\n",
      "15 ['사상자수', '중상자수', '주야', '도로형태'] [47, 49]\n"
     ]
    }
   ],
   "source": [
    "# train, set result in new array\n",
    "for (idx, case), range in zip(enumerate(Cases), test_ranges):\n",
    "    print(idx+1, case, range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 데이터 Case 함수\n",
    "\n",
    "def numeric_case(case, start, end):\n",
    "    \n",
    "    K.clear_session()\n",
    "    case_copy=case.copy()\n",
    "    \n",
    "    # Case 확인\n",
    "    print(\"Case:\", case)\n",
    "    \n",
    "    # Train Data\n",
    "    X = x_train_num.drop(columns=case)\n",
    "    X = pd.concat([X, x_train_cat], axis=1).values\n",
    "    \n",
    "    # Test Data\n",
    "    X_test = x_test_num.drop(columns=case)\n",
    "    X_test = pd.concat([X_test, x_test_cat],axis=1).values\n",
    "    \n",
    "    # Label Data\n",
    "    if '사상자수' in case:       \n",
    "        case_copy.remove('사상자수')\n",
    "        print('사상자제거:', case_copy) \n",
    "    Y = x_train_num[case_copy].values\n",
    "    \n",
    "    # Model define\n",
    "    num_input = Input(shape=(len(X[0]),), name='num_input')\n",
    "    x = Dense(512, activation='relu')(num_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    num_output = Dense(len(Y[0]), name='num_output')(x)\n",
    "\n",
    "    model = Model(inputs=num_input, outputs=num_output)\n",
    "\n",
    "    model.compile(optimizer='sgd',\n",
    "                  loss='mse',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=25, verbose=1, factor=0.5, min_lr=0.00000001)\n",
    "\n",
    "    callbacks = [\n",
    "        learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "        EarlyStopping('val_loss', patience=5)# val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(X, Y, epochs=1, batch_size=128, callbacks=callbacks, validation_split=0.2 )\n",
    "    \n",
    "    \n",
    "    # make a prediction\n",
    "    Y_test = model.predict(X_test[start:end+1])\n",
    "    \n",
    "    del model\n",
    "    \n",
    "    return Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 데이터 Case 함수\n",
    "\n",
    "def categorical_case(case, start, end):\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    # Case 확인\n",
    "    print(\"Case:\", case)\n",
    "    \n",
    "    col_name = [] # ex. '사고유형_대분류_차대차', '사고유형_대분류_차대사람', '사고유형_대분류_차량단독'\n",
    "    label_name = [] #  ex. '차대차', '차대사람', '차량단독\n",
    "    \n",
    "    # One Hot Encoding 후 Columns 이름과 Columns에 들어 있는 값 \n",
    "    for col in case:\n",
    "        label_name.extend(all_data[col].unique()) \n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)\n",
    "\n",
    "    # Train Data \n",
    "    X = x_train_cat.drop(columns=col_name)\n",
    "    X = pd.concat([X, x_train_num], axis=1).values\n",
    "\n",
    "    # Test Data\n",
    "    X_test = x_test_cat.drop(columns=col_name)\n",
    "    X_test = pd.concat([X_test, x_test_num],axis=1).values\n",
    "    \n",
    "    # Label Data\n",
    "    Y = x_train_cat[col_name].values\n",
    "    \n",
    "    # Model define\n",
    "    cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "    x = Dense(512, activation='relu')(cat_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    cat_output = Dense(len(Y[0]), activation='sigmoid', name='cat_output')(x)\n",
    "\n",
    "    model = Model(inputs=cat_input, outputs=cat_output)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=25, verbose=1, factor=0.5, min_lr=0.00000001)\n",
    "\n",
    "    callbacks = [\n",
    "        learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "        EarlyStopping('val_loss', patience=10), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "        ]\n",
    "\n",
    "    history = model.fit(X, Y, epochs=1, batch_size=128, callbacks=callbacks,validation_split=0.2 )\n",
    "    \n",
    "    # make a prediction\n",
    "    Y_test = model.predict(X_test[start:end+1])\n",
    "    \n",
    "\n",
    "    '''\n",
    "    예시 출력:\n",
    "        사고유형_대분류 : 차량단독\n",
    "        사고유형_중분류 : 공작물충돌\n",
    "        법규위반 : 안전운전 의무 불이행\n",
    "    '''\n",
    "    result = []\n",
    "    for cat in Y_test: \n",
    "        x_list = list(cat)\n",
    "        label_name_x = label_name.copy()\n",
    "        temp = []\n",
    "        for col in case:\n",
    "            print(col, ':', label_name_x[x_list.index(max(x_list[0:len(all_data[col].unique())]))] )\n",
    "            temp.append(label_name_x[x_list.index(max(x_list[0:len(all_data[col].unique())]))])\n",
    "            del x_list[:len(all_data[col].unique())]\n",
    "            del label_name_x[:len(all_data[col].unique())]\n",
    "        result.append(temp)\n",
    "        print()\n",
    "        \n",
    "    del model\n",
    "    \n",
    "    return np.array(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 믹스형 데이터 Case 함수\n",
    "\n",
    "def mix_case(case, n, start, end):\n",
    "    '''\n",
    "    case: Case에 해당되는 컬럼이 담긴 배열\n",
    "    n: 범주형 데이터 수\n",
    "    start: 해당 Case 테스트의 시작 인덱스\n",
    "    end: 해당 Case 테스트의 마지막 인덱스\n",
    "    '''\n",
    "    \n",
    "    case_copy=case.copy()\n",
    "    \n",
    "    # categorical\n",
    "    col_name = []\n",
    "    label_name = []\n",
    "    cat_name = case_copy[-n:]\n",
    "    \n",
    "    for col in case_copy[-n:]:\n",
    "        label_name.extend(all_data[col].unique()) \n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)\n",
    "    \n",
    "    Y_cat = x_train_cat[col_name].values\n",
    "    X1 = x_train_cat.drop(columns=col_name)\n",
    "    X_test1 = x_test_cat.drop(columns=col_name)\n",
    "    \n",
    "    # categorical columns 삭제\n",
    "    del case_copy[-n:]\n",
    "    \n",
    "    # numerical\n",
    "    X2 = x_train_num.drop(columns=case_copy)\n",
    "    X_test2 = x_test_num.drop(columns=case_copy)\n",
    "    \n",
    "    if '사상자수' in case: \n",
    "        case_copy.remove('사상자수')\n",
    "    Y_num = x_train_num[case_copy].values\n",
    "    \n",
    "    X = pd.concat([X1, X2], axis=1).values\n",
    "    X_test = pd.concat([X_test1, X_test2],axis=1).values\n",
    "    \n",
    "    # Model define\n",
    "    cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "    x = Dense(512, activation='relu')(cat_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    cat_output = Dense(len(Y_cat[0]), activation='softmax', name='cat_output')(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    num_output = Dense(len(Y_num[0]), name='num_output')(x)\n",
    "\n",
    "    model = Model(inputs=cat_input, outputs=[cat_output, num_output])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'cat_output': 'categorical_crossentropy', 'num_output': 'mse'},\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "    callbacks = [\n",
    "        learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "        EarlyStopping('val_loss', patience=20), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "    ]\n",
    "\n",
    "    history = model.fit(X, {'cat_output':Y_cat, 'num_output':Y_num}, epochs=1, batch_size=128, callbacks=callbacks,validation_split=0.2 )\n",
    "    \n",
    "    \n",
    "    # make a prediction\n",
    "    Y_test = model.predict(X_test[start:end+1])    \n",
    "    \n",
    "    result = []\n",
    "    for cat, num in zip(Y_test[0], Y_test[1]):\n",
    "        x_list = list(cat)\n",
    "        label_name_x = label_name.copy()\n",
    "        temp = []\n",
    "        for col in cat_name:\n",
    "            temp.append(label_name_x[x_list.index(max(x_list[0:len(all_data[col].unique())]))])\n",
    "            \n",
    "            # 출력한 Column과 데이터 삭제\n",
    "            del x_list[:len(all_data[col].unique())]\n",
    "            del label_name_x[:len(all_data[col].unique())]\n",
    "        temp.extend(num)\n",
    "        result.append(temp)\n",
    "        \n",
    "        \n",
    "#     print(np.array(result))\n",
    "    \n",
    "    return np.array(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set result array to each cases\n",
    "def setResult(arr, predict, case):\n",
    "    result_arr = arr\n",
    "    \n",
    "    if case == [int(x) for x in range(0, 2)]:\n",
    "        print(\"case1 activated\")\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 2] = predict[row, 0] # 사망자수\n",
    "            result_arr[row, 5] = predict[row, 1] # 사상자수            \n",
    "            result_arr[row, 3] = result_arr[row, 2] + result_arr[row, 4:7].sum() # 사상자수 = 사망자수 + (중상+경상+부상신고자수)\n",
    "        print(result_arr)\n",
    "            \n",
    "    elif case == [int(x) for x in range(2, 4)]:\n",
    "        print(\"case2 activated\")\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 4] = predict[row, 0]\n",
    "            result_arr[row, 6] = predict[row, 1]\n",
    "            result_arr[row, 3] = result_arr[row, 2] + result_arr[row, 4:7].sum()\n",
    "        print(result_arr)\n",
    "            \n",
    "    elif case == [int(x) for x in range(4, 7)]:\n",
    "        print(\"case3 activated\")\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 4] = predict[row, 0]\n",
    "            result_arr[row, 5] = predict[row, 1]\n",
    "            result_arr[row, 3] = result_arr[row, 2] + result_arr[row, 4:7].sum()\n",
    "        print(result_arr)\n",
    "            \n",
    "    elif case == [int(x) for x in range(7, 10)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 2] = predict[row, 0]\n",
    "            result_arr[row, 4] = predict[row, 1]\n",
    "            result_arr[row, 3] = result_arr[row, 2] + result_arr[row, 4:7].sum()\n",
    "            \n",
    "    elif case == [int(x) for x in range(10,20)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 9] = predict[row, 0] \n",
    "            result_arr[row, 10] = predict[row, 1] \n",
    "            result_arr[row, 11] = predict[row, 2] \n",
    "            print(result_arr[row, 11], predict[row, 2])\n",
    "            \n",
    "    elif case == [int(x) for x in range(20,23)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 12] = predict[row, 0] \n",
    "            result_arr[row, 13] = predict[row, 1] \n",
    "            result_arr[row, 14] = predict[row, 2] \n",
    "            \n",
    "    elif case == [int(x) for x in range(23,26)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 12] = predict[row, 0] \n",
    "            result_arr[row, 13] = predict[row, 1] \n",
    "            result_arr[row, 15] = predict[row, 2] \n",
    "    \n",
    "    elif case == [int(x) for x in range(26,30)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 12] = predict[row, 0] \n",
    "            result_arr[row, 13] = predict[row, 1] \n",
    "            result_arr[row, 14] = predict[row, 2] \n",
    "            result_arr[row, 15] = predict[row, 3] \n",
    "    \n",
    "    elif case == [int(x) for x in range(35,40)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 7] = predict[row, 0] \n",
    "            result_arr[row, 8] = predict[row, 1] \n",
    "        \n",
    "    elif case == [int(x) for x in range(40,42)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 1] = predict[row, 0] \n",
    "            result_arr[row, 9] = predict[row, 1] \n",
    "            result_arr[row, 10] = predict[row, 2] \n",
    "        \n",
    "    elif case == [int(x) for x in range(42,45)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 1] = predict[row, 0] \n",
    "            result_arr[row, 10] = predict[row, 1] \n",
    "            result_arr[row, 11] = predict[row, 2] \n",
    "            result_arr[row, 12] = predict[row, 3] \n",
    "    \n",
    "    elif case == [int(x) for x in range(30,32)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 2] = float(predict[row, 1])\n",
    "            result_arr[row, 3] = result_arr[row, 2] + result_arr[row, 4:7].sum()\n",
    "            result_arr[row, 8] = predict[row, 0]\n",
    "            \n",
    "    elif case == [int(x) for x in range(32,35)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 4] = predict[row, 1]\n",
    "            result_arr[row, 5] = predict[row, 2]\n",
    "            result_arr[row, 8] = predict[row, 0]\n",
    "            \n",
    "    elif case == [int(x) for x in range(45,47)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 0] = predict[row, 0]\n",
    "            result_arr[row, 2] = float(predict[row, 2])\n",
    "            result_arr[row, 14] = predict[row, 1]\n",
    "            result_arr[row, 3] = result_arr[row, 2] + result_arr[row, 4:7].sum()\n",
    "            \n",
    "    elif case == [int(x) for x in range(47,50)]:\n",
    "        for row in range(len(predict)):\n",
    "            result_arr[row, 0] = predict[row, 0]\n",
    "            result_arr[row, 4] = float(predict[row, 2])\n",
    "            result_arr[row, 13] = predict[row, 1]\n",
    "            result_arr[row, 3] = result_arr[row, 2] + result_arr[row, 4:7].sum()\n",
    "    \n",
    "    return result_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test = pd.read_csv('./test_kor.csv',encoding='cp949')\n",
    "\n",
    "# setResult(each case array, predict array, start to end in each case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['주야' '요일' '사망자수' '사상자수' '중상자수' '경상자수' '부상신고자수' '발생지시도' '발생지시군구'\n",
      "  '사고유형_대분류' '사고유형_중분류' '법규위반' '도로형태_대분류' '도로형태' '당사자종별_1당_대분류'\n",
      "  '당사자종별_2당_대분류']]\n"
     ]
    }
   ],
   "source": [
    "test_arr = np.array([x_test.columns.values])\n",
    "print(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['사망자수', '사상자수', '경상자수'] [0, 1]\n",
      "Case: ['사망자수', '사상자수', '경상자수']\n",
      "사상자제거: ['사망자수', '경상자수']\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/1\n",
      "20029/20029 [==============================] - 1s 49us/step - loss: 0.6921 - acc: 0.9403 - val_loss: 0.5867 - val_acc: 0.9507\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0d18c982fd88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mCase_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeric_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtest_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcase_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcase_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCase_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcase_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_arr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "# train, set result in new array\n",
    "for (idx, case), case_range in zip(enumerate(Cases), test_ranges):\n",
    "    # for matching case number +1 to idx\n",
    "    \n",
    "    # numeric case\n",
    "    if (idx+1) <= 4:      \n",
    "        print(idx+1, case, case_range)\n",
    "        Case_prediction = numeric_case(case, case_range[0], case_range[1])\n",
    "        test_arr = np.append(test_arr, setResult(x_test.loc[case_range[0]:case_range[1]].values, Case_prediction, [int(x) for x in range(case_range[0], case_range[1]+1)]), axis=0)\n",
    "        print(\"test_arr\")\n",
    "        print(test_arr)\n",
    "        print()\n",
    "        \n",
    "    # categorical case\n",
    "    elif ((idx+1) >= 5 and (idx+1) <= 8) or ((idx+1) >= 11 and (idx+1) <= 13):\n",
    "        print(idx+1, case, case_range)\n",
    "        Case_prediction = categorical_case(case, case_range[0], case_range[1])\n",
    "        test_arr = np.append(test_arr, setResult(x_test.loc[case_range[0]:case_range[1]].values, Case_prediction, [int(x) for x in range(case_range[0], case_range[1]+1)]), axis=0)\n",
    "\n",
    "    # mixed case\n",
    "    elif (idx+1) == 9 or (idx+1) == 10 or (idx+1) >= 14:\n",
    "        print(idx+1, case, case_range)\n",
    "        \n",
    "        if (idx+1) == 9 or (idx+1) == 10:\n",
    "            num_categories = 1  # number of categories for each case\n",
    "            \n",
    "        if (idx+1) == 14 or (idx+1) == 15:\n",
    "            num_categories = 2\n",
    "            \n",
    "        Case_prediction = mix_case(case, num_categories, case_range[0], case_range[1])\n",
    "        test_arr = np.append(test_arr, setResult(x_test.loc[case_range[0]:case_range[1]].values, Case_prediction, [int(x) for x in range(case_range[0], case_range[1]+1)]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test_kor_1.csv','wb',) as f:\n",
    "        np.savetxt(f,  test_arr,  delimiter=\",\", fmt='%s', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
