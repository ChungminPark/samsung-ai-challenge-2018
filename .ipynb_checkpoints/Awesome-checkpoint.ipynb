{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, OneHotEncoder, MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['주야', '요일', '발생지시도', '발생지시군구', '사고유형_대분류', '사고유형_중분류', '법규위반', \n",
    "            '도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류']\n",
    "numerical = ['사상자수', '사망자수', '중상자수', '경상자수','부상신고자수']\n",
    "\n",
    "x_train_num = pd.read_csv('./교통사망사고정보/Kor_Train_교통사망사고정보(12.1~17.6).csv',encoding='cp949', \n",
    "                              usecols=numerical)\n",
    "\n",
    "x_train_cat = pd.read_csv('./교통사망사고정보/Kor_Train_교통사망사고정보(12.1~17.6).csv',encoding='cp949',\n",
    "                               usecols=categorical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_num = pd.read_csv('./test_kor.csv',encoding='cp949', \n",
    "                              usecols=numerical)\n",
    "\n",
    "x_test_cat = pd.read_csv('./test_kor.csv',encoding='cp949',\n",
    "                               usecols=categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encdoing을 나열해서 만드는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat((x_test_cat.dropna(),x_train_cat))\n",
    "# for col in all_data.select_dtypes(include=[np.object]).columns:\n",
    "#     print(col, all_data[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iron/.local/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  \n",
      "/home/iron/.local/lib/python3.5/site-packages/ipykernel_launcher.py:3: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for column in all_data.select_dtypes(include=[np.object]).columns:\n",
    "    x_train_cat[column] = x_train_cat[column].astype('category', categories = all_data[column].unique())\n",
    "    x_test_cat[column] = x_test_cat[column].astype('category', categories = all_data[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cat = pd.get_dummies(data=x_train_cat)\n",
    "x_test_cat = pd.get_dummies(data=x_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 328)\n",
      "(50, 328)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_cat.shape)\n",
    "print(x_test_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Input, LSTM, concatenate, Dropout, Conv2D, MaxPool2D, Embedding, Reshape, Conv1D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras import metrics\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 328)\n",
      "(25037, 5)\n",
      "(50, 328)\n",
      "(50, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_cat.shape)\n",
    "print(x_train_num.shape)\n",
    "print(x_test_cat.shape)\n",
    "print(x_test_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric cases\n",
    "Case1 = ['사망자수','사상자수','경상자수']\n",
    "Case2 = ['사상자수', '중상자수', '부상신고자수']\n",
    "Case3 = ['사상자수', '중상자수', '경상자수' ]\n",
    "Case4 = ['사망자수', '사상자수', '중상자수' ]\n",
    "\n",
    "# Categorical cases\n",
    "Case5 = ['사고유형_대분류', '사고유형_중분류', '법규위반']\n",
    "Case6 = ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류']\n",
    "Case7 = ['도로형태_대분류', '도로형태', '당사자종별_2당_대분류']\n",
    "Case8 = ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류']\n",
    "Case11 = ['발생지시도', '발생지시군구']\n",
    "Case12 = ['요일', '사고유형_대분류', '사고유형_중분류']\n",
    "Case13 = ['요일', '사고유형_중분류', '법규위반', '도로형태_대분류']\n",
    "\n",
    "# Mixed cases\n",
    "Case9 = ['사망자수', '사상자수', '발생지시군구']\n",
    "Case10 = ['중상자수', '경상자수', '발생지시군구']\n",
    "Case14 = ['사망자수', '사상자수', '주야', '당사자종별_1당_대분류']\n",
    "Case15 = ['사상자수', '중상자수', '주야', '도로형태']\n",
    "\n",
    "Cases = [Case1, Case2, Case3, Case4, Case5, Case6, Case7, Case8, Case11, Case12, Case13,\n",
    "        Case9, Case10, Case14, Case15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 데이터 Case 함수\n",
    "\n",
    "def numeric_case(case, start, end):\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    print(\"Case:\", case)\n",
    "    X = x_train_num.drop(columns=case)\n",
    "    X_test = x_test_num.drop(columns=case)\n",
    "    \n",
    "    case_copy=case.copy()\n",
    "    if '사상자수' in case:       \n",
    "        case_copy.remove('사상자수')\n",
    "    print('사상자제거:', case_copy)\n",
    "    Y = x_train_num[case_copy].values\n",
    "    \n",
    "    # 수치형 데이터와 범주형 데이터 합치기\n",
    "    X = pd.concat([X, x_train_cat], axis=1).values\n",
    "    X_test = pd.concat([X_test, x_test_cat],axis=1).values\n",
    "    \n",
    "    print(X)\n",
    "    print(Y)\n",
    "    \n",
    "    # 모델 정의\n",
    "    num_input = Input(shape=(len(X[0]),), name='num_input')\n",
    "    x = Dense(512, activation='relu')(num_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    num_output = Dense(len(Y[0]), name='num_output')(x)\n",
    "\n",
    "    model = Model(inputs=num_input, outputs=num_output)\n",
    "\n",
    "    model.compile(optimizer='sgd',\n",
    "                  loss='mse',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                        patience=25, \n",
    "                                        verbose=1, \n",
    "                                        factor=0.5, \n",
    "                                        min_lr=0.00000001)\n",
    "\n",
    "    callbacks = [\n",
    "    #         learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "        EarlyStopping('val_loss', patience=5)# val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )\n",
    "    \n",
    "    \n",
    "    # make a prediction\n",
    "    Y_test = model.predict(X_test[start:end+1])\n",
    "    \n",
    "    # show the inputs and predicted outputs\n",
    "    print(\"X=%s, Predicted=%s\" % (X_test[range(start, end+1)],  Y_test ))\n",
    "    del model\n",
    "    \n",
    "    return Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 데이터 Case 함수\n",
    "\n",
    "def categorical_case(case, start, end):\n",
    "    col_name = [] # ex. '사고유형_대분류_차대차', '사고유형_대분류_차대사람', '사고유형_대분류_차량단독'\n",
    "    label_name = [] #  ex. '차대차', '차대사람', '차량단독\n",
    "    \n",
    "    for col in case:\n",
    "        label_name.extend(all_data[col].unique()) \n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)\n",
    "    \n",
    "    print('col_name:',col_name)\n",
    "    print('label_name:', label_name)\n",
    "                \n",
    "    Y = x_train_cat[col_name].values\n",
    "    X = x_train_cat.drop(columns=col_name)\n",
    "    X = pd.concat([X, x_train_num], axis=1).values\n",
    "\n",
    "    X_test = x_test_cat.drop(columns=col_name)\n",
    "    X_test = pd.concat([X_test, x_test_num],axis=1).values\n",
    "\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "\n",
    "    cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "    x = Dense(512, activation='relu')(cat_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    cat_output = Dense(len(Y[0]), activation='sigmoid', name='cat_output')(x)\n",
    "\n",
    "    model = Model(inputs=cat_input, outputs=cat_output)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                                patience=25, \n",
    "                                                verbose=1, \n",
    "                                                factor=0.5, \n",
    "                                                min_lr=0.00000001)\n",
    "\n",
    "    callbacks = [\n",
    "        learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "        EarlyStopping('val_loss', patience=10), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "        ]\n",
    "\n",
    "    history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )\n",
    "    \n",
    "    \n",
    "    # make a prediction\n",
    "    Y_test = model.predict(X_test[range(start, end+1)])\n",
    "    \n",
    "    # show the inputs and predicted outputs\n",
    "#     print(\"X=%s, Predicted=%s\" % (X_test[range(start, end+1)],  Y_test ))\n",
    "    \n",
    "            \n",
    "        \n",
    "    '''\n",
    "    예시 출력:\n",
    "        사고유형_대분류 : 차량단독\n",
    "        사고유형_중분류 : 공작물충돌\n",
    "        법규위반 : 안전운전 의무 불이행\n",
    "    '''\n",
    "    for val in Y_test: \n",
    "        x_list = list(val)\n",
    "        label_name_x = label_name.copy()\n",
    "        for col in case:\n",
    "            print(col, ':',label_name_x[x_list.index(max(x_list[0:len(all_data[col].unique())]))] )\n",
    "            del x_list[:len(all_data[col].unique())]\n",
    "            del label_name_x[:len(all_data[col].unique())]\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 믹스형 데이터 Case 함수\n",
    "\n",
    "def mix_case(case, n, start, end):\n",
    "    '''\n",
    "    case: Case에 해당되는 컬럼이 담긴 배열\n",
    "    n: 범주형 데이터 수\n",
    "    start: 해당 Case 테스트의 시작 인덱스\n",
    "    end: 해당 Case 테스트의 마지막 인덱스\n",
    "    '''\n",
    "    \n",
    "    case_copy=case.copy()\n",
    "    \n",
    "    # categorical\n",
    "    col_name = []\n",
    "    label_name = []\n",
    "    cat_name = case_copy[-n:]\n",
    "    \n",
    "    for col in case_copy[-n:]:\n",
    "        label_name.extend(all_data[col].unique()) \n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)\n",
    "    \n",
    "    Y_cat = x_train_cat[col_name].values\n",
    "    X1 = x_train_cat.drop(columns=col_name)\n",
    "    X_test1 = x_test_cat.drop(columns=col_name)\n",
    "    \n",
    "    # categorical columns 삭제\n",
    "    del case_copy[-n:]\n",
    "    \n",
    "    # numerical\n",
    "    X2 = x_train_num.drop(columns=case_copy)\n",
    "    X_test2 = x_test_num.drop(columns=case_copy)\n",
    "    if '사상자수' in case: \n",
    "        case_copy.remove('사상자수')\n",
    "    Y_num = x_train_num[case_copy].values\n",
    "    \n",
    "    X = pd.concat([X1, X2], axis=1).values\n",
    "    X_test = pd.concat([X_test1, X_test2],axis=1).values\n",
    "    print(Y_num.shape)\n",
    "    print(len(Y_num[0]))\n",
    "    \n",
    "    cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "    x = Dense(512, activation='relu')(cat_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    cat_output = Dense(len(Y_cat[0]), activation='softmax', name='cat_output')(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    num_output = Dense(len(Y_num[0]), name='num_output')(x)\n",
    "\n",
    "    model = Model(inputs=cat_input, outputs=[cat_output, num_output])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'cat_output': 'categorical_crossentropy', 'num_output': 'mse'},\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "    callbacks = [\n",
    "        learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "        EarlyStopping('val_loss', patience=20), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "    ]\n",
    "\n",
    "    history = model.fit(X, {'cat_output':Y_cat, 'num_output':Y_num}, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )\n",
    "    \n",
    "    \n",
    "    # make a prediction\n",
    "    Y_test = model.predict(X_test[start:end+1])\n",
    "    \n",
    "    # show the inputs and predicted outputs\n",
    "    print(\"X=%s, Predicted=%s\" % (X_test[start:end+1],  Y_test ))\n",
    "    \n",
    "    \n",
    "    \n",
    "    for val in Y_test[0]:\n",
    "        x_list = list(val)\n",
    "        label_name_x = label_name.copy()\n",
    "        for col in cat_name:\n",
    "            print(col, ':', label_name_x[x_list.index(max(x_list[0:len(all_data[col].unique())]))] )\n",
    "            # 출력한 Column과 데이터 삭제\n",
    "            del x_list[:len(all_data[col].unique())]\n",
    "            del label_name_x[:len(all_data[col].unique())]\n",
    "        print()\n",
    "        \n",
    "    for num in Y_test[1]:\n",
    "        print(case_copy, ':', num)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set result array to each cases\n",
    "def setResult(arr, predict, case):\n",
    "\n",
    "    result_arr = arr\n",
    "    if case == 'Case1':\n",
    "        result_arr[:, 2] = predict[:, 0]\n",
    "        result_arr[:, 5] = predict[:, 1]\n",
    "\n",
    "        result_arr[:, 3] = result_arr[:, 2].sum() + result_arr[:, 4:6].sum()\n",
    "\n",
    "    print(result_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314,)\n",
      "[0. 2.]\n",
      "[0. 3.]\n",
      "[0. 5.]\n",
      "[1. 2.]\n",
      "[1. 3.]\n",
      "[1. 5.]\n",
      "[2. 3.]\n",
      "[2. 4.]\n",
      "[2. 6.]\n",
      "[3. 3.]\n",
      "[3. 4.]\n",
      "[3. 6.]\n",
      "[4. 3.]\n",
      "[4. 4.]\n",
      "[4. 5.]\n",
      "[5. 3.]\n",
      "[5. 4.]\n",
      "[5. 5.]\n",
      "[6. 3.]\n",
      "[6. 4.]\n",
      "[6. 5.]\n",
      "[7. 2.]\n",
      "[7. 3.]\n",
      "[7. 4.]\n",
      "[8. 2.]\n",
      "[8. 3.]\n",
      "[8. 4.]\n",
      "[9. 2.]\n",
      "[9. 3.]\n",
      "[9. 4.]\n",
      "[10.  9.]\n",
      "[10. 10.]\n",
      "[10. 11.]\n",
      "[11.  9.]\n",
      "[11. 10.]\n",
      "[11. 11.]\n",
      "[12.  9.]\n",
      "[12. 10.]\n",
      "[12. 11.]\n",
      "[13.  9.]\n",
      "[13. 10.]\n",
      "[13. 11.]\n",
      "[14.  9.]\n",
      "[14. 10.]\n",
      "[14. 11.]\n",
      "[15.  9.]\n",
      "[15. 10.]\n",
      "[15. 11.]\n",
      "[16.  9.]\n",
      "[16. 10.]\n",
      "[16. 11.]\n",
      "[17.  9.]\n",
      "[17. 10.]\n",
      "[17. 11.]\n",
      "[18.  9.]\n",
      "[18. 10.]\n",
      "[18. 11.]\n",
      "[19.  9.]\n",
      "[19. 10.]\n",
      "[19. 11.]\n",
      "[20. 12.]\n",
      "[20. 13.]\n",
      "[20. 14.]\n",
      "[21. 12.]\n",
      "[21. 13.]\n",
      "[21. 14.]\n",
      "[22. 12.]\n",
      "[22. 13.]\n",
      "[22. 14.]\n",
      "[23. 12.]\n",
      "[23. 13.]\n",
      "[23. 15.]\n",
      "[24. 12.]\n",
      "[24. 13.]\n",
      "[24. 15.]\n",
      "[25. 12.]\n",
      "[25. 13.]\n",
      "[25. 15.]\n",
      "[26. 12.]\n",
      "[26. 13.]\n",
      "[26. 14.]\n",
      "[26. 15.]\n",
      "[27. 12.]\n",
      "[27. 13.]\n",
      "[27. 14.]\n",
      "[27. 15.]\n",
      "[28. 12.]\n",
      "[28. 13.]\n",
      "[28. 14.]\n",
      "[28. 15.]\n",
      "[29. 12.]\n",
      "[29. 13.]\n",
      "[29. 14.]\n",
      "[29. 15.]\n",
      "[30.  2.]\n",
      "[30.  3.]\n",
      "[30.  8.]\n",
      "[31.  2.]\n",
      "[31.  3.]\n",
      "[31.  8.]\n",
      "[32.  4.]\n",
      "[32.  5.]\n",
      "[32.  8.]\n",
      "[33.  4.]\n",
      "[33.  5.]\n",
      "[33.  8.]\n",
      "[34.  4.]\n",
      "[34.  5.]\n",
      "[34.  8.]\n",
      "[35.  7.]\n",
      "[35.  8.]\n",
      "[36.  7.]\n",
      "[36.  8.]\n",
      "[37.  7.]\n",
      "[37.  8.]\n",
      "[38.  7.]\n",
      "[38.  8.]\n",
      "[39.  7.]\n",
      "[39.  8.]\n",
      "[40.  1.]\n",
      "[40.  9.]\n",
      "[40. 10.]\n",
      "[41.  1.]\n",
      "[41.  9.]\n",
      "[41. 10.]\n",
      "[42.  1.]\n",
      "[42. 10.]\n",
      "[42. 11.]\n",
      "[42. 12.]\n",
      "[43.  1.]\n",
      "[43. 10.]\n",
      "[43. 11.]\n",
      "[43. 12.]\n",
      "[44.  1.]\n",
      "[44. 10.]\n",
      "[44. 11.]\n",
      "[44. 12.]\n",
      "[45.  0.]\n",
      "[45.  2.]\n",
      "[45.  3.]\n",
      "[45. 14.]\n",
      "[46.  0.]\n",
      "[46.  2.]\n",
      "[46.  3.]\n",
      "[46. 14.]\n",
      "[47.  0.]\n",
      "[47.  3.]\n",
      "[47.  4.]\n",
      "[47. 13.]\n",
      "[48.  0.]\n",
      "[48.  3.]\n",
      "[48.  4.]\n",
      "[48. 13.]\n",
      "[49.  0.]\n",
      "[49.  3.]\n",
      "[49.  4.]\n",
      "[49. 13.]\n"
     ]
    }
   ],
   "source": [
    "blank = pd.read_csv('./result_kor.csv', encoding='cp949')\n",
    "x_test = pd.read_csv('./test_kor.csv',encoding='cp949')\n",
    "\n",
    "# find coordinate of null \n",
    "def findCoorporate(input_data):\n",
    "    result= np.array([])\n",
    "    data = input_data.isnull()\n",
    "    for i in range(50):\n",
    "        for j in range(16):\n",
    "            if data.values[i:i+1, j:j+1] == True:\n",
    "                temp = np.array([i, j])\n",
    "                result = np.append(result, temp)\n",
    "    \n",
    "    return(result)\n",
    "\n",
    "x = findCoorporate(x_test)\n",
<<<<<<< Updated upstream
    "print(x.shape)\n",
    "x = np.reshape(x, (-1, 2))\n",
    "# print(x)\n",
=======
    "\n",
    "x = np.reshape(x, (-1, 2))\n",
    "# print(x)\n",
    "\n",
>>>>>>> Stashed changes
    "for y in x:\n",
    "    tmp = 0\n",
    "    if tmp == y[0]:\n",
    "        # 한번 더 가\n",
    "        # 갔던것들 append\n",
    "        else:\n",
    "            # 그만 가\n",
    "            # 앞에서 append한것들로 \n",
    "            # 그럼 각 좌표의 컬럼이름을 찾아서\n",
    "            # 그걸 또 append해\n",
    "            # 다하면 그거랑 case값을 비교해서 무슨 케이스인지 알아내\n",
    "            # 그리고 각 케이스에 맞게 이언이 함수를 실행해!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(x_test.values[0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-42-c287e27f9902>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-42-c287e27f9902>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    numerical_case(case, , )\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for idx, case in enumerate(Cases):\n",
    "    print(idx, case)\n",
    "    if idx == 0:\n",
    "        numerical_case(case, , )\n",
    "    elif idx >=11:\n",
    "        mix_case(case, , ,)\n",
    "    else:\n",
    "        categorical_case()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< Updated upstream
   "version": "3.5.2"
=======
   "version": "3.6.5"
>>>>>>> Stashed changes
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
