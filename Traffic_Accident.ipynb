{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리\n",
    "\n",
    "### 수치형\n",
    "사상자수, 사망자수, 중상자수, 경상자수, 부상신고자수\n",
    "\n",
    "### 범주형\n",
    "주야, 요일, 발생지시도, 발생지시군구, \n",
    "사고유형_대분류, 사고유형_중분류, 법규위반, 도로형태_대분류,\n",
    "도로형태, 당사자종별_1당_대분류, 당사자종별_2당_대분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer, OneHotEncoder, MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical = ['주야', '요일', '발생지시도', '발생지시군구', '사고유형_대분류', '사고유형_중분류', '법규위반', \n",
    "            '도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류']\n",
    "numerical = ['사상자수', '사망자수', '중상자수', '경상자수','부상신고자수']\n",
    "x_train_num = pd.read_csv('./교통사망사고정보/Kor_Train_교통사망사고정보(12.1~17.6).csv',encoding='cp949', \n",
    "                              usecols=numerical)\n",
    "\n",
    "x_train_cat = pd.read_csv('./교통사망사고정보/Kor_Train_교통사망사고정보(12.1~17.6).csv',encoding='cp949',\n",
    "                               usecols=categorical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_num = pd.read_csv('./test_kor.csv',encoding='cp949', \n",
    "                              usecols=numerical)\n",
    "\n",
    "x_test_cat = pd.read_csv('./test_kor.csv',encoding='cp949',\n",
    "                               usecols=categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>사망자수</th>\n",
       "      <th>사상자수</th>\n",
       "      <th>중상자수</th>\n",
       "      <th>경상자수</th>\n",
       "      <th>부상신고자수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25037.000000</td>\n",
       "      <td>25037.00000</td>\n",
       "      <td>25037.000000</td>\n",
       "      <td>25037.000000</td>\n",
       "      <td>25037.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.040899</td>\n",
       "      <td>1.62152</td>\n",
       "      <td>0.299996</td>\n",
       "      <td>0.250509</td>\n",
       "      <td>0.030115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.252493</td>\n",
       "      <td>2.05103</td>\n",
       "      <td>1.052157</td>\n",
       "      <td>1.145349</td>\n",
       "      <td>0.541728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               사망자수         사상자수          중상자수          경상자수        부상신고자수\n",
       "count  25037.000000  25037.00000  25037.000000  25037.000000  25037.000000\n",
       "mean       1.040899      1.62152      0.299996      0.250509      0.030115\n",
       "std        0.252493      2.05103      1.052157      1.145349      0.541728\n",
       "min        1.000000      1.00000      0.000000      0.000000      0.000000\n",
       "25%        1.000000      1.00000      0.000000      0.000000      0.000000\n",
       "50%        1.000000      1.00000      0.000000      0.000000      0.000000\n",
       "75%        1.000000      2.00000      0.000000      0.000000      0.000000\n",
       "max       10.000000    100.00000     54.000000     62.000000     67.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>주야</th>\n",
       "      <th>요일</th>\n",
       "      <th>발생지시도</th>\n",
       "      <th>발생지시군구</th>\n",
       "      <th>사고유형_대분류</th>\n",
       "      <th>사고유형_중분류</th>\n",
       "      <th>법규위반</th>\n",
       "      <th>도로형태_대분류</th>\n",
       "      <th>도로형태</th>\n",
       "      <th>당사자종별_1당_대분류</th>\n",
       "      <th>당사자종별_2당_대분류</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25037</td>\n",
       "      <td>25037</td>\n",
       "      <td>25037</td>\n",
       "      <td>25037</td>\n",
       "      <td>25037</td>\n",
       "      <td>25037</td>\n",
       "      <td>25037</td>\n",
       "      <td>25037</td>\n",
       "      <td>25037</td>\n",
       "      <td>25037</td>\n",
       "      <td>25037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>208</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>야간</td>\n",
       "      <td>금</td>\n",
       "      <td>경기</td>\n",
       "      <td>서구</td>\n",
       "      <td>차대차</td>\n",
       "      <td>기타</td>\n",
       "      <td>안전운전 의무 불이행</td>\n",
       "      <td>단일로</td>\n",
       "      <td>기타단일로</td>\n",
       "      <td>승용차</td>\n",
       "      <td>보행자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>12913</td>\n",
       "      <td>3714</td>\n",
       "      <td>4728</td>\n",
       "      <td>493</td>\n",
       "      <td>9857</td>\n",
       "      <td>5847</td>\n",
       "      <td>17741</td>\n",
       "      <td>16746</td>\n",
       "      <td>15011</td>\n",
       "      <td>12374</td>\n",
       "      <td>9784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           주야     요일  발생지시도 발생지시군구 사고유형_대분류 사고유형_중분류         법규위반 도로형태_대분류  \\\n",
       "count   25037  25037  25037  25037    25037    25037        25037    25037   \n",
       "unique      2      7     17    208        4       19           20        9   \n",
       "top        야간      금     경기     서구      차대차       기타  안전운전 의무 불이행      단일로   \n",
       "freq    12913   3714   4728    493     9857     5847        17741    16746   \n",
       "\n",
       "         도로형태 당사자종별_1당_대분류 당사자종별_2당_대분류  \n",
       "count   25037        25037        25037  \n",
       "unique     16           12           14  \n",
       "top     기타단일로          승용차          보행자  \n",
       "freq    15011        12374         9784  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>사망자수</th>\n",
       "      <th>사상자수</th>\n",
       "      <th>중상자수</th>\n",
       "      <th>경상자수</th>\n",
       "      <th>부상신고자수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.170732</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.380949</td>\n",
       "      <td>4.181942</td>\n",
       "      <td>1.715476</td>\n",
       "      <td>4.027562</td>\n",
       "      <td>1.545842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            사망자수       사상자수       중상자수       경상자수     부상신고자수\n",
       "count  41.000000  33.000000  36.000000  42.000000  48.000000\n",
       "mean    1.170732   3.636364   0.833333   1.785714   0.312500\n",
       "std     0.380949   4.181942   1.715476   4.027562   1.545842\n",
       "min     1.000000   1.000000   0.000000   0.000000   0.000000\n",
       "25%     1.000000   1.000000   0.000000   0.000000   0.000000\n",
       "50%     1.000000   2.000000   0.000000   0.000000   0.000000\n",
       "75%     1.000000   4.000000   1.000000   1.000000   0.000000\n",
       "max     2.000000  19.000000   9.000000  21.000000  10.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>주야</th>\n",
       "      <th>요일</th>\n",
       "      <th>발생지시도</th>\n",
       "      <th>발생지시군구</th>\n",
       "      <th>사고유형_대분류</th>\n",
       "      <th>사고유형_중분류</th>\n",
       "      <th>법규위반</th>\n",
       "      <th>도로형태_대분류</th>\n",
       "      <th>도로형태</th>\n",
       "      <th>당사자종별_1당_대분류</th>\n",
       "      <th>당사자종별_2당_대분류</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>주간</td>\n",
       "      <td>화</td>\n",
       "      <td>경기</td>\n",
       "      <td>평택시</td>\n",
       "      <td>차대차</td>\n",
       "      <td>추돌</td>\n",
       "      <td>안전운전 의무 불이행</td>\n",
       "      <td>단일로</td>\n",
       "      <td>기타단일로</td>\n",
       "      <td>승용차</td>\n",
       "      <td>화물차</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        주야  요일 발생지시도 발생지시군구 사고유형_대분류 사고유형_중분류         법규위반 도로형태_대분류   도로형태  \\\n",
       "count   45  45    45     40       38       35           37       37     37   \n",
       "unique   2   7    14     37        3        9            8        2      5   \n",
       "top     주간   화    경기    평택시      차대차       추돌  안전운전 의무 불이행      단일로  기타단일로   \n",
       "freq    24  12     8      3       25       11           22       24     24   \n",
       "\n",
       "       당사자종별_1당_대분류 당사자종별_2당_대분류  \n",
       "count            41           43  \n",
       "unique            8            8  \n",
       "top             승용차          화물차  \n",
       "freq             19           11  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_cat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encdoing을 나열해서 만드는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주야 ['야간' '주간']\n",
      "요일 ['금' '월' '일' '목' '수' '화' '토']\n",
      "발생지시도 ['경기' '전남' '대구' '경북' '충남' '강원' '충북' '서울' '광주' '부산' '경남' '인천' '세종' '전북'\n",
      " '대전' '울산' '제주']\n",
      "발생지시군구 ['화성시' '영암군' '곡성군' '달성군' '고흥군' '영천시' '아산시' '서천군' '평창군' '음성군' '성남시' '서산시'\n",
      " '서구' '영등포구' '용인시' '광양시' '광산구' '중구' '원주시' '고양시' '논산시' '동구' '고성군' '안산시'\n",
      " '목포시' '강서구' '시흥시' '이천시' '사상구' '광진구' '서대문구' '양평군' '남양주시' '동작구' '기장군' '예산군'\n",
      " '남구' '여수시' '제천시' '세종' '춘천시' '의성군' '충주시' '서초구' '금산군' '밀양시' '김천시' '군산시'\n",
      " '대덕구' '파주시' '진주시' '김해시' '북구' '나주시' '고창군' '합천군' '무주군' '계양구' '함양군' '안동시'\n",
      " '인제군' '사하구' '철원군' '강동구' '홍성군' '안양시' '정선군' '용산구' '구미시' '부산진구' '광명시' '송파구'\n",
      " '평택시' '남원시' '함안군' '서귀포시' '경산시' '정읍시' '청주시' '상주시' '삼척시' '강릉시' '양산시' '제주시'\n",
      " '달서구' '영덕군' '여주시' '장성군' '전주시' '청도군' '포항시' '마포구' '영광군' '영주시' '도봉구' '당진시'\n",
      " '부천시' '수성구' '봉화군' '익산시' '구로구' '유성구' '금천구' '천안시' '진도군' '가평군' '강화군' '거창군'\n",
      " '군위군' '부평구' '양주시' '사천시' '의정부시' '영동군' '광주시' '창원시(통합)' '울주군' '진천군' '김포시'\n",
      " '동래구' '강남구' '보령시' '강진군' '보성군' '화순군' '순천시' '보은군' '양양군' '군포시' '청송군' '통영시'\n",
      " '수원시' '경주시' '하남시' '완주군' '양천구' '함평군' '의령군' '공주시' '성북구' '부안군' '예천군' '안성시'\n",
      " '중랑구' '칠곡군' '영월군' '수영구' '순창군' '거제시' '성주군' '장수군' '문경시' '은평구' '포천시' '울진군'\n",
      " '무안군' '해남군' '담양군' '양구군' '연천군' '횡성군' '장흥군' '태백시' '홍천군' '하동군' '남동구' '의왕시'\n",
      " '속초시' '부여군' '성동구' '김제시' '강북구' '청양군' '신안군' '해운대구' '종로구' '동두천시' '연제구' '진안군'\n",
      " '임실군' '노원구' '증평군' '단양군' '태안군' '고령군' '동해시' '연수구' '관악구' '옥천군' '동대문구' '영양군'\n",
      " '오산시' '금정구' '구례군' '괴산군' '계룡시' '완도군' '창녕군' '화천군' '남해군' '구리시' '산청군' '옹진군'\n",
      " '과천시' '울릉군' '영도구' '청원군' '연기군']\n",
      "사고유형_대분류 ['차대차' '차대사람' '차량단독' '건널목']\n",
      "사고유형_중분류 ['측면충돌' '차도통행중' '전도전복' '정면충돌' '추돌' '횡단중' '기타' '전도' '도로이탈' '길가장자리구역통행중'\n",
      " '공작물충돌' '전복' '보도통행중' '후진중충돌' '주/정차차량 충돌' '측면직각충돌' '차단기돌파' '직전진행' '경보기무시']\n",
      "법규위반 ['중앙선 침범' '과속' '안전운전 의무 불이행' '안전거리 미확보' '기타(운전자법규위반)' '신호위반'\n",
      " '직진 및 우회전차의 통행방해' '교차로 통행방법 위반' '보행자 보호의무 위반' '부당한 회전' '차로위반(진로변경 위반)'\n",
      " '앞지르기 금지위반' '앞지르기 방법위반' '정비불량 제차의 운전금지위반' '서행 및 일시정지위반' '과로'\n",
      " '철길건널목 통과방법위반' '진로양보 의무 불이행' '보행자과실' '통행우선 순위위반']\n",
      "도로형태_대분류 ['단일로' '교차로' '기타' '주차장' '불명' '기타/불명' '고가도로위' '지하도로내' '건널목']\n",
      "도로형태 ['기타단일로' '교차로내' '교차로부근' '교량위' '고가도로위' '교차로횡단보도내' '기타' '지하차도(도로)내' '주차장'\n",
      " '터널안' '불명' '횡단보도상' '횡단보도부근' '기타/불명' '지하도로내' '건널목']\n",
      "당사자종별_1당_대분류 ['승용차' '자전거' '화물차' '승합차' '건설기계' '이륜차' '특수차' '원동기장치자전거' '사륜오토바이(ATV)' '농기계'\n",
      " '개인형이동수단(PM)' '불명']\n",
      "당사자종별_2당_대분류 ['승합차' '보행자' '없음' '화물차' '특수차' '승용차' '이륜차' '농기계' '원동기장치자전거' '자전거'\n",
      " '사륜오토바이(ATV)' '건설기계' '불명' '열차']\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.concat((x_test_cat.dropna(),x_train_cat))\n",
    "for col in all_data.select_dtypes(include=[np.object]).columns:\n",
    "    print(col, all_data[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iron/.local/lib/python3.5/site-packages/ipykernel_launcher.py:2: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  \n",
      "/home/iron/.local/lib/python3.5/site-packages/ipykernel_launcher.py:3: FutureWarning: specifying 'categories' or 'ordered' in .astype() is deprecated; pass a CategoricalDtype instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for column in all_data.select_dtypes(include=[np.object]).columns:\n",
    "    x_train_cat[column] = x_train_cat[column].astype('category', categories = all_data[column].unique())\n",
    "    x_test_cat[column] = x_test_cat[column].astype('category', categories = all_data[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cat = pd.get_dummies(data=x_train_cat)\n",
    "x_test_cat = pd.get_dummies(data=x_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 328)\n",
      "(50, 328)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_cat.shape)\n",
    "print(x_test_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Input, LSTM, concatenate, Dropout, Conv2D, MaxPool2D, Embedding, Reshape, Conv1D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 328)\n",
      "(25037, 5)\n",
      "(50, 328)\n",
      "(50, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_cat.shape)\n",
    "print(x_train_num.shape)\n",
    "print(x_test_cat.shape)\n",
    "print(x_test_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Case1 = ['사망자수','사상자수','경상자수']\n",
    "Case2 = ['사상자수', '중상자수', '부상신고자수']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1\n",
    "'사망자수','사상자수','경상자수' 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = x_train_num[['사망자수','경상자수']].values\n",
    "X = x_train_num.drop(columns=['사망자수','사상자수','경상자수'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=25037, step=1)\n",
      "RangeIndex(start=0, stop=25037, step=1)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(X.index)\n",
    "print(x_train_cat.index)\n",
    "if X.index.all() == x_train_cat.index.all():\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.reset_index(drop=True)\n",
    "# x_train_cat = x_train_cat.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, x_train_cat], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25037, 330)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x_test_num.drop(columns=['사망자수','사상자수','경상자수'])\n",
    "# X_test = X_test.reset_index(drop=True)\n",
    "# x_test_cat = x_test_cat.reset_index(drop=True)\n",
    "X_test = pd.concat([X_test, x_test_cat],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 330)\n",
      "(25037, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = Input(shape=(len(X[0]),), name='num_input')\n",
    "x = Dense(512, activation='relu')(num_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "num_output = Dense(len(Y[0]), name='num_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=num_input, outputs=num_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "callbacks = [\n",
    "    learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "                                        # approach to get optimal value by gradually decreasing learning_rate\n",
    "    EarlyStopping('val_loss', patience=10), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "                                                            # If val_loss deviates from the optimal value, \n",
    "                                                            # learning stops even if epoch remains.\n",
    "    ModelCheckpoint('model.h5', save_best_only=True)] # 모델을 학습시키면서 지금까지 등장했던 최적의 weight들을 항상 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 0.7141 - acc: 0.9326 - val_loss: 0.6196 - val_acc: 0.9557\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.6220 - acc: 0.9554 - val_loss: 0.5763 - val_acc: 0.9405\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.6033 - acc: 0.9492 - val_loss: 0.5658 - val_acc: 0.9383\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.6169 - acc: 0.9471 - val_loss: 0.5683 - val_acc: 0.9401\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.5962 - acc: 0.9480 - val_loss: 0.5575 - val_acc: 0.9391\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 0.5949 - acc: 0.9454 - val_loss: 0.5547 - val_acc: 0.9393\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.5896 - acc: 0.9474 - val_loss: 0.5464 - val_acc: 0.9269\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5968 - acc: 0.9456 - val_loss: 0.5708 - val_acc: 0.9445\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.5828 - acc: 0.9480 - val_loss: 0.5413 - val_acc: 0.9261\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.5727 - acc: 0.9423 - val_loss: 0.5486 - val_acc: 0.9431\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 0.5852 - acc: 0.9481 - val_loss: 0.5381 - val_acc: 0.9341\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.5743 - acc: 0.9457 - val_loss: 0.5336 - val_acc: 0.9383\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.5781 - acc: 0.9450 - val_loss: 0.5664 - val_acc: 0.9535\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.5615 - acc: 0.9474 - val_loss: 0.5311 - val_acc: 0.9377\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 1s 30us/step - loss: 0.5753 - acc: 0.9455 - val_loss: 0.5327 - val_acc: 0.9445\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.5764 - acc: 0.9470 - val_loss: 0.5267 - val_acc: 0.9431\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.5498 - acc: 0.9453 - val_loss: 0.5242 - val_acc: 0.9355\n",
      "Epoch 18/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.5616 - acc: 0.9457 - val_loss: 0.5185 - val_acc: 0.9399\n",
      "Epoch 19/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.5652 - acc: 0.9458 - val_loss: 0.5354 - val_acc: 0.9483\n",
      "Epoch 20/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.5533 - acc: 0.9449 - val_loss: 0.5156 - val_acc: 0.9349\n",
      "Epoch 21/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.5746 - acc: 0.9462 - val_loss: 0.5419 - val_acc: 0.9495\n",
      "Epoch 22/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.5711 - acc: 0.9452 - val_loss: 0.5431 - val_acc: 0.9515\n",
      "Epoch 23/50\n",
      "20029/20029 [==============================] - 1s 30us/step - loss: 0.5649 - acc: 0.9475 - val_loss: 0.5149 - val_acc: 0.9335\n",
      "Epoch 24/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.5450 - acc: 0.9425 - val_loss: 0.5373 - val_acc: 0.9483\n",
      "Epoch 25/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.5545 - acc: 0.9458 - val_loss: 0.5444 - val_acc: 0.9497\n",
      "Epoch 26/50\n",
      "20029/20029 [==============================] - 1s 31us/step - loss: 0.5440 - acc: 0.9454 - val_loss: 0.5757 - val_acc: 0.9531\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 27/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.5311 - acc: 0.9464 - val_loss: 0.5378 - val_acc: 0.9463\n",
      "Epoch 28/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.5265 - acc: 0.9411 - val_loss: 0.5371 - val_acc: 0.9467\n",
      "Epoch 29/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.5263 - acc: 0.9445 - val_loss: 0.5479 - val_acc: 0.9485\n",
      "Epoch 30/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.5324 - acc: 0.9447 - val_loss: 0.5470 - val_acc: 0.9479\n",
      "Epoch 31/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.5225 - acc: 0.9441 - val_loss: 0.5399 - val_acc: 0.9475\n",
      "Epoch 32/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.5303 - acc: 0.9442 - val_loss: 0.5461 - val_acc: 0.9483\n",
      "Epoch 33/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.5303 - acc: 0.9463 - val_loss: 0.5382 - val_acc: 0.9465\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[[0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], Predicted=[[1.0179033  0.69331276]\n",
      " [0.9656948  0.02339632]]\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "Y_test = model.predict(X_test[0:2])\n",
    "# Y_test = model.predict(X[0:2])\n",
    "\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (X_test[0:2],  Y_test ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2\n",
    "\n",
    "'사상자수', '중상자수', '부상신고자수' 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = x_train_num[['사상자수', '중상자수', '부상신고자수']].values\n",
    "X = x_train_num.drop(columns=['사상자수', '중상자수', '부상신고자수'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reset_index(drop=True)\n",
    "x_train_cat = x_train_cat.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, x_train_cat], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x_test_num.drop(columns=['사상자수', '중상자수', '부상신고자수'])\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "x_test_cat = x_test_cat.reset_index(drop=True)\n",
    "X_test = pd.concat([X_test, x_test_cat],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan,  1., ...,  0.,  0.,  0.],\n",
       "       [nan, nan,  1., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 2.,  9.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 330)\n",
      "(25037, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = Input(shape=(len(X[0]),), name='num_input')\n",
    "x = Dense(512, activation='relu')(num_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "num_output = Dense(len(Y[0]), name='num_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=num_input, outputs=num_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "callbacks = [\n",
    "    learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "                                        # approach to get optimal value by gradually decreasing learning_rate\n",
    "    EarlyStopping('val_loss', patience=10), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "                                                            # If val_loss deviates from the optimal value, \n",
    "                                                            # learning stops even if epoch remains.\n",
    "    ModelCheckpoint('model.h5', save_best_only=True)] # 모델을 학습시키면서 지금까지 등장했던 최적의 weight들을 항상 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 1.1353 - acc: 0.9906 - val_loss: 1.3231 - val_acc: 1.0000\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 0.9941 - acc: 1.0000 - val_loss: 1.5311 - val_acc: 1.0000\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.8412 - acc: 1.0000 - val_loss: 1.2721 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.7906 - acc: 1.0000 - val_loss: 1.5489 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 0.8055 - acc: 1.0000 - val_loss: 1.2552 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 0.7961 - acc: 1.0000 - val_loss: 1.2185 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 0.8144 - acc: 1.0000 - val_loss: 1.1873 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.7486 - acc: 1.0000 - val_loss: 1.1899 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.9346 - acc: 1.0000 - val_loss: 1.2694 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 30us/step - loss: 0.7749 - acc: 1.0000 - val_loss: 1.2809 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.7199 - acc: 1.0000 - val_loss: 1.1927 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.7174 - acc: 1.0000 - val_loss: 1.1891 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 0.6935 - acc: 1.0000 - val_loss: 1.2772 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.7498 - acc: 1.0000 - val_loss: 1.2446 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.7628 - acc: 1.0000 - val_loss: 1.2326 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 0.7686 - acc: 1.0000 - val_loss: 1.2112 - val_acc: 1.0000\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 0.7215 - acc: 1.0000 - val_loss: 1.2249 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[[1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [2. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], Predicted=[[0.8869258  0.06663677 0.02041714]\n",
      " [5.7255545  1.9354925  0.23735398]]\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "Y_test = model.predict(X_test[2:4])\n",
    "# Y_test = model.predict(X[0:2])\n",
    "\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (X_test[2:4],  Y_test ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3\n",
    "'사상자수', '중상자수', '경상자수' 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = x_train_num[['사상자수', '중상자수', '경상자수']].values\n",
    "X = x_train_num.drop(columns=['사상자수', '중상자수', '경상자수'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, x_train_cat], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x_test_num.drop(columns=['사상자수', '중상자수', '경상자수'])\n",
    "X_test = pd.concat([X_test, x_test_cat],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 330)\n",
      "(25037, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = Input(shape=(len(X[0]),), name='num_input')\n",
    "x = Dense(512, activation='relu')(num_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "num_output = Dense(len(Y[0]), name='num_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=num_input, outputs=num_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "callbacks = [\n",
    "    learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "                                        # approach to get optimal value by gradually decreasing learning_rate\n",
    "    EarlyStopping('val_loss', patience=10), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "                                                            # If val_loss deviates from the optimal value, \n",
    "                                                            # learning stops even if epoch remains.\n",
    "    ModelCheckpoint('model.h5', save_best_only=True)] # 모델을 학습시키면서 지금까지 등장했던 최적의 weight들을 항상 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 1s 36us/step - loss: 2.1094 - acc: 0.9922 - val_loss: 2.1658 - val_acc: 1.0000\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 1.8946 - acc: 1.0000 - val_loss: 1.8385 - val_acc: 1.0000\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 1.8123 - acc: 1.0000 - val_loss: 1.8323 - val_acc: 1.0000\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 1.7215 - acc: 1.0000 - val_loss: 1.7207 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 1.6523 - acc: 1.0000 - val_loss: 1.7731 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 1.6442 - acc: 1.0000 - val_loss: 1.5930 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 30us/step - loss: 1.5781 - acc: 1.0000 - val_loss: 1.6481 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 1.5597 - acc: 1.0000 - val_loss: 1.6134 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 1.5446 - acc: 1.0000 - val_loss: 1.8727 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 1.4882 - acc: 1.0000 - val_loss: 1.8196 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 1.5271 - acc: 1.0000 - val_loss: 1.9800 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 1.4652 - acc: 1.0000 - val_loss: 1.7815 - val_acc: 1.0000\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 27us/step - loss: 1.4798 - acc: 1.0000 - val_loss: 1.6434 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 29us/step - loss: 1.4136 - acc: 1.0000 - val_loss: 1.7441 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 1s 28us/step - loss: 1.4295 - acc: 1.0000 - val_loss: 1.6968 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 1s 30us/step - loss: 1.4473 - acc: 1.0000 - val_loss: 2.0517 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[[1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [2. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], Predicted=[[1.4452763  0.34059936 0.24327429]\n",
      " [1.9304359  0.5187419  0.45005864]\n",
      " [3.2472782  1.0748171  1.0712734 ]]\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "Y_test = model.predict(X_test[4:7])\n",
    "\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (X_test[4:7],  Y_test ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 4\n",
    "'사망자수', '사상자수', '중상자수' 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = x_train_num[['사망자수', '중상자수']].values\n",
    "X = x_train_num.drop(columns=['사망자수', '사상자수', '중상자수'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, x_train_cat], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x_test_num.drop(columns=['사망자수', '사상자수', '중상자수'])\n",
    "X_test = pd.concat([X_test, x_test_cat],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 330)\n",
      "(25037, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = Input(shape=(len(X[0]),), name='num_input')\n",
    "x = Dense(512, activation='relu')(num_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "num_output = Dense(len(Y[0]), name='num_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=num_input, outputs=num_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "callbacks = [\n",
    "    learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "                                        # approach to get optimal value by gradually decreasing learning_rate\n",
    "    EarlyStopping('val_loss', patience=10), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "                                                            # If val_loss deviates from the optimal value, \n",
    "                                                            # learning stops even if epoch remains.\n",
    "    ModelCheckpoint('model.h5', save_best_only=True)] # 모델을 학습시키면서 지금까지 등장했던 최적의 weight들을 항상 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 1s 52us/step - loss: 0.5541 - acc: 0.9251 - val_loss: 0.5070 - val_acc: 0.9303\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.4962 - acc: 0.9276 - val_loss: 0.4655 - val_acc: 0.9139\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 35us/step - loss: 0.4760 - acc: 0.9297 - val_loss: 0.4747 - val_acc: 0.9119\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 35us/step - loss: 0.4676 - acc: 0.9303 - val_loss: 0.4840 - val_acc: 0.9333\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 35us/step - loss: 0.4243 - acc: 0.9336 - val_loss: 0.6673 - val_acc: 0.9247\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 35us/step - loss: 0.4054 - acc: 0.9410 - val_loss: 0.6006 - val_acc: 0.9058\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.3551 - acc: 0.9414 - val_loss: 0.6155 - val_acc: 0.9263\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.3325 - acc: 0.9459 - val_loss: 0.5355 - val_acc: 0.9341\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 36us/step - loss: 0.3098 - acc: 0.9461 - val_loss: 0.4897 - val_acc: 0.9271\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 35us/step - loss: 0.2716 - acc: 0.9474 - val_loss: 0.5197 - val_acc: 0.9197\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 36us/step - loss: 0.3032 - acc: 0.9491 - val_loss: 0.5370 - val_acc: 0.9353\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 35us/step - loss: 0.2921 - acc: 0.9508 - val_loss: 0.5167 - val_acc: 0.9215\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[[ 5.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [21.  4.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.]], Predicted=[[1.0862623  0.48115999]\n",
      " [1.2250136  5.3040648 ]\n",
      " [1.0168526  0.04771724]]\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "Y_test = model.predict(X_test[7:10])\n",
    "\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (X_test[7:10],  Y_test ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 5\n",
    "'사고유형_대분류', '사고유형_중분류', '법규위반'예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 290)\n",
      "(25037, 43)\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 1s 50us/step - loss: 0.1419 - acc: 0.9480 - val_loss: 0.0803 - val_acc: 0.9672\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.0866 - acc: 0.9647 - val_loss: 0.0775 - val_acc: 0.9684\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 36us/step - loss: 0.0820 - acc: 0.9664 - val_loss: 0.0769 - val_acc: 0.9682\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 36us/step - loss: 0.0800 - acc: 0.9672 - val_loss: 0.0772 - val_acc: 0.9681\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.0781 - acc: 0.9681 - val_loss: 0.0766 - val_acc: 0.9684\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 36us/step - loss: 0.0766 - acc: 0.9687 - val_loss: 0.0773 - val_acc: 0.9678\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.0756 - acc: 0.9693 - val_loss: 0.0765 - val_acc: 0.9684\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.0743 - acc: 0.9697 - val_loss: 0.0768 - val_acc: 0.9683\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.0729 - acc: 0.9704 - val_loss: 0.0778 - val_acc: 0.9681\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.0723 - acc: 0.9707 - val_loss: 0.0777 - val_acc: 0.9680\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0708 - acc: 0.9713 - val_loss: 0.0783 - val_acc: 0.9678\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.0694 - acc: 0.9719 - val_loss: 0.0791 - val_acc: 0.9673\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.0680 - acc: 0.9724 - val_loss: 0.0813 - val_acc: 0.9665\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.0667 - acc: 0.9731 - val_loss: 0.0811 - val_acc: 0.9669\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.0660 - acc: 0.9733 - val_loss: 0.0814 - val_acc: 0.9666\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.0646 - acc: 0.9740 - val_loss: 0.0817 - val_acc: 0.9668\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.0636 - acc: 0.9744 - val_loss: 0.0841 - val_acc: 0.9665\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "col_name = []\n",
    "for col in ['사고유형_대분류', '사고유형_중분류', '법규위반']:\n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)\n",
    "\n",
    "Y = x_train_cat[col_name].values\n",
    "X = x_train_cat.drop(columns=col_name)\n",
    "X = pd.concat([X, x_train_num], axis=1).values\n",
    "\n",
    "X_test = x_test_cat.drop(columns=col_name)\n",
    "X_test = pd.concat([X_test, x_test_num],axis=1).values\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "x = Dense(512, activation='relu')(cat_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "cat_output = Dense(len(Y[0]), activation='sigmoid', name='cat_output')(x)\n",
    "\n",
    "model = Model(inputs=cat_input, outputs=cat_output)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "callbacks = [\n",
    "    learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "                                        # approach to get optimal value by gradually decreasing learning_rate\n",
    "    EarlyStopping('val_loss', patience=10), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "                                                            # If val_loss deviates from the optimal value, \n",
    "                                                            # learning stops even if epoch remains.\n",
    "    ModelCheckpoint('model.h5', save_best_only=True)] # 모델을 학습시키면서 지금까지 등장했던 최적의 weight들을 항상 저장한다.\n",
    "\n",
    "history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[[0. 1. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 2. 8. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]], Predicted=[[9.99998689e-01 5.27063605e-07 1.27890542e-06 2.05984065e-07\n",
      "  7.72733912e-02 1.24240813e-07 9.13340955e-07 5.52775860e-02\n",
      "  7.55810272e-03 8.59435261e-07 5.52138351e-02 9.12658379e-07\n",
      "  3.09710060e-07 8.31335978e-09 2.91493109e-07 3.20063371e-08\n",
      "  2.86850764e-07 5.35616673e-05 1.04063770e-06 8.27486277e-01\n",
      "  1.48210475e-07 6.02065526e-08 4.04412823e-08 1.64565234e-03\n",
      "  7.23002525e-03 4.35372069e-02 1.69696112e-03 9.40096215e-05\n",
      "  4.95410055e-01 2.73947030e-01 2.26652935e-01 1.47036844e-04\n",
      "  9.42418724e-03 1.09505560e-03 4.42899857e-03 1.93573142e-05\n",
      "  1.57734632e-07 3.60701699e-03 1.43428508e-06 3.65411694e-07\n",
      "  2.21719674e-05 3.58132120e-08 1.11197318e-08]\n",
      " [1.71359136e-06 1.30408478e-06 9.99997854e-01 9.62149534e-06\n",
      "  1.31907318e-05 1.90251631e-05 3.36594820e-01 3.53773953e-06\n",
      "  5.50982850e-06 3.14114986e-05 1.54825658e-01 2.83651482e-02\n",
      "  1.14318624e-01 1.90645205e-05 4.54115361e-01 1.47648284e-03\n",
      "  9.19629383e-06 5.56776115e-07 1.81742726e-04 7.66950598e-06\n",
      "  1.40367331e-06 2.50639459e-06 1.76277766e-07 1.99764222e-03\n",
      "  4.86519840e-03 9.80521917e-01 1.85771240e-03 7.64633017e-03\n",
      "  4.53880231e-04 1.58781916e-06 2.30622347e-04 6.98102531e-06\n",
      "  2.99397834e-06 1.15335376e-06 3.44053580e-04 2.25069714e-04\n",
      "  1.14173657e-04 1.02834917e-06 3.57796608e-07 3.82196868e-06\n",
      "  1.28566015e-07 5.68841415e-07 3.82914550e-07]\n",
      " [9.99988675e-01 2.12824398e-06 6.74553621e-06 1.57881658e-07\n",
      "  3.05675436e-03 1.34047548e-06 4.10550825e-07 1.70298424e-02\n",
      "  8.93625557e-01 4.91627475e-07 8.49140808e-02 1.93427567e-07\n",
      "  1.72955470e-06 5.58051966e-07 5.56619671e-06 6.50545005e-08\n",
      "  4.80063022e-07 1.21034493e-04 6.67899876e-05 1.67154372e-02\n",
      "  3.06219157e-08 1.76155098e-07 1.82453963e-08 8.92794039e-03\n",
      "  9.38789360e-03 9.43765759e-01 5.03813215e-02 2.01013358e-03\n",
      "  6.90618181e-05 4.10192979e-06 2.58819655e-05 1.57051636e-05\n",
      "  1.18346934e-05 5.25761978e-04 1.98635753e-05 2.65180679e-05\n",
      "  4.45489468e-06 2.89520176e-06 2.13266094e-06 1.77293217e-07\n",
      "  2.83220260e-07 3.41900872e-08 1.44319188e-08]\n",
      " [8.64879723e-09 9.99999881e-01 8.15483020e-07 7.46417115e-08\n",
      "  2.11951303e-07 1.79836974e-01 6.33948503e-07 1.24539881e-07\n",
      "  2.10294488e-07 5.24951518e-01 2.53068805e-01 7.77026301e-08\n",
      "  3.40579106e-07 2.91858111e-02 4.78858681e-07 3.03455039e-08\n",
      "  4.41157911e-03 3.62506434e-08 2.38340533e-07 8.60569003e-08\n",
      "  5.32583222e-08 4.79258375e-08 4.64512029e-09 1.28019543e-03\n",
      "  1.51913185e-02 9.58707690e-01 1.21001969e-04 1.32012239e-03\n",
      "  5.92916319e-03 2.41475482e-06 7.20359094e-05 5.94272790e-03\n",
      "  1.24442930e-04 5.98675513e-07 9.24790768e-08 5.54504958e-08\n",
      "  9.91401407e-07 1.41547048e-06 2.47657184e-08 3.55160168e-08\n",
      "  3.93081256e-09 7.84710608e-07 1.92392466e-08]\n",
      " [9.97750700e-01 1.75629987e-03 1.06960675e-03 7.09476008e-04\n",
      "  6.11166693e-02 5.10898884e-04 2.79891101e-04 1.43044963e-01\n",
      "  2.51872748e-01 4.96031716e-04 4.19500113e-01 3.91455105e-04\n",
      "  4.11612593e-04 9.59466735e-04 3.74311610e-04 1.02929036e-04\n",
      "  1.66066957e-03 3.93722113e-03 2.31501507e-03 1.62165806e-01\n",
      "  2.28898731e-04 2.30081831e-04 6.37307967e-05 2.34589338e-01\n",
      "  5.06163761e-02 4.55003381e-01 1.91568121e-01 5.86430207e-02\n",
      "  1.26532260e-02 3.25433142e-03 6.58568693e-03 7.12652504e-03\n",
      "  1.66230295e-02 6.16734102e-02 5.61713241e-03 5.40772825e-03\n",
      "  1.23027561e-03 1.37355516e-03 8.16831132e-04 4.45397542e-04\n",
      "  5.24911506e-04 1.39254334e-04 6.06564936e-05]\n",
      " [2.11283716e-11 1.00000000e+00 1.38326794e-09 1.44232795e-08\n",
      "  4.59995197e-09 4.45801951e-03 1.91171807e-08 1.19539822e-09\n",
      "  2.07012474e-09 9.15427506e-01 3.88369597e-02 9.39391320e-09\n",
      "  6.52734755e-09 1.84479868e-03 1.10470948e-08 3.01634295e-09\n",
      "  1.88244916e-02 1.92695637e-10 3.31162275e-09 1.96654137e-09\n",
      "  8.77039774e-09 1.13140253e-09 1.50334845e-09 1.01203192e-03\n",
      "  1.86276380e-02 5.16168237e-01 1.49606358e-05 1.22550852e-03\n",
      "  4.08393443e-02 1.14796467e-06 1.20716431e-05 3.62024605e-01\n",
      "  6.22302250e-05 4.95357106e-08 3.68193853e-09 1.22920862e-09\n",
      "  5.70420127e-07 3.50912643e-07 1.12491705e-09 1.29085169e-08\n",
      "  4.58095062e-10 4.85983662e-07 1.42529510e-09]\n",
      " [9.99998808e-01 4.26089827e-07 1.21422920e-06 1.56750460e-07\n",
      "  7.30826631e-02 9.81244028e-08 7.69722362e-07 5.47647923e-02\n",
      "  7.83519261e-03 6.46589513e-07 4.50373888e-02 6.95894471e-07\n",
      "  2.38763477e-07 6.41842046e-09 2.90414818e-07 2.90226225e-08\n",
      "  1.78914974e-07 7.21733595e-05 7.88216255e-07 8.30407917e-01\n",
      "  1.32030223e-07 4.64015493e-08 2.83815282e-08 1.16311270e-03\n",
      "  1.38902254e-02 5.48921265e-02 1.01870578e-03 7.24728889e-05\n",
      "  3.53625894e-01 3.84451956e-01 2.77787089e-01 9.42537808e-05\n",
      "  3.95730557e-03 8.84777401e-04 6.50354242e-03 1.80456591e-05\n",
      "  1.14154481e-07 5.13558742e-03 9.76736942e-07 2.81935598e-07\n",
      "  2.23162824e-05 3.25595728e-08 9.56276125e-09]\n",
      " [2.64754956e-08 9.99999881e-01 1.10590793e-06 1.68200444e-07\n",
      "  4.76241325e-07 1.19875990e-01 1.07966650e-06 1.93927733e-07\n",
      "  5.12577060e-07 5.27434826e-01 3.08624774e-01 1.98808323e-07\n",
      "  5.87225372e-07 2.58569792e-02 8.21469769e-07 8.14386567e-08\n",
      "  7.11064041e-03 6.99589506e-08 4.46636648e-07 1.88748885e-07\n",
      "  1.24538346e-07 1.23042000e-07 1.32676936e-08 1.66273885e-03\n",
      "  1.32494597e-02 9.49128687e-01 2.87327624e-04 2.78414297e-03\n",
      "  7.72020314e-03 3.76467892e-06 1.03523373e-04 1.29443277e-02\n",
      "  2.39985980e-04 1.63089067e-06 2.00157331e-07 1.00682882e-07\n",
      "  2.09706172e-06 2.48867855e-06 5.63845575e-08 1.24007869e-07\n",
      "  1.03583657e-08 1.69126611e-06 5.03557338e-08]\n",
      " [9.94191349e-01 2.50075897e-03 2.99977022e-03 9.42512706e-04\n",
      "  4.52705435e-02 1.06958172e-03 6.37469697e-04 2.19051391e-01\n",
      "  3.57780159e-01 8.31893936e-04 3.88156623e-01 6.12691860e-04\n",
      "  8.50535696e-04 1.56419899e-03 1.20789022e-03 1.55470669e-04\n",
      "  1.76768855e-03 4.59550135e-03 3.81077058e-03 8.72357115e-02\n",
      "  3.18330480e-04 4.13278671e-04 9.33035408e-05 2.31441513e-01\n",
      "  9.96428430e-02 5.03153265e-01 1.26976028e-01 5.13007343e-02\n",
      "  8.33728816e-03 1.92744820e-03 3.56469164e-03 4.24995366e-03\n",
      "  4.82017640e-03 2.49473676e-02 3.92944179e-03 6.10887213e-03\n",
      "  1.94127613e-03 9.23030719e-04 1.02737569e-03 6.08891016e-04\n",
      "  4.96715656e-04 2.22451767e-04 1.03029684e-04]\n",
      " [4.65164067e-15 1.00000000e+00 2.62900725e-11 6.04647972e-12\n",
      "  9.72620508e-12 2.50134747e-02 5.87366822e-11 1.47360271e-12\n",
      "  4.30805738e-12 9.04855907e-01 4.55124974e-02 5.18224613e-12\n",
      "  2.08406400e-11 2.19748728e-03 4.93829075e-11 2.78013268e-12\n",
      "  6.50972826e-04 3.48586909e-13 8.35220695e-12 2.22034457e-12\n",
      "  3.98673412e-12 9.86415160e-13 2.12179653e-13 3.11877520e-05\n",
      "  3.95105872e-03 9.76584256e-01 3.38837395e-07 4.67037389e-05\n",
      "  2.88269646e-03 4.33883063e-09 4.11327562e-07 1.01249432e-02\n",
      "  1.35903713e-06 7.29550934e-11 3.32613364e-12 2.46036611e-12\n",
      "  1.17324794e-09 1.40085810e-09 9.25381408e-13 3.43152611e-12\n",
      "  9.90256393e-14 5.98646965e-10 7.90227855e-13]]\n",
      "X=[1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0], Predicted=[[4.7126747e-07 9.9999726e-01 1.3003359e-05 3.7977056e-06 5.8551368e-06\n",
      "  1.5081507e-01 1.3398555e-05 5.2582732e-06 6.8906597e-06 5.5205101e-01\n",
      "  2.6095897e-01 3.5961755e-06 6.8235850e-06 3.8365409e-02 1.6180622e-05\n",
      "  1.3885999e-06 1.6887017e-02 1.4866732e-06 6.3596226e-06 2.9662062e-06\n",
      "  2.6623468e-06 1.7432958e-06 5.1194684e-07 7.0977621e-03 7.8323588e-02\n",
      "  8.4010845e-01 8.2050107e-04 7.4687130e-03 2.2711707e-02 5.3541800e-05\n",
      "  4.3249124e-04 2.5718870e-02 7.3395955e-04 1.2273417e-05 2.8198183e-06\n",
      "  2.6529740e-06 3.2670880e-05 3.1242496e-05 1.2269404e-06 2.3277348e-06\n",
      "  3.1627971e-07 2.1631882e-05 1.0898428e-06]]\n",
      "['차대차' '차대사람' '차량단독' '건널목']\n",
      "4\n",
      "['측면충돌' '차도통행중' '전도전복' '정면충돌' '추돌' '횡단중' '기타' '전도' '도로이탈' '길가장자리구역통행중'\n",
      " '공작물충돌' '전복' '보도통행중' '후진중충돌' '주/정차차량 충돌' '측면직각충돌' '차단기돌파' '직전진행' '경보기무시']\n",
      "19\n",
      "['중앙선 침범' '과속' '안전운전 의무 불이행' '안전거리 미확보' '기타(운전자법규위반)' '신호위반'\n",
      " '직진 및 우회전차의 통행방해' '교차로 통행방법 위반' '보행자 보호의무 위반' '부당한 회전' '차로위반(진로변경 위반)'\n",
      " '앞지르기 금지위반' '앞지르기 방법위반' '정비불량 제차의 운전금지위반' '서행 및 일시정지위반' '과로'\n",
      " '철길건널목 통과방법위반' '진로양보 의무 불이행' '보행자과실' '통행우선 순위위반']\n",
      "차량단독 0.999998\n",
      "전도전복 0.336595\n",
      "공작물충돌 0.454115\n",
      "안전운전 의무 불이행 0.980522\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "Y_test = model.predict(X_test[10:20])\n",
    "Y_test1 = model.predict(X[0:1])\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (X_test[10:20],  Y_test ))\n",
    "print(\"X=%s, Predicted=%s\" % (X[0],  Y_test1))\n",
    "\n",
    "print(all_data['사고유형_대분류'].unique())\n",
    "print(len(all_data['사고유형_대분류'].unique()))\n",
    "print(all_data['사고유형_중분류'].unique())\n",
    "print(len(all_data['사고유형_중분류'].unique()))\n",
    "print(all_data['법규위반'].unique())\n",
    "\n",
    "label_name = []\n",
    "label_name.extend(all_data['사고유형_대분류'].unique()) \n",
    "label_name.extend(all_data['사고유형_중분류'].unique())\n",
    "label_name.extend(all_data['법규위반'].unique())\n",
    "\n",
    "for i, x in zip(label_name, Y_test[1]):\n",
    "    if x>0.3:\n",
    "        print(i,'%f'%(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 6\n",
    "'도로형태_대분류', '도로형태', '당사자종별_1당_대분류'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = []\n",
    "for col in ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류']:\n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = x_train_cat[col_name].values\n",
    "X = x_train_cat.drop(columns=col_name)\n",
    "X = pd.concat([X, x_train_num], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x_test_cat.drop(columns=col_name)\n",
    "X_test = pd.concat([X_test, x_test_num],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 296)\n",
      "(25037, 37)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "x = Dense(512, activation='relu')(cat_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "cat_output = Dense(len(Y[0]), activation='sigmoid', name='cat_output')(x)\n",
    "\n",
    "model = Model(inputs=cat_input, outputs=cat_output)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 1s 52us/step - loss: 0.1788 - acc: 0.9313 - val_loss: 0.1384 - val_acc: 0.9463\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 36us/step - loss: 0.1410 - acc: 0.9448 - val_loss: 0.1346 - val_acc: 0.9472\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 35us/step - loss: 0.1364 - acc: 0.9461 - val_loss: 0.1337 - val_acc: 0.9476\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.1340 - acc: 0.9470 - val_loss: 0.1344 - val_acc: 0.9471\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.1314 - acc: 0.9478 - val_loss: 0.1337 - val_acc: 0.9475\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 36us/step - loss: 0.1295 - acc: 0.9486 - val_loss: 0.1360 - val_acc: 0.9464\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.1268 - acc: 0.9495 - val_loss: 0.1367 - val_acc: 0.9460\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 36us/step - loss: 0.1247 - acc: 0.9504 - val_loss: 0.1371 - val_acc: 0.9467\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.1223 - acc: 0.9511 - val_loss: 0.1370 - val_acc: 0.9466\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.1198 - acc: 0.9519 - val_loss: 0.1408 - val_acc: 0.9461\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 36us/step - loss: 0.1177 - acc: 0.9529 - val_loss: 0.1424 - val_acc: 0.9464\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.1153 - acc: 0.9536 - val_loss: 0.1435 - val_acc: 0.9453\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.1132 - acc: 0.9544 - val_loss: 0.1469 - val_acc: 0.9440\n"
     ]
    }
   ],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "callbacks = [\n",
    "    learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "                                        # approach to get optimal value by gradually decreasing learning_rate\n",
    "    EarlyStopping('val_loss', patience=10), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "                                                            # If val_loss deviates from the optimal value, \n",
    "                                                            # learning stops even if epoch remains.\n",
    "    ModelCheckpoint('model.h5', save_best_only=True)] # 모델을 학습시키면서 지금까지 등장했던 최적의 weight들을 항상 저장한다.\n",
    "\n",
    "history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[[ 1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  1. 11.  0.  0. 10.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  1. 13.  3.  9.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  1.  1.  0.  0.  0.]], Predicted=[[9.99958992e-01 2.85386159e-05 3.05838854e-10 1.54790087e-14\n",
      "  6.73868106e-14 1.16432297e-07 1.49942618e-08 5.92572311e-11\n",
      "  3.25603753e-16 9.99778688e-01 5.26048007e-06 2.92414916e-06\n",
      "  2.47818953e-05 1.58293947e-08 1.77280269e-14 5.15073650e-10\n",
      "  3.83008868e-11 3.59730785e-15 2.97194674e-07 7.96670293e-13\n",
      "  1.32532452e-09 3.42934783e-08 1.80482004e-07 6.15524645e-11\n",
      "  1.07716153e-15 8.85419309e-01 2.42270010e-10 8.87710080e-02\n",
      "  1.94413029e-02 1.43830539e-06 1.38328886e-07 4.47050570e-06\n",
      "  4.05751805e-08 1.39608399e-12 1.40624701e-09 4.80981984e-15\n",
      "  6.50187744e-08]\n",
      " [5.64910829e-01 3.15669477e-01 6.57803193e-03 7.18460593e-04\n",
      "  9.39293473e-04 9.62761343e-02 5.28292451e-03 8.06615595e-03\n",
      "  1.34601491e-03 4.87807900e-01 1.47361800e-01 2.02345237e-01\n",
      "  4.10152599e-02 6.04412938e-03 2.76122685e-03 7.56210694e-03\n",
      "  2.03090976e-03 3.49168520e-04 7.09841251e-02 1.04413927e-03\n",
      "  1.99140701e-02 9.34555382e-03 9.59627703e-02 9.66886897e-03\n",
      "  7.15895265e-04 3.17126721e-01 2.99379067e-03 3.70554656e-01\n",
      "  3.26518059e-01 4.97078039e-02 4.40309895e-03 3.37755382e-02\n",
      "  4.75209998e-03 9.69651737e-04 2.52987887e-03 4.18943993e-04\n",
      "  5.63869113e-03]\n",
      " [7.03257263e-01 2.75764465e-01 9.48378234e-04 4.02559490e-05\n",
      "  5.12964252e-05 1.46707315e-02 5.92851487e-04 7.00711447e-04\n",
      "  2.83456848e-05 6.61784053e-01 1.19458184e-01 1.52981594e-01\n",
      "  4.31900239e-03 4.79556795e-04 1.76724698e-03 7.91292929e-04\n",
      "  1.02035257e-04 4.49176223e-05 2.39829905e-03 4.30535692e-05\n",
      "  2.31163669e-02 9.56513453e-03 1.38625978e-02 6.90256536e-04\n",
      "  2.45834399e-05 3.12143952e-01 5.03018452e-03 4.62942511e-01\n",
      "  1.08249448e-01 7.89472237e-02 6.51528221e-03 1.69986431e-02\n",
      "  6.35237340e-03 1.29823558e-04 1.71177485e-03 2.23043462e-05\n",
      "  1.46877079e-03]]\n",
      "X=[1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0], Predicted=[[8.0598807e-01 1.9966237e-01 2.9454011e-04 3.6690242e-06 5.0417943e-06\n",
      "  3.3862507e-03 4.0152817e-04 1.7074119e-04 3.3716135e-06 7.1193999e-01\n",
      "  8.0134936e-02 7.9952754e-02 1.8755373e-03 3.3644773e-04 1.5286600e-03\n",
      "  3.3873858e-04 1.8436684e-05 2.5683705e-06 3.3980497e-04 4.9354121e-06\n",
      "  4.9032532e-02 2.7287733e-02 3.4641561e-03 1.4393861e-04 2.8516347e-06\n",
      "  6.8982154e-01 8.0193457e-04 1.2848991e-01 1.5629774e-01 6.7070900e-03\n",
      "  2.5894404e-03 3.6911233e-03 1.3905717e-03 5.2386977e-06 2.6882482e-05\n",
      "  9.6467852e-07 5.3908949e-04]]\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "Y_test = model.predict(X_test[20:23])\n",
    "Y_test1 = model.predict(X[0:1])\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (X_test[20:23],  Y_test ))\n",
    "print(\"X=%s, Predicted=%s\" % (X[0],  Y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['단일로' '교차로' '기타' '주차장' '불명' '기타/불명' '고가도로위' '지하도로내' '건널목']\n",
      "9\n",
      "['기타단일로' '교차로내' '교차로부근' '교량위' '고가도로위' '교차로횡단보도내' '기타' '지하차도(도로)내' '주차장'\n",
      " '터널안' '불명' '횡단보도상' '횡단보도부근' '기타/불명' '지하도로내' '건널목']\n",
      "16\n",
      "['승용차' '자전거' '화물차' '승합차' '건설기계' '이륜차' '특수차' '원동기장치자전거' '사륜오토바이(ATV)' '농기계'\n",
      " '개인형이동수단(PM)' '불명']\n"
     ]
    }
   ],
   "source": [
    "print(all_data['도로형태_대분류'].unique())\n",
    "print(len(all_data['도로형태_대분류'].unique()))\n",
    "print(all_data['도로형태'].unique())\n",
    "print(len(all_data['도로형태'].unique()))\n",
    "print(all_data['당사자종별_1당_대분류'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = []\n",
    "label_name.extend(all_data['도로형태_대분류'].unique()) \n",
    "label_name.extend(all_data['도로형태'].unique())\n",
    "label_name.extend(all_data['당사자종별_1당_대분류'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단일로 0.564911\n",
      "교차로 0.315669\n",
      "기타단일로 0.487808\n",
      "승용차 0.317127\n",
      "화물차 0.370555\n",
      "승합차 0.326518\n"
     ]
    }
   ],
   "source": [
    "for i, x in zip(label_name, Y_test[1]):\n",
    "    if x>0.3:\n",
    "        print(i,'%f'%(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단일로 0.805988\n",
      "기타단일로 0.711940\n",
      "승용차 0.689822\n"
     ]
    }
   ],
   "source": [
    "for i, x in zip(label_name, Y_test1[0]):\n",
    "    if x>0.3:\n",
    "        print(i,'%f'%(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 7\n",
    "'도로형태_대분류', '도로형태', '당사자종별_2당_대분류'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = []\n",
    "for col in ['도로형태_대분류', '도로형태', '당사자종별_2당_대분류']:\n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = x_train_cat[col_name].values\n",
    "X = x_train_cat.drop(columns=col_name)\n",
    "X = pd.concat([X, x_train_num], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x_test_cat.drop(columns=col_name)\n",
    "X_test = pd.concat([X_test, x_test_num],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 294)\n",
      "(25037, 39)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "x = Dense(512, activation='relu')(cat_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "cat_output = Dense(len(Y[0]), activation='sigmoid', name='cat_output')(x)\n",
    "\n",
    "model = Model(inputs=cat_input, outputs=cat_output)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 1s 58us/step - loss: 0.1537 - acc: 0.9424 - val_loss: 0.1021 - val_acc: 0.9618\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.1061 - acc: 0.9602 - val_loss: 0.0999 - val_acc: 0.9616\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.1017 - acc: 0.9611 - val_loss: 0.0991 - val_acc: 0.9617\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.0991 - acc: 0.9618 - val_loss: 0.0982 - val_acc: 0.9621\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 36us/step - loss: 0.0969 - acc: 0.9625 - val_loss: 0.0985 - val_acc: 0.9620\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.0951 - acc: 0.9630 - val_loss: 0.0991 - val_acc: 0.9619\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.0928 - acc: 0.9638 - val_loss: 0.1005 - val_acc: 0.9615\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.0909 - acc: 0.9643 - val_loss: 0.1013 - val_acc: 0.9610\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.0890 - acc: 0.9650 - val_loss: 0.1024 - val_acc: 0.9614\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.0867 - acc: 0.9657 - val_loss: 0.1029 - val_acc: 0.9613\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.0844 - acc: 0.9665 - val_loss: 0.1070 - val_acc: 0.9603\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0827 - acc: 0.9673 - val_loss: 0.1059 - val_acc: 0.9604\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.0805 - acc: 0.9681 - val_loss: 0.1094 - val_acc: 0.9588\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0782 - acc: 0.9689 - val_loss: 0.1096 - val_acc: 0.9604\n"
     ]
    }
   ],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "callbacks = [\n",
    "    learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "                                        # approach to get optimal value by gradually decreasing learning_rate\n",
    "    EarlyStopping('val_loss', patience=10), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "                                                            # If val_loss deviates from the optimal value, \n",
    "                                                            # learning stops even if epoch remains.\n",
    "    ModelCheckpoint('model.h5', save_best_only=True)] # 모델을 학습시키면서 지금까지 등장했던 최적의 weight들을 항상 저장한다.\n",
    "\n",
    "history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[[1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 2. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 1. 2. 0. 1. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 1. 0. 0. 0.]], Predicted=[[2.28998228e-03 9.96263444e-01 8.88786453e-05 4.87393254e-06\n",
      "  1.05873653e-04 1.87629438e-03 1.85778830e-04 1.76282963e-04\n",
      "  4.00033714e-05 1.38352648e-03 9.52197671e-01 6.15712926e-02\n",
      "  3.60194099e-04 3.62070889e-04 2.46073888e-03 6.82467944e-05\n",
      "  1.11797981e-05 4.78538186e-06 4.48083556e-05 9.69901885e-05\n",
      "  1.42247486e-03 2.63426395e-04 1.35024800e-03 1.40125179e-04\n",
      "  7.34998175e-05 2.24561170e-01 1.63026998e-04 2.56943476e-05\n",
      "  2.24662483e-01 1.60580538e-02 5.36674082e-01 8.62088427e-02\n",
      "  4.13373252e-03 4.51090671e-02 6.13090815e-03 2.86740367e-04\n",
      "  4.65546586e-02 7.68656610e-05 4.94569213e-05]\n",
      " [8.21198463e-01 9.27812457e-02 9.68189538e-03 7.79437774e-04\n",
      "  3.35784425e-04 8.51020887e-02 1.08818300e-02 4.51743510e-03\n",
      "  1.22624289e-04 7.57127941e-01 4.25467975e-02 6.18513450e-02\n",
      "  7.16034174e-02 1.50906192e-02 1.47480932e-05 9.16196685e-03\n",
      "  1.45673635e-03 8.34305596e-04 2.27724425e-02 3.40715866e-04\n",
      "  7.03182537e-04 6.56742183e-03 9.36273485e-02 4.24369052e-03\n",
      "  1.12975315e-04 3.85589869e-04 1.06393149e-04 9.99920726e-01\n",
      "  1.76439513e-04 7.06976280e-05 1.67275415e-04 7.86570599e-05\n",
      "  1.03279737e-04 7.29404710e-05 7.11006505e-05 3.52792595e-05\n",
      "  1.06118561e-04 4.05811443e-05 9.73851784e-05]\n",
      " [8.07390571e-01 1.68309331e-01 3.66014254e-04 6.53861025e-06\n",
      "  2.35746285e-07 1.51736406e-03 3.02271452e-04 7.75483859e-05\n",
      "  3.12958400e-06 2.48953924e-01 9.53720286e-02 8.15321654e-02\n",
      "  1.26987475e-03 3.00630694e-04 8.82248580e-03 2.39303015e-04\n",
      "  1.21852020e-06 1.06384105e-05 2.03449279e-04 3.13743271e-07\n",
      "  5.57968080e-01 6.46632239e-02 1.14588556e-03 4.26634906e-05\n",
      "  1.83607222e-06 1.41443306e-05 1.00000000e+00 5.03038393e-07\n",
      "  3.21324887e-06 1.38221822e-07 1.20606528e-05 1.29071589e-06\n",
      "  5.96883751e-08 4.86949148e-07 7.12773556e-07 1.68230457e-07\n",
      "  2.85085207e-07 5.75017339e-07 2.32128855e-06]]\n",
      "X=[1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0], Predicted=[[6.2513238e-01 3.2180235e-01 2.3990052e-03 6.3915330e-05 1.6722475e-05\n",
      "  3.5148576e-02 2.0993045e-03 6.3406018e-04 2.1258858e-05 5.6987083e-01\n",
      "  1.5329063e-01 1.9473155e-01 1.0702545e-02 2.6967239e-03 3.1568096e-03\n",
      "  2.7246366e-03 2.8551685e-05 1.0004989e-04 2.3776779e-03 1.4529741e-05\n",
      "  2.7753396e-02 2.0673597e-02 3.5115816e-02 6.4903073e-04 2.4871721e-05\n",
      "  1.8361327e-04 9.9979800e-01 7.7366458e-05 2.7397729e-04 3.0132884e-05\n",
      "  3.7153999e-04 1.2539884e-04 2.6998019e-05 1.0420201e-04 1.1463489e-04\n",
      "  9.8831097e-06 5.4244603e-05 3.2027929e-05 2.0177455e-05]]\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "Y_test = model.predict(X_test[23:26])\n",
    "Y_test1 = model.predict(X[0:1])\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (X_test[23:26],  Y_test ))\n",
    "print(\"X=%s, Predicted=%s\" % (X[0],  Y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['단일로' '교차로' '기타' '주차장' '불명' '기타/불명' '고가도로위' '지하도로내' '건널목']\n",
      "9\n",
      "['기타단일로' '교차로내' '교차로부근' '교량위' '고가도로위' '교차로횡단보도내' '기타' '지하차도(도로)내' '주차장'\n",
      " '터널안' '불명' '횡단보도상' '횡단보도부근' '기타/불명' '지하도로내' '건널목']\n",
      "16\n",
      "['승합차' '보행자' '없음' '화물차' '특수차' '승용차' '이륜차' '농기계' '원동기장치자전거' '자전거'\n",
      " '사륜오토바이(ATV)' '건설기계' '불명' '열차']\n"
     ]
    }
   ],
   "source": [
    "print(all_data['도로형태_대분류'].unique())\n",
    "print(len(all_data['도로형태_대분류'].unique()))\n",
    "print(all_data['도로형태'].unique())\n",
    "print(len(all_data['도로형태'].unique()))\n",
    "print(all_data['당사자종별_2당_대분류'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = []\n",
    "label_name.extend(all_data['도로형태_대분류'].unique()) \n",
    "label_name.extend(all_data['도로형태'].unique())\n",
    "label_name.extend(all_data['당사자종별_2당_대분류'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단일로 0.807391\n",
      "횡단보도상 0.557968\n",
      "보행자 1.000000\n"
     ]
    }
   ],
   "source": [
    "for i, x in zip(label_name, Y_test[2]):\n",
    "    if x>0.3:\n",
    "        print(i,'%f'%(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단일로 0.625132\n",
      "교차로 0.321802\n",
      "기타단일로 0.569871\n",
      "보행자 0.999798\n"
     ]
    }
   ],
   "source": [
    "for i, x in zip(label_name, Y_test1[0]):\n",
    "    if x>0.3:\n",
    "        print(i,'%f'%(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 8\n",
    "'도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = []\n",
    "for col in ['도로형태_대분류', '도로형태', '당사자종별_1당_대분류', '당사자종별_2당_대분류']:\n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = x_train_cat[col_name].values\n",
    "X = x_train_cat.drop(columns=col_name)\n",
    "X = pd.concat([X, x_train_num], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = x_test_cat.drop(columns=col_name)\n",
    "X_test = pd.concat([X_test, x_test_num],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 282)\n",
      "(25037, 51)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "x = Dense(512, activation='relu')(cat_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "cat_output = Dense(len(Y[0]), activation='sigmoid', name='cat_output')(x)\n",
    "\n",
    "model = Model(inputs=cat_input, outputs=cat_output)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 1s 59us/step - loss: 0.1742 - acc: 0.9330 - val_loss: 0.1233 - val_acc: 0.9527\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.1268 - acc: 0.9514 - val_loss: 0.1210 - val_acc: 0.9530\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.1223 - acc: 0.9530 - val_loss: 0.1192 - val_acc: 0.9539\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 36us/step - loss: 0.1195 - acc: 0.9535 - val_loss: 0.1183 - val_acc: 0.9538\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.1180 - acc: 0.9540 - val_loss: 0.1185 - val_acc: 0.9536\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.1166 - acc: 0.9544 - val_loss: 0.1186 - val_acc: 0.9536\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.1149 - acc: 0.9550 - val_loss: 0.1194 - val_acc: 0.9534\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.1135 - acc: 0.9553 - val_loss: 0.1189 - val_acc: 0.9536\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.1122 - acc: 0.9558 - val_loss: 0.1192 - val_acc: 0.9538\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.1108 - acc: 0.9562 - val_loss: 0.1218 - val_acc: 0.9517\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.1095 - acc: 0.9567 - val_loss: 0.1207 - val_acc: 0.9535\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.1077 - acc: 0.9573 - val_loss: 0.1224 - val_acc: 0.9531\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.1062 - acc: 0.9576 - val_loss: 0.1230 - val_acc: 0.9528\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 37us/step - loss: 0.1047 - acc: 0.9583 - val_loss: 0.1246 - val_acc: 0.9522\n"
     ]
    }
   ],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "callbacks = [\n",
    "    learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "                                        # approach to get optimal value by gradually decreasing learning_rate\n",
    "    EarlyStopping('val_loss', patience=10), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "                                                            # If val_loss deviates from the optimal value, \n",
    "                                                            # learning stops even if epoch remains.\n",
    "    ModelCheckpoint('model.h5', save_best_only=True)] # 모델을 학습시키면서 지금까지 등장했던 최적의 weight들을 항상 저장한다.\n",
    "\n",
    "history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[[1. 0. 0. ... 0. 1. 0.]\n",
      " [1. 0. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 1. 2. 0.]], Predicted=[[9.00926113e-01 7.42825121e-02 1.46288495e-03 4.23452657e-05\n",
      "  4.04295308e-04 1.69139858e-02 6.34770375e-03 4.10757447e-03\n",
      "  6.50824513e-05 8.60257745e-01 1.97435133e-02 6.77383393e-02\n",
      "  4.09865715e-02 6.65782159e-03 2.18166751e-04 1.22788385e-03\n",
      "  7.97970686e-04 4.61460477e-05 9.92540084e-03 4.31603548e-04\n",
      "  1.47063844e-03 2.39260728e-03 1.65975206e-02 3.47314053e-03\n",
      "  8.59308129e-05 7.59471178e-01 8.16323736e-04 1.94617048e-01\n",
      "  5.10904789e-02 3.61016323e-03 2.68924013e-02 1.17409090e-02\n",
      "  1.48408907e-02 1.55307527e-04 6.94406684e-04 1.89432958e-05\n",
      "  1.91943930e-03 7.77298063e-02 1.54226262e-04 1.10063535e-04\n",
      "  2.85069555e-01 3.76630537e-02 5.41678131e-01 2.83366144e-02\n",
      "  2.88336296e-02 1.10025657e-02 7.04900082e-03 2.43602321e-04\n",
      "  3.40929441e-02 2.78043980e-03 3.41735904e-05]\n",
      " [9.08460498e-01 7.85143152e-02 1.48918969e-03 6.56208940e-05\n",
      "  4.71273874e-04 6.29917206e-03 1.02779884e-02 3.80068482e-03\n",
      "  9.75449366e-05 8.72687936e-01 2.90888175e-02 5.73270656e-02\n",
      "  2.71079205e-02 1.07368184e-02 3.62067978e-04 1.19630212e-03\n",
      "  8.29397526e-04 5.33830425e-05 5.43725304e-03 3.77284392e-04\n",
      "  4.78261756e-03 7.19050923e-03 5.15767559e-03 3.47826723e-03\n",
      "  9.40535538e-05 7.33124912e-01 1.21427700e-02 8.01929310e-02\n",
      "  2.64878552e-02 2.35352735e-03 1.62164509e-01 7.52093177e-03\n",
      "  8.64714906e-02 2.96119950e-04 1.22591003e-03 2.55278246e-05\n",
      "  5.61939646e-03 7.34619200e-02 8.91388772e-05 2.57190387e-03\n",
      "  1.48377389e-01 1.37223452e-02 5.27416885e-01 1.34513780e-01\n",
      "  7.19570927e-03 3.87073345e-02 1.59200188e-02 4.41217184e-04\n",
      "  2.21033301e-02 3.63588310e-03 6.32605661e-05]\n",
      " [5.39575815e-01 3.56918484e-01 1.00893732e-02 1.52845692e-03\n",
      "  8.95922887e-04 7.76806995e-02 1.51777118e-02 9.77063086e-03\n",
      "  5.68072952e-04 5.16152740e-01 1.66079298e-01 2.33585700e-01\n",
      "  3.26188914e-02 1.61332209e-02 6.76987693e-04 1.01876007e-02\n",
      "  1.93287979e-03 1.75205478e-03 1.86424442e-02 8.27132026e-04\n",
      "  1.94697676e-03 1.01433685e-02 8.38259831e-02 1.13014076e-02\n",
      "  4.12855152e-04 3.82696152e-01 5.50591759e-02 1.41746789e-01\n",
      "  4.76012044e-02 1.63506530e-02 2.53930479e-01 1.48113528e-02\n",
      "  1.26461372e-01 9.18161310e-03 3.08418926e-02 9.29747650e-04\n",
      "  1.89125794e-03 1.43190508e-03 3.46096524e-04 9.98355806e-01\n",
      "  1.22361188e-03 6.66295120e-04 2.20389524e-03 9.96509450e-04\n",
      "  2.43203162e-04 6.88916945e-04 6.09142648e-04 2.47092888e-04\n",
      "  5.71301847e-04 3.18004692e-04 5.42676426e-04]\n",
      " [9.59216714e-01 2.44902130e-02 5.29536279e-04 1.73206063e-05\n",
      "  9.26457869e-05 1.49662439e-02 2.92193785e-04 1.01297593e-03\n",
      "  5.96910422e-06 9.24216568e-01 4.27536387e-03 2.55397353e-02\n",
      "  1.91382281e-02 5.77602943e-04 1.27787334e-05 6.81863748e-04\n",
      "  1.76281115e-04 2.12055638e-05 2.04397347e-02 1.80236500e-04\n",
      "  6.57543787e-05 1.74301342e-04 1.64946485e-02 4.74248343e-04\n",
      "  1.51798176e-05 2.50778526e-01 2.79845757e-04 6.76507890e-01\n",
      "  5.69317378e-02 1.27113927e-02 9.25236940e-03 1.06138550e-02\n",
      "  5.38969552e-03 1.32717076e-04 2.49318196e-03 1.14950681e-05\n",
      "  3.18053208e-04 4.29839864e-02 8.83174871e-05 6.28274065e-05\n",
      "  5.53171039e-01 2.83703301e-02 1.63073987e-01 6.50329003e-03\n",
      "  1.05922222e-01 3.89955589e-03 1.60250778e-03 5.89931406e-05\n",
      "  3.95423397e-02 3.41061474e-04 5.80527421e-06]]\n",
      "X=[1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0], Predicted=[[5.51886559e-01 3.95760149e-01 6.80819247e-03 7.41994649e-04\n",
      "  5.41557441e-04 3.79243456e-02 1.25608556e-02 4.50849161e-03\n",
      "  7.76232337e-04 4.55460727e-01 1.80613995e-01 2.69195825e-01\n",
      "  2.23419908e-02 1.38630932e-02 2.18288302e-02 7.67607754e-03\n",
      "  3.85251624e-04 1.01209036e-03 4.65220539e-03 3.78432946e-04\n",
      "  8.69840235e-02 5.21158166e-02 3.94524820e-02 5.91730652e-03\n",
      "  5.33900922e-04 6.88784778e-01 1.13481293e-02 1.11666508e-01\n",
      "  1.39462978e-01 9.92401410e-03 5.70004210e-02 1.48909325e-02\n",
      "  2.13267338e-02 1.91364888e-04 4.52120992e-04 1.29280510e-04\n",
      "  3.98773421e-03 1.69923180e-03 9.95425880e-01 1.94525393e-03\n",
      "  1.10416475e-03 7.52535590e-04 5.12508536e-03 1.38732034e-03\n",
      "  1.98831127e-04 6.96169271e-04 9.64028935e-04 3.43382970e-04\n",
      "  4.07125044e-04 7.90742284e-04 4.98229463e-04]]\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "Y_test = model.predict(X_test[26:30])\n",
    "Y_test1 = model.predict(X[0:1])\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (X_test[26:30],  Y_test ))\n",
    "print(\"X=%s, Predicted=%s\" % (X[0],  Y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['단일로' '교차로' '기타' '주차장' '불명' '기타/불명' '고가도로위' '지하도로내' '건널목']\n",
      "9\n",
      "['기타단일로' '교차로내' '교차로부근' '교량위' '고가도로위' '교차로횡단보도내' '기타' '지하차도(도로)내' '주차장'\n",
      " '터널안' '불명' '횡단보도상' '횡단보도부근' '기타/불명' '지하도로내' '건널목']\n",
      "16\n",
      "['승용차' '자전거' '화물차' '승합차' '건설기계' '이륜차' '특수차' '원동기장치자전거' '사륜오토바이(ATV)' '농기계'\n",
      " '개인형이동수단(PM)' '불명']\n",
      "12\n",
      "['승합차' '보행자' '없음' '화물차' '특수차' '승용차' '이륜차' '농기계' '원동기장치자전거' '자전거'\n",
      " '사륜오토바이(ATV)' '건설기계' '불명' '열차']\n"
     ]
    }
   ],
   "source": [
    "print(all_data['도로형태_대분류'].unique())\n",
    "print(len(all_data['도로형태_대분류'].unique()))\n",
    "print(all_data['도로형태'].unique())\n",
    "print(len(all_data['도로형태'].unique()))\n",
    "print(all_data['당사자종별_1당_대분류'].unique())\n",
    "print(len(all_data['당사자종별_1당_대분류'].unique()))\n",
    "print(all_data['당사자종별_2당_대분류'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = []\n",
    "label_name.extend(all_data['도로형태_대분류'].unique()) \n",
    "label_name.extend(all_data['도로형태'].unique())\n",
    "label_name.extend(all_data['당사자종별_1당_대분류'].unique())\n",
    "label_name.extend(all_data['당사자종별_2당_대분류'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단일로 0.908460\n",
      "기타단일로 0.872688\n",
      "승용차 0.733125\n",
      "이륜차 0.162165\n",
      "화물차 0.148377\n",
      "승용차 0.527417\n",
      "이륜차 0.134514\n"
     ]
    }
   ],
   "source": [
    "for i, x in zip(label_name, Y_test[1]):\n",
    "    if x>0.1:\n",
    "        print(i,'%f'%(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단일로 0.551887\n",
      "교차로 0.395760\n",
      "기타단일로 0.455461\n",
      "승용차 0.688785\n",
      "보행자 0.995426\n"
     ]
    }
   ],
   "source": [
    "for i, x in zip(label_name, Y_test1[0]):\n",
    "    if x>0.3:\n",
    "        print(i,'%f'%(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 9\n",
    "'사망자수', '사상자수', '발생지시군구'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = []\n",
    "for col in ['발생지시군구']:\n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_num = x_train_num['사망자수'].values\n",
    "Y_cat = x_train_cat[col_name].values\n",
    "X1 = x_train_cat.drop(columns=col_name)\n",
    "X2 = x_train_num.drop(columns=['사망자수', '사상자수'])\n",
    "X = pd.concat([X1, X2], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 123)\n",
      "208\n",
      "주야_야간\n",
      "주야_주간\n",
      "요일_금\n",
      "요일_월\n",
      "요일_일\n",
      "요일_목\n",
      "요일_수\n",
      "요일_화\n",
      "요일_토\n",
      "발생지시도_경기\n",
      "발생지시도_전남\n",
      "발생지시도_대구\n",
      "발생지시도_경북\n",
      "발생지시도_충남\n",
      "발생지시도_강원\n",
      "발생지시도_충북\n",
      "발생지시도_서울\n",
      "발생지시도_광주\n",
      "발생지시도_부산\n",
      "발생지시도_경남\n",
      "발생지시도_인천\n",
      "발생지시도_세종\n",
      "발생지시도_전북\n",
      "발생지시도_대전\n",
      "발생지시도_울산\n",
      "발생지시도_제주\n",
      "사고유형_대분류_차대차\n",
      "사고유형_대분류_차대사람\n",
      "사고유형_대분류_차량단독\n",
      "사고유형_대분류_건널목\n",
      "사고유형_중분류_측면충돌\n",
      "사고유형_중분류_차도통행중\n",
      "사고유형_중분류_전도전복\n",
      "사고유형_중분류_정면충돌\n",
      "사고유형_중분류_추돌\n",
      "사고유형_중분류_횡단중\n",
      "사고유형_중분류_기타\n",
      "사고유형_중분류_전도\n",
      "사고유형_중분류_도로이탈\n",
      "사고유형_중분류_길가장자리구역통행중\n",
      "사고유형_중분류_공작물충돌\n",
      "사고유형_중분류_전복\n",
      "사고유형_중분류_보도통행중\n",
      "사고유형_중분류_후진중충돌\n",
      "사고유형_중분류_주/정차차량 충돌\n",
      "사고유형_중분류_측면직각충돌\n",
      "사고유형_중분류_차단기돌파\n",
      "사고유형_중분류_직전진행\n",
      "사고유형_중분류_경보기무시\n",
      "법규위반_중앙선 침범\n",
      "법규위반_과속\n",
      "법규위반_안전운전 의무 불이행\n",
      "법규위반_안전거리 미확보\n",
      "법규위반_기타(운전자법규위반)\n",
      "법규위반_신호위반\n",
      "법규위반_직진 및 우회전차의 통행방해\n",
      "법규위반_교차로 통행방법 위반\n",
      "법규위반_보행자 보호의무 위반\n",
      "법규위반_부당한 회전\n",
      "법규위반_차로위반(진로변경 위반)\n",
      "법규위반_앞지르기 금지위반\n",
      "법규위반_앞지르기 방법위반\n",
      "법규위반_정비불량 제차의 운전금지위반\n",
      "법규위반_서행 및 일시정지위반\n",
      "법규위반_과로\n",
      "법규위반_철길건널목 통과방법위반\n",
      "법규위반_진로양보 의무 불이행\n",
      "법규위반_보행자과실\n",
      "법규위반_통행우선 순위위반\n",
      "도로형태_대분류_단일로\n",
      "도로형태_대분류_교차로\n",
      "도로형태_대분류_기타\n",
      "도로형태_대분류_주차장\n",
      "도로형태_대분류_불명\n",
      "도로형태_대분류_기타/불명\n",
      "도로형태_대분류_고가도로위\n",
      "도로형태_대분류_지하도로내\n",
      "도로형태_대분류_건널목\n",
      "도로형태_기타단일로\n",
      "도로형태_교차로내\n",
      "도로형태_교차로부근\n",
      "도로형태_교량위\n",
      "도로형태_고가도로위\n",
      "도로형태_교차로횡단보도내\n",
      "도로형태_기타\n",
      "도로형태_지하차도(도로)내\n",
      "도로형태_주차장\n",
      "도로형태_터널안\n",
      "도로형태_불명\n",
      "도로형태_횡단보도상\n",
      "도로형태_횡단보도부근\n",
      "도로형태_기타/불명\n",
      "도로형태_지하도로내\n",
      "도로형태_건널목\n",
      "당사자종별_1당_대분류_승용차\n",
      "당사자종별_1당_대분류_자전거\n",
      "당사자종별_1당_대분류_화물차\n",
      "당사자종별_1당_대분류_승합차\n",
      "당사자종별_1당_대분류_건설기계\n",
      "당사자종별_1당_대분류_이륜차\n",
      "당사자종별_1당_대분류_특수차\n",
      "당사자종별_1당_대분류_원동기장치자전거\n",
      "당사자종별_1당_대분류_사륜오토바이(ATV)\n",
      "당사자종별_1당_대분류_농기계\n",
      "당사자종별_1당_대분류_개인형이동수단(PM)\n",
      "당사자종별_1당_대분류_불명\n",
      "당사자종별_2당_대분류_승합차\n",
      "당사자종별_2당_대분류_보행자\n",
      "당사자종별_2당_대분류_없음\n",
      "당사자종별_2당_대분류_화물차\n",
      "당사자종별_2당_대분류_특수차\n",
      "당사자종별_2당_대분류_승용차\n",
      "당사자종별_2당_대분류_이륜차\n",
      "당사자종별_2당_대분류_농기계\n",
      "당사자종별_2당_대분류_원동기장치자전거\n",
      "당사자종별_2당_대분류_자전거\n",
      "당사자종별_2당_대분류_사륜오토바이(ATV)\n",
      "당사자종별_2당_대분류_건설기계\n",
      "당사자종별_2당_대분류_불명\n",
      "당사자종별_2당_대분류_열차\n",
      "중상자수\n",
      "경상자수\n",
      "부상신고자수\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(len(col_name))\n",
    "for name in pd.concat([X1, X2], axis=1).columns:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = x_test_cat.drop(columns=col_name)\n",
    "X_test2 = x_test_num.drop(columns=['사망자수', '사상자수'])\n",
    "X_test = pd.concat([X_test1, X_test2],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "x = Dense(512, activation='relu')(cat_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "cat_output = Dense(len(Y_cat[0]), activation='softmax', name='cat_output')(x)\n",
    "num_output = Dense(len(Y_num.shape), name='num_output')(x)\n",
    "\n",
    "model = Model(inputs=cat_input, outputs=[cat_output, num_output])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'cat_output': 'categorical_crossentropy', 'num_output': 'mse'},\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 2.4411 - cat_output_loss: 2.3755 - num_output_loss: 0.0656 - cat_output_acc: 0.2548 - num_output_acc: 0.9673 - val_loss: 2.8439 - val_cat_output_loss: 2.7821 - val_num_output_loss: 0.0617 - val_cat_output_acc: 0.1510 - val_num_output_acc: 0.9629\n",
      "Epoch 2/50\n",
      " 3584/20029 [====>.........................] - ETA: 0s - loss: 2.3795 - cat_output_loss: 2.3207 - num_output_loss: 0.0588 - cat_output_acc: 0.2693 - num_output_acc: 0.9685"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:1043: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,cat_output_acc,cat_output_loss,num_output_acc,val_num_output_acc,val_loss,val_cat_output_acc,val_num_output_loss,num_output_loss,val_cat_output_loss,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20029/20029 [==============================] - 1s 45us/step - loss: 2.4208 - cat_output_loss: 2.3572 - num_output_loss: 0.0636 - cat_output_acc: 0.2577 - num_output_acc: 0.9670 - val_loss: 2.8496 - val_cat_output_loss: 2.7887 - val_num_output_loss: 0.0609 - val_cat_output_acc: 0.1508 - val_num_output_acc: 0.9627\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 2.4006 - cat_output_loss: 2.3378 - num_output_loss: 0.0628 - cat_output_acc: 0.2671 - num_output_acc: 0.9666 - val_loss: 2.8787 - val_cat_output_loss: 2.8181 - val_num_output_loss: 0.0606 - val_cat_output_acc: 0.1558 - val_num_output_acc: 0.9631\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 2.3908 - cat_output_loss: 2.3269 - num_output_loss: 0.0639 - cat_output_acc: 0.2702 - num_output_acc: 0.9659 - val_loss: 2.8669 - val_cat_output_loss: 2.8063 - val_num_output_loss: 0.0607 - val_cat_output_acc: 0.1498 - val_num_output_acc: 0.9629\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 47us/step - loss: 2.3590 - cat_output_loss: 2.2965 - num_output_loss: 0.0625 - cat_output_acc: 0.2794 - num_output_acc: 0.9666 - val_loss: 2.8979 - val_cat_output_loss: 2.8365 - val_num_output_loss: 0.0615 - val_cat_output_acc: 0.1456 - val_num_output_acc: 0.9627\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 2.3427 - cat_output_loss: 2.2799 - num_output_loss: 0.0628 - cat_output_acc: 0.2797 - num_output_acc: 0.9665 - val_loss: 2.9109 - val_cat_output_loss: 2.8501 - val_num_output_loss: 0.0608 - val_cat_output_acc: 0.1486 - val_num_output_acc: 0.9629\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 2.3273 - cat_output_loss: 2.2635 - num_output_loss: 0.0638 - cat_output_acc: 0.2887 - num_output_acc: 0.9665 - val_loss: 2.9189 - val_cat_output_loss: 2.8575 - val_num_output_loss: 0.0614 - val_cat_output_acc: 0.1452 - val_num_output_acc: 0.9629\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 2.3002 - cat_output_loss: 2.2391 - num_output_loss: 0.0611 - cat_output_acc: 0.2938 - num_output_acc: 0.9669 - val_loss: 2.9402 - val_cat_output_loss: 2.8795 - val_num_output_loss: 0.0607 - val_cat_output_acc: 0.1520 - val_num_output_acc: 0.9629\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 2.2777 - cat_output_loss: 2.2174 - num_output_loss: 0.0602 - cat_output_acc: 0.3035 - num_output_acc: 0.9661 - val_loss: 2.9496 - val_cat_output_loss: 2.8887 - val_num_output_loss: 0.0609 - val_cat_output_acc: 0.1426 - val_num_output_acc: 0.9625\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 2.2655 - cat_output_loss: 2.2063 - num_output_loss: 0.0592 - cat_output_acc: 0.3033 - num_output_acc: 0.9666 - val_loss: 2.9819 - val_cat_output_loss: 2.9204 - val_num_output_loss: 0.0615 - val_cat_output_acc: 0.1450 - val_num_output_acc: 0.9631\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 2.2452 - cat_output_loss: 2.1856 - num_output_loss: 0.0596 - cat_output_acc: 0.3122 - num_output_acc: 0.9667 - val_loss: 2.9723 - val_cat_output_loss: 2.9131 - val_num_output_loss: 0.0592 - val_cat_output_acc: 0.1486 - val_num_output_acc: 0.9629\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 2.2277 - cat_output_loss: 2.1663 - num_output_loss: 0.0614 - cat_output_acc: 0.3144 - num_output_acc: 0.9659 - val_loss: 2.9847 - val_cat_output_loss: 2.9241 - val_num_output_loss: 0.0606 - val_cat_output_acc: 0.1438 - val_num_output_acc: 0.9631\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 2.2101 - cat_output_loss: 2.1503 - num_output_loss: 0.0598 - cat_output_acc: 0.3213 - num_output_acc: 0.9670 - val_loss: 3.0154 - val_cat_output_loss: 2.9557 - val_num_output_loss: 0.0597 - val_cat_output_acc: 0.1418 - val_num_output_acc: 0.9625\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 46us/step - loss: 2.1971 - cat_output_loss: 2.1387 - num_output_loss: 0.0584 - cat_output_acc: 0.3220 - num_output_acc: 0.9665 - val_loss: 3.0186 - val_cat_output_loss: 2.9572 - val_num_output_loss: 0.0614 - val_cat_output_acc: 0.1432 - val_num_output_acc: 0.9625\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 2.1661 - cat_output_loss: 2.1069 - num_output_loss: 0.0592 - cat_output_acc: 0.3339 - num_output_acc: 0.9667 - val_loss: 3.0343 - val_cat_output_loss: 2.9745 - val_num_output_loss: 0.0598 - val_cat_output_acc: 0.1426 - val_num_output_acc: 0.9627\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 1s 46us/step - loss: 2.1467 - cat_output_loss: 2.0903 - num_output_loss: 0.0563 - cat_output_acc: 0.3346 - num_output_acc: 0.9662 - val_loss: 3.0806 - val_cat_output_loss: 3.0211 - val_num_output_loss: 0.0596 - val_cat_output_acc: 0.1414 - val_num_output_acc: 0.9627\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 1s 46us/step - loss: 2.1451 - cat_output_loss: 2.0884 - num_output_loss: 0.0566 - cat_output_acc: 0.3385 - num_output_acc: 0.9667 - val_loss: 3.0575 - val_cat_output_loss: 2.9975 - val_num_output_loss: 0.0601 - val_cat_output_acc: 0.1418 - val_num_output_acc: 0.9621\n",
      "Epoch 18/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 2.1265 - cat_output_loss: 2.0709 - num_output_loss: 0.0556 - cat_output_acc: 0.3450 - num_output_acc: 0.9665 - val_loss: 3.0934 - val_cat_output_loss: 3.0328 - val_num_output_loss: 0.0606 - val_cat_output_acc: 0.1398 - val_num_output_acc: 0.9623\n",
      "Epoch 19/50\n",
      "20029/20029 [==============================] - 1s 46us/step - loss: 2.1150 - cat_output_loss: 2.0571 - num_output_loss: 0.0579 - cat_output_acc: 0.3485 - num_output_acc: 0.9667 - val_loss: 3.0849 - val_cat_output_loss: 3.0245 - val_num_output_loss: 0.0604 - val_cat_output_acc: 0.1370 - val_num_output_acc: 0.9613\n",
      "Epoch 20/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 2.0956 - cat_output_loss: 2.0391 - num_output_loss: 0.0565 - cat_output_acc: 0.3572 - num_output_acc: 0.9668 - val_loss: 3.1149 - val_cat_output_loss: 3.0548 - val_num_output_loss: 0.0602 - val_cat_output_acc: 0.1452 - val_num_output_acc: 0.9623\n",
      "Epoch 21/50\n",
      "20029/20029 [==============================] - 1s 46us/step - loss: 2.0775 - cat_output_loss: 2.0181 - num_output_loss: 0.0594 - cat_output_acc: 0.3631 - num_output_acc: 0.9664 - val_loss: 3.1244 - val_cat_output_loss: 3.0594 - val_num_output_loss: 0.0651 - val_cat_output_acc: 0.1368 - val_num_output_acc: 0.9625\n",
      "Epoch 22/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 2.0640 - cat_output_loss: 2.0057 - num_output_loss: 0.0583 - cat_output_acc: 0.3633 - num_output_acc: 0.9662 - val_loss: 3.1298 - val_cat_output_loss: 3.0692 - val_num_output_loss: 0.0606 - val_cat_output_acc: 0.1408 - val_num_output_acc: 0.9627\n",
      "Epoch 23/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 2.0641 - cat_output_loss: 2.0047 - num_output_loss: 0.0594 - cat_output_acc: 0.3630 - num_output_acc: 0.9669 - val_loss: 3.1336 - val_cat_output_loss: 3.0735 - val_num_output_loss: 0.0600 - val_cat_output_acc: 0.1464 - val_num_output_acc: 0.9621\n",
      "Epoch 24/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 2.0341 - cat_output_loss: 1.9771 - num_output_loss: 0.0570 - cat_output_acc: 0.3730 - num_output_acc: 0.9666 - val_loss: 3.1902 - val_cat_output_loss: 3.1304 - val_num_output_loss: 0.0598 - val_cat_output_acc: 0.1380 - val_num_output_acc: 0.9615\n",
      "Epoch 25/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 2.0276 - cat_output_loss: 1.9685 - num_output_loss: 0.0591 - cat_output_acc: 0.3753 - num_output_acc: 0.9666 - val_loss: 3.1934 - val_cat_output_loss: 3.1337 - val_num_output_loss: 0.0597 - val_cat_output_acc: 0.1334 - val_num_output_acc: 0.9619\n",
      "Epoch 26/50\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 2.0033 - cat_output_loss: 1.9481 - num_output_loss: 0.0552 - cat_output_acc: 0.3798 - num_output_acc: 0.9658 - val_loss: 3.1821 - val_cat_output_loss: 3.1215 - val_num_output_loss: 0.0606 - val_cat_output_acc: 0.1326 - val_num_output_acc: 0.9609\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20029/20029 [==============================] - 1s 48us/step - loss: 1.9900 - cat_output_loss: 1.9345 - num_output_loss: 0.0555 - cat_output_acc: 0.3865 - num_output_acc: 0.9663 - val_loss: 3.2208 - val_cat_output_loss: 3.1605 - val_num_output_loss: 0.0604 - val_cat_output_acc: 0.1360 - val_num_output_acc: 0.9627\n",
      "Epoch 28/50\n",
      "20029/20029 [==============================] - 1s 49us/step - loss: 1.9823 - cat_output_loss: 1.9251 - num_output_loss: 0.0572 - cat_output_acc: 0.3854 - num_output_acc: 0.9668 - val_loss: 3.2090 - val_cat_output_loss: 3.1487 - val_num_output_loss: 0.0603 - val_cat_output_acc: 0.1396 - val_num_output_acc: 0.9613\n",
      "Epoch 29/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 1.9738 - cat_output_loss: 1.9193 - num_output_loss: 0.0545 - cat_output_acc: 0.3914 - num_output_acc: 0.9668 - val_loss: 3.2377 - val_cat_output_loss: 3.1780 - val_num_output_loss: 0.0597 - val_cat_output_acc: 0.1340 - val_num_output_acc: 0.9621\n",
      "Epoch 30/50\n",
      "20029/20029 [==============================] - 1s 47us/step - loss: 1.9537 - cat_output_loss: 1.8950 - num_output_loss: 0.0587 - cat_output_acc: 0.3945 - num_output_acc: 0.9663 - val_loss: 3.2600 - val_cat_output_loss: 3.1947 - val_num_output_loss: 0.0654 - val_cat_output_acc: 0.1346 - val_num_output_acc: 0.9627\n",
      "Epoch 31/50\n",
      "20029/20029 [==============================] - 1s 47us/step - loss: 1.9483 - cat_output_loss: 1.8892 - num_output_loss: 0.0591 - cat_output_acc: 0.3990 - num_output_acc: 0.9664 - val_loss: 3.2623 - val_cat_output_loss: 3.2028 - val_num_output_loss: 0.0595 - val_cat_output_acc: 0.1366 - val_num_output_acc: 0.9625\n",
      "Epoch 32/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 1.9452 - cat_output_loss: 1.8885 - num_output_loss: 0.0567 - cat_output_acc: 0.3924 - num_output_acc: 0.9663 - val_loss: 3.2429 - val_cat_output_loss: 3.1813 - val_num_output_loss: 0.0616 - val_cat_output_acc: 0.1330 - val_num_output_acc: 0.9627\n",
      "Epoch 33/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 1.9178 - cat_output_loss: 1.8625 - num_output_loss: 0.0554 - cat_output_acc: 0.4065 - num_output_acc: 0.9666 - val_loss: 3.2594 - val_cat_output_loss: 3.1996 - val_num_output_loss: 0.0598 - val_cat_output_acc: 0.1408 - val_num_output_acc: 0.9627\n",
      "Epoch 34/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 1.9094 - cat_output_loss: 1.8545 - num_output_loss: 0.0548 - cat_output_acc: 0.4125 - num_output_acc: 0.9667 - val_loss: 3.2926 - val_cat_output_loss: 3.2335 - val_num_output_loss: 0.0591 - val_cat_output_acc: 0.1372 - val_num_output_acc: 0.9621\n",
      "Epoch 35/50\n",
      "20029/20029 [==============================] - 1s 46us/step - loss: 1.9010 - cat_output_loss: 1.8458 - num_output_loss: 0.0552 - cat_output_acc: 0.4116 - num_output_acc: 0.9672 - val_loss: 3.3157 - val_cat_output_loss: 3.2560 - val_num_output_loss: 0.0597 - val_cat_output_acc: 0.1386 - val_num_output_acc: 0.9621\n",
      "Epoch 36/50\n",
      "20029/20029 [==============================] - 1s 46us/step - loss: 1.8879 - cat_output_loss: 1.8346 - num_output_loss: 0.0534 - cat_output_acc: 0.4103 - num_output_acc: 0.9665 - val_loss: 3.3329 - val_cat_output_loss: 3.2712 - val_num_output_loss: 0.0617 - val_cat_output_acc: 0.1352 - val_num_output_acc: 0.9623\n",
      "Epoch 37/50\n",
      "20029/20029 [==============================] - 1s 47us/step - loss: 1.8876 - cat_output_loss: 1.8341 - num_output_loss: 0.0534 - cat_output_acc: 0.4158 - num_output_acc: 0.9668 - val_loss: 3.3131 - val_cat_output_loss: 3.2523 - val_num_output_loss: 0.0608 - val_cat_output_acc: 0.1336 - val_num_output_acc: 0.9617\n",
      "Epoch 38/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 1.8655 - cat_output_loss: 1.8124 - num_output_loss: 0.0531 - cat_output_acc: 0.4208 - num_output_acc: 0.9664 - val_loss: 3.3547 - val_cat_output_loss: 3.2931 - val_num_output_loss: 0.0616 - val_cat_output_acc: 0.1336 - val_num_output_acc: 0.9627\n",
      "Epoch 39/50\n",
      "20029/20029 [==============================] - 1s 46us/step - loss: 1.8576 - cat_output_loss: 1.8034 - num_output_loss: 0.0542 - cat_output_acc: 0.4243 - num_output_acc: 0.9664 - val_loss: 3.3679 - val_cat_output_loss: 3.3085 - val_num_output_loss: 0.0595 - val_cat_output_acc: 0.1358 - val_num_output_acc: 0.9629\n",
      "Epoch 40/50\n",
      "20029/20029 [==============================] - 1s 46us/step - loss: 1.8553 - cat_output_loss: 1.7999 - num_output_loss: 0.0554 - cat_output_acc: 0.4252 - num_output_acc: 0.9665 - val_loss: 3.3717 - val_cat_output_loss: 3.3128 - val_num_output_loss: 0.0589 - val_cat_output_acc: 0.1320 - val_num_output_acc: 0.9613\n",
      "Epoch 41/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 1.8473 - cat_output_loss: 1.7901 - num_output_loss: 0.0571 - cat_output_acc: 0.4290 - num_output_acc: 0.9670 - val_loss: 3.3236 - val_cat_output_loss: 3.2581 - val_num_output_loss: 0.0655 - val_cat_output_acc: 0.1282 - val_num_output_acc: 0.9627\n",
      "Epoch 42/50\n",
      "20029/20029 [==============================] - 1s 46us/step - loss: 1.8575 - cat_output_loss: 1.7971 - num_output_loss: 0.0604 - cat_output_acc: 0.4273 - num_output_acc: 0.9664 - val_loss: 3.3546 - val_cat_output_loss: 3.2917 - val_num_output_loss: 0.0629 - val_cat_output_acc: 0.1350 - val_num_output_acc: 0.9621\n",
      "Epoch 43/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 1.8329 - cat_output_loss: 1.7766 - num_output_loss: 0.0563 - cat_output_acc: 0.4348 - num_output_acc: 0.9670 - val_loss: 3.4095 - val_cat_output_loss: 3.3480 - val_num_output_loss: 0.0615 - val_cat_output_acc: 0.1342 - val_num_output_acc: 0.9619\n",
      "Epoch 44/50\n",
      "20029/20029 [==============================] - 1s 47us/step - loss: 1.8397 - cat_output_loss: 1.7796 - num_output_loss: 0.0601 - cat_output_acc: 0.4335 - num_output_acc: 0.9664 - val_loss: 3.4115 - val_cat_output_loss: 3.3504 - val_num_output_loss: 0.0611 - val_cat_output_acc: 0.1338 - val_num_output_acc: 0.9629\n",
      "Epoch 45/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 1.8262 - cat_output_loss: 1.7694 - num_output_loss: 0.0568 - cat_output_acc: 0.4355 - num_output_acc: 0.9670 - val_loss: 3.3846 - val_cat_output_loss: 3.3262 - val_num_output_loss: 0.0584 - val_cat_output_acc: 0.1324 - val_num_output_acc: 0.9629\n",
      "Epoch 46/50\n",
      "20029/20029 [==============================] - 1s 46us/step - loss: 1.8076 - cat_output_loss: 1.7544 - num_output_loss: 0.0532 - cat_output_acc: 0.4391 - num_output_acc: 0.9670 - val_loss: 3.4168 - val_cat_output_loss: 3.3573 - val_num_output_loss: 0.0595 - val_cat_output_acc: 0.1354 - val_num_output_acc: 0.9631\n",
      "Epoch 47/50\n",
      "20029/20029 [==============================] - 1s 47us/step - loss: 1.7977 - cat_output_loss: 1.7447 - num_output_loss: 0.0531 - cat_output_acc: 0.4451 - num_output_acc: 0.9665 - val_loss: 3.4234 - val_cat_output_loss: 3.3640 - val_num_output_loss: 0.0593 - val_cat_output_acc: 0.1342 - val_num_output_acc: 0.9629\n",
      "Epoch 48/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 1.7982 - cat_output_loss: 1.7450 - num_output_loss: 0.0531 - cat_output_acc: 0.4414 - num_output_acc: 0.9659 - val_loss: 3.4222 - val_cat_output_loss: 3.3623 - val_num_output_loss: 0.0599 - val_cat_output_acc: 0.1308 - val_num_output_acc: 0.9607\n",
      "Epoch 49/50\n",
      "20029/20029 [==============================] - 1s 46us/step - loss: 1.7973 - cat_output_loss: 1.7431 - num_output_loss: 0.0542 - cat_output_acc: 0.4436 - num_output_acc: 0.9667 - val_loss: 3.4286 - val_cat_output_loss: 3.3671 - val_num_output_loss: 0.0616 - val_cat_output_acc: 0.1318 - val_num_output_acc: 0.9625\n",
      "Epoch 50/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 1.7819 - cat_output_loss: 1.7250 - num_output_loss: 0.0569 - cat_output_acc: 0.4430 - num_output_acc: 0.9661 - val_loss: 3.4409 - val_cat_output_loss: 3.3785 - val_num_output_loss: 0.0624 - val_cat_output_acc: 0.1320 - val_num_output_acc: 0.9629\n"
     ]
    }
   ],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "callbacks = [\n",
    "    learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "                                        # approach to get optimal value by gradually decreasing learning_rate\n",
    "#     EarlyStopping('val_loss', patience=10), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "                                                            # If val_loss deviates from the optimal value, \n",
    "                                                            # learning stops even if epoch remains.\n",
    "    ModelCheckpoint('model.h5', save_best_only=True)] # 모델을 학습시키면서 지금까지 등장했던 최적의 weight들을 항상 저장한다.\n",
    "\n",
    "history = model.fit(X, {'cat_output':Y_cat, 'num_output':Y_num}, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[[0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 2. 0.]], Predicted=[array([[2.06447817e-10, 3.77568282e-15, 1.18520960e-09, 1.15495769e-09,\n",
      "        2.29895074e-12, 1.79602719e-12, 1.50841018e-07, 1.76865473e-08,\n",
      "        4.33623982e-14, 8.63113192e-10, 1.54300697e-08, 6.40886566e-10,\n",
      "        5.41995883e-01, 2.49401246e-08, 5.64827699e-11, 3.30352201e-14,\n",
      "        3.05099491e-07, 4.58504027e-03, 8.35439692e-15, 4.31152392e-10,\n",
      "        1.08171800e-08, 9.18508624e-04, 6.01031757e-13, 2.04222111e-10,\n",
      "        2.31254881e-12, 9.91041361e-06, 6.28813841e-12, 3.95165733e-10,\n",
      "        2.64920743e-08, 1.82250035e-10, 2.18791416e-10, 1.01592068e-11,\n",
      "        2.27236452e-10, 6.79299106e-09, 6.73513512e-07, 1.70180485e-07,\n",
      "        1.87787488e-02, 4.81064188e-10, 1.73111753e-12, 1.18970372e-12,\n",
      "        1.62820349e-14, 5.31010479e-11, 3.99113520e-11, 2.28036982e-11,\n",
      "        1.64215235e-05, 1.28656591e-11, 2.95440790e-11, 7.85392817e-09,\n",
      "        3.80131655e-06, 4.88441093e-11, 3.08278680e-11, 1.05511572e-11,\n",
      "        2.14079705e-06, 1.43833542e-10, 8.06755764e-08, 1.09915813e-10,\n",
      "        1.76838330e-06, 3.56766805e-02, 2.22281896e-13, 3.39726619e-12,\n",
      "        1.63663759e-15, 6.23239828e-07, 4.37642113e-18, 2.14678622e-11,\n",
      "        2.61767946e-06, 4.80873341e-10, 1.14751026e-15, 2.00504591e-09,\n",
      "        2.66173497e-14, 2.89642267e-05, 8.21837239e-06, 1.71431100e-08,\n",
      "        9.59293547e-11, 1.77881238e-10, 2.00403252e-13, 1.58283147e-08,\n",
      "        1.97641773e-12, 1.79018397e-10, 2.51963339e-10, 4.35086456e-13,\n",
      "        1.24213641e-13, 6.35689282e-14, 7.32731844e-12, 9.07490289e-07,\n",
      "        6.24176089e-09, 7.87957460e-12, 6.56501817e-13, 1.17886956e-13,\n",
      "        7.69902755e-08, 5.71131751e-14, 1.77233315e-11, 2.68240807e-09,\n",
      "        2.24063643e-10, 5.47119919e-11, 4.27746771e-09, 8.91072546e-07,\n",
      "        4.65539135e-10, 9.36627109e-10, 7.41273633e-14, 7.27989686e-07,\n",
      "        3.70189462e-10, 2.13125554e-06, 5.47634937e-10, 9.64899755e-07,\n",
      "        3.86874473e-12, 1.21902349e-11, 1.49420083e-01, 2.07410417e-14,\n",
      "        2.18890336e-10, 8.05767812e-03, 3.06882164e-09, 4.05984374e-15,\n",
      "        1.11691945e-09, 2.53357370e-11, 9.63428892e-10, 5.07377473e-11,\n",
      "        2.20798213e-10, 2.46412668e-10, 5.84934011e-12, 1.73562075e-04,\n",
      "        1.09538045e-10, 4.35552778e-07, 2.26356245e-09, 8.26585814e-11,\n",
      "        3.00676855e-13, 2.85578311e-10, 1.28296798e-12, 5.38509429e-14,\n",
      "        1.52516944e-09, 3.00125902e-15, 2.08120576e-10, 6.57502525e-11,\n",
      "        3.71872845e-11, 1.08803079e-07, 6.99212066e-09, 4.79037865e-10,\n",
      "        7.28273846e-14, 2.28758068e-10, 3.48763365e-07, 1.01440178e-09,\n",
      "        7.51125384e-08, 4.17750556e-12, 1.57429256e-12, 3.57127328e-09,\n",
      "        4.17923041e-14, 2.07699133e-13, 1.07943393e-07, 6.41993847e-10,\n",
      "        2.49133325e-10, 6.07617906e-13, 1.77339382e-12, 8.58711539e-12,\n",
      "        1.59266483e-06, 1.35061060e-11, 8.62740712e-11, 8.17158841e-10,\n",
      "        2.64712124e-12, 1.23048327e-12, 6.34541072e-21, 1.06774604e-12,\n",
      "        1.72100584e-17, 1.17053436e-10, 6.15327296e-16, 5.34244525e-17,\n",
      "        1.85959026e-11, 2.31525183e-01, 6.81381357e-14, 6.88330271e-15,\n",
      "        4.70728173e-06, 4.52388821e-10, 4.85862905e-10, 5.99080638e-12,\n",
      "        7.45802264e-09, 7.46466352e-14, 5.01404475e-06, 2.34909980e-09,\n",
      "        3.49299922e-09, 9.23493957e-08, 3.08082974e-07, 1.99470401e-06,\n",
      "        2.21764953e-08, 1.26782684e-09, 9.04974570e-07, 1.01547482e-08,\n",
      "        5.63119701e-14, 8.16318990e-14, 7.51096103e-03, 2.24516477e-12,\n",
      "        1.17373480e-08, 1.01402602e-10, 3.87037485e-20, 3.60185991e-12,\n",
      "        4.47594084e-06, 9.85757674e-16, 4.29840018e-11, 2.77098761e-11,\n",
      "        1.38557041e-10, 7.56381069e-11, 7.84982431e-13, 2.14726071e-15,\n",
      "        1.73554360e-09, 2.16396304e-10, 1.25574111e-03, 4.08817572e-15,\n",
      "        5.15870341e-21, 1.76879968e-08, 7.41082862e-10, 3.45752443e-16],\n",
      "       [2.22858873e-07, 6.51638477e-09, 4.73892698e-07, 4.38746761e-10,\n",
      "        8.79225510e-08, 8.20224173e-08, 4.39938248e-07, 9.53959443e-07,\n",
      "        1.45423282e-08, 3.37093518e-08, 1.64253436e-07, 1.63375523e-06,\n",
      "        2.23006100e-06, 1.94138163e-08, 4.81804285e-08, 6.36468656e-07,\n",
      "        9.34511320e-07, 2.52432500e-07, 1.99546402e-09, 1.34238789e-08,\n",
      "        2.63938659e-07, 3.05069534e-07, 6.66398214e-10, 1.87834175e-08,\n",
      "        7.86701015e-09, 1.63892608e-07, 8.19208367e-07, 4.79580731e-09,\n",
      "        2.96459852e-08, 1.44690731e-07, 1.70189338e-08, 4.66589931e-08,\n",
      "        5.69818539e-08, 1.95633465e-09, 1.71407805e-07, 3.59959768e-06,\n",
      "        3.61482375e-06, 3.52579804e-07, 1.32945832e-09, 2.95719484e-08,\n",
      "        6.23545970e-09, 1.41225527e-07, 1.09177471e-07, 6.85977763e-09,\n",
      "        3.43499593e-08, 7.86935025e-13, 1.71296275e-08, 1.19772896e-01,\n",
      "        6.14677587e-10, 3.82678900e-06, 4.69705075e-09, 7.96477381e-12,\n",
      "        5.73284410e-07, 2.11820733e-07, 5.92907146e-02, 3.54868440e-10,\n",
      "        1.35347005e-02, 2.56087471e-08, 1.57673862e-14, 1.92643625e-07,\n",
      "        5.25652299e-10, 1.01796180e-08, 1.45653067e-09, 4.05522854e-07,\n",
      "        8.70258191e-07, 2.12834572e-09, 4.09995149e-09, 4.65945560e-10,\n",
      "        9.95716931e-09, 5.61916513e-10, 1.14725353e-07, 3.15124140e-07,\n",
      "        5.33417904e-07, 5.40640987e-02, 2.91974750e-10, 3.62267310e-05,\n",
      "        9.38465519e-08, 2.42550001e-02, 1.02112718e-09, 5.60231854e-07,\n",
      "        3.50518925e-09, 6.33800852e-08, 5.43007722e-11, 4.40036638e-06,\n",
      "        1.55815594e-09, 8.01152644e-10, 2.76312812e-06, 9.70977254e-09,\n",
      "        4.21096012e-02, 2.51225640e-09, 5.12445837e-08, 9.37946538e-08,\n",
      "        2.83697318e-07, 2.27261282e-07, 2.92382829e-09, 1.32694220e-06,\n",
      "        4.75536069e-07, 7.36463113e-10, 1.33374130e-08, 9.97744724e-02,\n",
      "        1.43966594e-09, 1.39261491e-09, 1.82808282e-10, 6.07708500e-07,\n",
      "        2.82314261e-08, 6.40332246e-07, 2.60454893e-08, 5.29435350e-11,\n",
      "        1.02132391e-09, 3.08750820e-08, 2.57791072e-07, 4.59740197e-11,\n",
      "        8.94556251e-08, 1.05921224e-07, 5.16334708e-09, 1.10272479e-10,\n",
      "        2.71584668e-06, 3.53057388e-08, 2.22483294e-08, 1.39351091e-08,\n",
      "        6.41057518e-09, 1.98097240e-07, 1.84174655e-06, 3.25721539e-09,\n",
      "        3.68534131e-07, 2.42469952e-07, 1.34248781e-08, 5.28724176e-10,\n",
      "        1.91031191e-10, 1.04111619e-09, 2.98649543e-11, 1.25666588e-07,\n",
      "        4.21421362e-07, 5.55775614e-07, 1.21656999e-01, 1.02212255e-06,\n",
      "        2.14278950e-09, 5.71773792e-12, 2.32024149e-06, 2.26958718e-09,\n",
      "        9.77488980e-02, 1.44405107e-07, 3.20534582e-06, 5.59344357e-08,\n",
      "        8.75760620e-09, 1.31652855e-09, 2.49091903e-09, 1.82815362e-02,\n",
      "        4.51784210e-09, 1.03202062e-07, 7.41202896e-03, 6.01330541e-09,\n",
      "        2.33391546e-07, 9.69440521e-07, 1.54783608e-09, 2.51256473e-08,\n",
      "        1.00268369e-06, 1.70807391e-06, 7.02813807e-08, 2.46324959e-07,\n",
      "        1.66738161e-08, 1.46508398e-06, 1.45729837e-08, 1.65789249e-09,\n",
      "        8.63818045e-12, 6.85814641e-08, 4.84969009e-10, 6.45457519e-08,\n",
      "        3.29564322e-08, 1.36129774e-08, 3.04961681e-01, 1.44959017e-06,\n",
      "        8.16618240e-08, 1.30745107e-07, 2.20273293e-08, 4.35667197e-10,\n",
      "        2.55549288e-08, 2.11918283e-09, 2.32358892e-02, 1.38015812e-02,\n",
      "        5.58699220e-08, 3.21959455e-08, 4.30047820e-08, 1.72536568e-06,\n",
      "        5.45628964e-08, 5.84207394e-09, 1.88895495e-08, 1.46012169e-09,\n",
      "        3.26762595e-09, 2.61479762e-08, 4.32869018e-11, 2.66841624e-07,\n",
      "        5.21225507e-10, 1.48184495e-06, 1.58606674e-08, 1.36286565e-10,\n",
      "        1.18620029e-07, 8.18644874e-10, 7.39156625e-10, 1.13584926e-10,\n",
      "        4.48450695e-12, 9.95925280e-14, 3.82348190e-07, 4.75020197e-11,\n",
      "        1.84021933e-13, 7.06218450e-13, 7.55783390e-07, 5.29126135e-12]],\n",
      "      dtype=float32), array([[1.0334193 ],\n",
      "       [0.99125254]], dtype=float32)]\n",
      "X=[1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0], Predicted=[array([[5.70478588e-02, 5.26386521e-06, 5.70494194e-05, 6.75737692e-06,\n",
      "        4.76180048e-06, 2.02698211e-05, 9.97463940e-06, 1.86709058e-05,\n",
      "        1.23359378e-05, 1.09413513e-07, 6.38617128e-02, 9.86003506e-05,\n",
      "        1.04538103e-05, 9.62647118e-06, 7.59488195e-02, 4.48478795e-06,\n",
      "        1.61864245e-05, 1.77837883e-05, 2.20373349e-05, 6.13500401e-02,\n",
      "        3.51055060e-05, 5.20499589e-06, 6.62095499e-06, 6.50533438e-02,\n",
      "        7.61348019e-06, 9.77831769e-06, 4.85397317e-02, 3.05691063e-02,\n",
      "        6.00300382e-06, 1.47776930e-07, 9.15901546e-06, 1.08752940e-02,\n",
      "        3.28336284e-02, 2.11247811e-06, 6.42285443e-07, 2.61885798e-05,\n",
      "        5.83753317e-05, 6.29496753e-07, 1.15542480e-06, 2.72099015e-07,\n",
      "        6.36914119e-05, 5.17936132e-06, 1.71503143e-06, 5.79883408e-06,\n",
      "        1.12825446e-05, 6.76300488e-06, 4.30094588e-07, 3.72506497e-06,\n",
      "        6.34290927e-06, 2.95933820e-02, 4.16189687e-06, 8.17621731e-06,\n",
      "        3.92191614e-05, 7.92608989e-06, 1.16978072e-06, 1.24609699e-06,\n",
      "        3.15365537e-06, 1.13379629e-05, 1.52852738e-06, 3.13882301e-05,\n",
      "        7.53789573e-06, 1.24237058e-05, 7.00277496e-07, 4.21041750e-06,\n",
      "        2.84567031e-05, 4.77153361e-02, 1.60364687e-06, 3.05554931e-06,\n",
      "        6.37820040e-06, 2.34017719e-07, 4.66055656e-03, 3.67689108e-06,\n",
      "        4.87317517e-02, 2.93006724e-06, 1.36617255e-05, 6.48426112e-06,\n",
      "        1.90238752e-05, 1.96514975e-06, 2.58478917e-06, 1.46079458e-06,\n",
      "        5.76073489e-06, 2.49404875e-05, 5.33055800e-06, 2.93866105e-06,\n",
      "        1.78079699e-05, 8.32779097e-06, 4.23255656e-03, 5.44158866e-07,\n",
      "        1.29294313e-05, 1.58467969e-06, 4.26476799e-05, 8.33619106e-06,\n",
      "        7.95234996e-07, 2.00783124e-05, 1.29850132e-05, 1.14935783e-05,\n",
      "        2.98085939e-02, 2.12987379e-05, 5.31617900e-07, 3.37161214e-06,\n",
      "        6.45033879e-06, 9.25959796e-07, 3.97036274e-06, 6.84859187e-05,\n",
      "        3.38183008e-06, 7.85804540e-03, 3.67540991e-07, 4.46160675e-06,\n",
      "        1.99978126e-06, 3.92858510e-06, 5.90776093e-03, 1.67182916e-05,\n",
      "        2.30722539e-02, 6.65831976e-06, 1.93641409e-02, 1.08956092e-05,\n",
      "        5.21372976e-06, 1.14222459e-07, 4.03441451e-02, 8.29921305e-07,\n",
      "        3.21239327e-07, 9.34813488e-06, 5.14014846e-06, 2.19517210e-06,\n",
      "        3.57467093e-06, 4.85544263e-07, 3.27489005e-07, 1.19895949e-05,\n",
      "        2.33886223e-02, 1.66697500e-05, 3.73345824e-06, 1.25613347e-01,\n",
      "        1.61662465e-05, 9.57275275e-03, 4.17498359e-06, 3.26312183e-05,\n",
      "        9.37693949e-06, 2.68727973e-07, 1.10551755e-05, 6.67073550e-07,\n",
      "        4.85940109e-06, 5.85841599e-06, 2.60124542e-02, 4.04289904e-06,\n",
      "        5.64111324e-05, 9.92417972e-06, 6.12273925e-06, 2.11649578e-07,\n",
      "        4.93437710e-06, 1.29136715e-05, 8.48812221e-08, 1.34638367e-06,\n",
      "        1.14970644e-05, 3.98449041e-02, 2.24236078e-06, 1.95445159e-06,\n",
      "        1.65939866e-06, 5.36427990e-07, 2.98910891e-06, 7.27394409e-03,\n",
      "        2.19716617e-06, 1.54496638e-06, 2.29835081e-07, 1.49682528e-05,\n",
      "        6.10301777e-06, 4.26555334e-06, 9.66727734e-03, 2.21736882e-05,\n",
      "        9.89720888e-07, 1.40336203e-06, 8.44591614e-06, 2.22730232e-05,\n",
      "        2.52901668e-06, 5.13750228e-06, 3.83822726e-06, 2.07501034e-06,\n",
      "        1.56949498e-02, 6.68587154e-06, 7.00739804e-07, 9.98617367e-08,\n",
      "        7.66495418e-07, 7.46359945e-07, 4.80829203e-06, 2.92248096e-05,\n",
      "        8.39644508e-06, 3.24752295e-06, 1.39185033e-06, 9.94206403e-06,\n",
      "        1.84598065e-07, 2.08938582e-05, 9.08684706e-06, 1.37026655e-02,\n",
      "        1.13907276e-06, 2.51544316e-06, 8.77809612e-07, 2.14554007e-06,\n",
      "        6.94518150e-08, 4.52842824e-06, 2.24713904e-06, 9.81449193e-06,\n",
      "        4.37621726e-03, 5.77536980e-07, 2.47423509e-06, 1.58544835e-02,\n",
      "        4.99742914e-10, 6.96160441e-07, 3.00983334e-06, 1.04871862e-08]],\n",
      "      dtype=float32), array([[0.97534174]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "Y_test = model.predict(X_test[30:32])\n",
    "Y_test1 = model.predict(X[0:1])\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (X_test[30:32],  Y_test ))\n",
    "print(\"X=%s, Predicted=%s\" % (X[0],  Y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['화성시' '영암군' '곡성군' '달성군' '고흥군' '영천시' '아산시' '서천군' '평창군' '음성군' '성남시' '서산시'\n",
      " '서구' '영등포구' '용인시' '광양시' '광산구' '중구' '원주시' '고양시' '논산시' '동구' '고성군' '안산시'\n",
      " '목포시' '강서구' '시흥시' '이천시' '사상구' '광진구' '서대문구' '양평군' '남양주시' '동작구' '기장군' '예산군'\n",
      " '남구' '여수시' '제천시' '세종' '춘천시' '의성군' '충주시' '서초구' '금산군' '밀양시' '김천시' '군산시'\n",
      " '대덕구' '파주시' '진주시' '김해시' '북구' '나주시' '고창군' '합천군' '무주군' '계양구' '함양군' '안동시'\n",
      " '인제군' '사하구' '철원군' '강동구' '홍성군' '안양시' '정선군' '용산구' '구미시' '부산진구' '광명시' '송파구'\n",
      " '평택시' '남원시' '함안군' '서귀포시' '경산시' '정읍시' '청주시' '상주시' '삼척시' '강릉시' '양산시' '제주시'\n",
      " '달서구' '영덕군' '여주시' '장성군' '전주시' '청도군' '포항시' '마포구' '영광군' '영주시' '도봉구' '당진시'\n",
      " '부천시' '수성구' '봉화군' '익산시' '구로구' '유성구' '금천구' '천안시' '진도군' '가평군' '강화군' '거창군'\n",
      " '군위군' '부평구' '양주시' '사천시' '의정부시' '영동군' '광주시' '창원시(통합)' '울주군' '진천군' '김포시'\n",
      " '동래구' '강남구' '보령시' '강진군' '보성군' '화순군' '순천시' '보은군' '양양군' '군포시' '청송군' '통영시'\n",
      " '수원시' '경주시' '하남시' '완주군' '양천구' '함평군' '의령군' '공주시' '성북구' '부안군' '예천군' '안성시'\n",
      " '중랑구' '칠곡군' '영월군' '수영구' '순창군' '거제시' '성주군' '장수군' '문경시' '은평구' '포천시' '울진군'\n",
      " '무안군' '해남군' '담양군' '양구군' '연천군' '횡성군' '장흥군' '태백시' '홍천군' '하동군' '남동구' '의왕시'\n",
      " '속초시' '부여군' '성동구' '김제시' '강북구' '청양군' '신안군' '해운대구' '종로구' '동두천시' '연제구' '진안군'\n",
      " '임실군' '노원구' '증평군' '단양군' '태안군' '고령군' '동해시' '연수구' '관악구' '옥천군' '동대문구' '영양군'\n",
      " '오산시' '금정구' '구례군' '괴산군' '계룡시' '완도군' '창녕군' '화천군' '남해군' '구리시' '산청군' '옹진군'\n",
      " '과천시' '울릉군' '영도구' '청원군' '연기군']\n",
      "208\n"
     ]
    }
   ],
   "source": [
    "print(all_data['발생지시군구'].unique())\n",
    "print(len(all_data['발생지시군구'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = []\n",
    "label_name.extend(all_data['발생지시군구'].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.06447817e-10, 3.77568282e-15, 1.18520960e-09, 1.15495769e-09,\n",
       "       2.29895074e-12, 1.79602719e-12, 1.50841018e-07, 1.76865473e-08,\n",
       "       4.33623982e-14, 8.63113192e-10, 1.54300697e-08, 6.40886566e-10,\n",
       "       5.41995883e-01, 2.49401246e-08, 5.64827699e-11, 3.30352201e-14,\n",
       "       3.05099491e-07, 4.58504027e-03, 8.35439692e-15, 4.31152392e-10,\n",
       "       1.08171800e-08, 9.18508624e-04, 6.01031757e-13, 2.04222111e-10,\n",
       "       2.31254881e-12, 9.91041361e-06, 6.28813841e-12, 3.95165733e-10,\n",
       "       2.64920743e-08, 1.82250035e-10, 2.18791416e-10, 1.01592068e-11,\n",
       "       2.27236452e-10, 6.79299106e-09, 6.73513512e-07, 1.70180485e-07,\n",
       "       1.87787488e-02, 4.81064188e-10, 1.73111753e-12, 1.18970372e-12,\n",
       "       1.62820349e-14, 5.31010479e-11, 3.99113520e-11, 2.28036982e-11,\n",
       "       1.64215235e-05, 1.28656591e-11, 2.95440790e-11, 7.85392817e-09,\n",
       "       3.80131655e-06, 4.88441093e-11, 3.08278680e-11, 1.05511572e-11,\n",
       "       2.14079705e-06, 1.43833542e-10, 8.06755764e-08, 1.09915813e-10,\n",
       "       1.76838330e-06, 3.56766805e-02, 2.22281896e-13, 3.39726619e-12,\n",
       "       1.63663759e-15, 6.23239828e-07, 4.37642113e-18, 2.14678622e-11,\n",
       "       2.61767946e-06, 4.80873341e-10, 1.14751026e-15, 2.00504591e-09,\n",
       "       2.66173497e-14, 2.89642267e-05, 8.21837239e-06, 1.71431100e-08,\n",
       "       9.59293547e-11, 1.77881238e-10, 2.00403252e-13, 1.58283147e-08,\n",
       "       1.97641773e-12, 1.79018397e-10, 2.51963339e-10, 4.35086456e-13,\n",
       "       1.24213641e-13, 6.35689282e-14, 7.32731844e-12, 9.07490289e-07,\n",
       "       6.24176089e-09, 7.87957460e-12, 6.56501817e-13, 1.17886956e-13,\n",
       "       7.69902755e-08, 5.71131751e-14, 1.77233315e-11, 2.68240807e-09,\n",
       "       2.24063643e-10, 5.47119919e-11, 4.27746771e-09, 8.91072546e-07,\n",
       "       4.65539135e-10, 9.36627109e-10, 7.41273633e-14, 7.27989686e-07,\n",
       "       3.70189462e-10, 2.13125554e-06, 5.47634937e-10, 9.64899755e-07,\n",
       "       3.86874473e-12, 1.21902349e-11, 1.49420083e-01, 2.07410417e-14,\n",
       "       2.18890336e-10, 8.05767812e-03, 3.06882164e-09, 4.05984374e-15,\n",
       "       1.11691945e-09, 2.53357370e-11, 9.63428892e-10, 5.07377473e-11,\n",
       "       2.20798213e-10, 2.46412668e-10, 5.84934011e-12, 1.73562075e-04,\n",
       "       1.09538045e-10, 4.35552778e-07, 2.26356245e-09, 8.26585814e-11,\n",
       "       3.00676855e-13, 2.85578311e-10, 1.28296798e-12, 5.38509429e-14,\n",
       "       1.52516944e-09, 3.00125902e-15, 2.08120576e-10, 6.57502525e-11,\n",
       "       3.71872845e-11, 1.08803079e-07, 6.99212066e-09, 4.79037865e-10,\n",
       "       7.28273846e-14, 2.28758068e-10, 3.48763365e-07, 1.01440178e-09,\n",
       "       7.51125384e-08, 4.17750556e-12, 1.57429256e-12, 3.57127328e-09,\n",
       "       4.17923041e-14, 2.07699133e-13, 1.07943393e-07, 6.41993847e-10,\n",
       "       2.49133325e-10, 6.07617906e-13, 1.77339382e-12, 8.58711539e-12,\n",
       "       1.59266483e-06, 1.35061060e-11, 8.62740712e-11, 8.17158841e-10,\n",
       "       2.64712124e-12, 1.23048327e-12, 6.34541072e-21, 1.06774604e-12,\n",
       "       1.72100584e-17, 1.17053436e-10, 6.15327296e-16, 5.34244525e-17,\n",
       "       1.85959026e-11, 2.31525183e-01, 6.81381357e-14, 6.88330271e-15,\n",
       "       4.70728173e-06, 4.52388821e-10, 4.85862905e-10, 5.99080638e-12,\n",
       "       7.45802264e-09, 7.46466352e-14, 5.01404475e-06, 2.34909980e-09,\n",
       "       3.49299922e-09, 9.23493957e-08, 3.08082974e-07, 1.99470401e-06,\n",
       "       2.21764953e-08, 1.26782684e-09, 9.04974570e-07, 1.01547482e-08,\n",
       "       5.63119701e-14, 8.16318990e-14, 7.51096103e-03, 2.24516477e-12,\n",
       "       1.17373480e-08, 1.01402602e-10, 3.87037485e-20, 3.60185991e-12,\n",
       "       4.47594084e-06, 9.85757674e-16, 4.29840018e-11, 2.77098761e-11,\n",
       "       1.38557041e-10, 7.56381069e-11, 7.84982431e-13, 2.14726071e-15,\n",
       "       1.73554360e-09, 2.16396304e-10, 1.25574111e-03, 4.08817572e-15,\n",
       "       5.15870341e-21, 1.76879968e-08, 7.41082862e-10, 3.45752443e-16],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "군산시 0.119773\n",
      "완주군 0.121657\n",
      "김제시 0.304962\n"
     ]
    }
   ],
   "source": [
    "for i, x in zip(label_name, Y_test[0][1]):\n",
    "    if x>0.1:\n",
    "        print(i,'%f'%(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 10\n",
    "'중상자수', '경상자수', '발생지시군구'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = []\n",
    "for col in ['발생지시군구']:\n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_num = x_train_num[['중상자수', '경상자수']].values\n",
    "Y_cat = x_train_cat[col_name].values\n",
    "X1 = x_train_cat.drop(columns=col_name)\n",
    "X2 = x_train_num.drop(columns=['중상자수', '경상자수'])\n",
    "X = pd.concat([X1, X2], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 123)\n",
      "208\n",
      "주야_야간\n",
      "주야_주간\n",
      "요일_금\n",
      "요일_월\n",
      "요일_일\n",
      "요일_목\n",
      "요일_수\n",
      "요일_화\n",
      "요일_토\n",
      "발생지시도_경기\n",
      "발생지시도_전남\n",
      "발생지시도_대구\n",
      "발생지시도_경북\n",
      "발생지시도_충남\n",
      "발생지시도_강원\n",
      "발생지시도_충북\n",
      "발생지시도_서울\n",
      "발생지시도_광주\n",
      "발생지시도_부산\n",
      "발생지시도_경남\n",
      "발생지시도_인천\n",
      "발생지시도_세종\n",
      "발생지시도_전북\n",
      "발생지시도_대전\n",
      "발생지시도_울산\n",
      "발생지시도_제주\n",
      "사고유형_대분류_차대차\n",
      "사고유형_대분류_차대사람\n",
      "사고유형_대분류_차량단독\n",
      "사고유형_대분류_건널목\n",
      "사고유형_중분류_측면충돌\n",
      "사고유형_중분류_차도통행중\n",
      "사고유형_중분류_전도전복\n",
      "사고유형_중분류_정면충돌\n",
      "사고유형_중분류_추돌\n",
      "사고유형_중분류_횡단중\n",
      "사고유형_중분류_기타\n",
      "사고유형_중분류_전도\n",
      "사고유형_중분류_도로이탈\n",
      "사고유형_중분류_길가장자리구역통행중\n",
      "사고유형_중분류_공작물충돌\n",
      "사고유형_중분류_전복\n",
      "사고유형_중분류_보도통행중\n",
      "사고유형_중분류_후진중충돌\n",
      "사고유형_중분류_주/정차차량 충돌\n",
      "사고유형_중분류_측면직각충돌\n",
      "사고유형_중분류_차단기돌파\n",
      "사고유형_중분류_직전진행\n",
      "사고유형_중분류_경보기무시\n",
      "법규위반_중앙선 침범\n",
      "법규위반_과속\n",
      "법규위반_안전운전 의무 불이행\n",
      "법규위반_안전거리 미확보\n",
      "법규위반_기타(운전자법규위반)\n",
      "법규위반_신호위반\n",
      "법규위반_직진 및 우회전차의 통행방해\n",
      "법규위반_교차로 통행방법 위반\n",
      "법규위반_보행자 보호의무 위반\n",
      "법규위반_부당한 회전\n",
      "법규위반_차로위반(진로변경 위반)\n",
      "법규위반_앞지르기 금지위반\n",
      "법규위반_앞지르기 방법위반\n",
      "법규위반_정비불량 제차의 운전금지위반\n",
      "법규위반_서행 및 일시정지위반\n",
      "법규위반_과로\n",
      "법규위반_철길건널목 통과방법위반\n",
      "법규위반_진로양보 의무 불이행\n",
      "법규위반_보행자과실\n",
      "법규위반_통행우선 순위위반\n",
      "도로형태_대분류_단일로\n",
      "도로형태_대분류_교차로\n",
      "도로형태_대분류_기타\n",
      "도로형태_대분류_주차장\n",
      "도로형태_대분류_불명\n",
      "도로형태_대분류_기타/불명\n",
      "도로형태_대분류_고가도로위\n",
      "도로형태_대분류_지하도로내\n",
      "도로형태_대분류_건널목\n",
      "도로형태_기타단일로\n",
      "도로형태_교차로내\n",
      "도로형태_교차로부근\n",
      "도로형태_교량위\n",
      "도로형태_고가도로위\n",
      "도로형태_교차로횡단보도내\n",
      "도로형태_기타\n",
      "도로형태_지하차도(도로)내\n",
      "도로형태_주차장\n",
      "도로형태_터널안\n",
      "도로형태_불명\n",
      "도로형태_횡단보도상\n",
      "도로형태_횡단보도부근\n",
      "도로형태_기타/불명\n",
      "도로형태_지하도로내\n",
      "도로형태_건널목\n",
      "당사자종별_1당_대분류_승용차\n",
      "당사자종별_1당_대분류_자전거\n",
      "당사자종별_1당_대분류_화물차\n",
      "당사자종별_1당_대분류_승합차\n",
      "당사자종별_1당_대분류_건설기계\n",
      "당사자종별_1당_대분류_이륜차\n",
      "당사자종별_1당_대분류_특수차\n",
      "당사자종별_1당_대분류_원동기장치자전거\n",
      "당사자종별_1당_대분류_사륜오토바이(ATV)\n",
      "당사자종별_1당_대분류_농기계\n",
      "당사자종별_1당_대분류_개인형이동수단(PM)\n",
      "당사자종별_1당_대분류_불명\n",
      "당사자종별_2당_대분류_승합차\n",
      "당사자종별_2당_대분류_보행자\n",
      "당사자종별_2당_대분류_없음\n",
      "당사자종별_2당_대분류_화물차\n",
      "당사자종별_2당_대분류_특수차\n",
      "당사자종별_2당_대분류_승용차\n",
      "당사자종별_2당_대분류_이륜차\n",
      "당사자종별_2당_대분류_농기계\n",
      "당사자종별_2당_대분류_원동기장치자전거\n",
      "당사자종별_2당_대분류_자전거\n",
      "당사자종별_2당_대분류_사륜오토바이(ATV)\n",
      "당사자종별_2당_대분류_건설기계\n",
      "당사자종별_2당_대분류_불명\n",
      "당사자종별_2당_대분류_열차\n",
      "사망자수\n",
      "사상자수\n",
      "부상신고자수\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(len(col_name))\n",
    "for name in pd.concat([X1, X2], axis=1).columns:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1 = x_test_cat.drop(columns=col_name)\n",
    "X_test2 = x_test_num.drop(columns=['중상자수', '경상자수'])\n",
    "X_test = pd.concat([X_test1, X_test2],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "x = Dense(512, activation='relu', kernel_initializer='glorot_normal')(cat_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu', kernel_initializer='glorot_normal')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu', kernel_initializer='glorot_normal')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "cat_output = Dense(len(Y_cat[0]), activation='softmax', name='cat_output')(x)\n",
    "num_output = Dense(len(Y_num.shape), name='num_output')(x)\n",
    "\n",
    "model = Model(inputs=cat_input, outputs=[cat_output, num_output])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'cat_output': 'categorical_crossentropy', 'num_output': 'mse'},\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 2.9848 - cat_output_loss: 2.5533 - num_output_loss: 0.4315 - cat_output_acc: 0.1991 - num_output_acc: 0.5255 - val_loss: 3.1105 - val_cat_output_loss: 2.7127 - val_num_output_loss: 0.3977 - val_cat_output_acc: 0.1605 - val_num_output_acc: 0.5909\n",
      "Epoch 2/100\n",
      " 4224/20029 [=====>........................] - ETA: 0s - loss: 2.8505 - cat_output_loss: 2.5095 - num_output_loss: 0.3410 - cat_output_acc: 0.2102 - num_output_acc: 0.5933"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:1043: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,cat_output_acc,cat_output_loss,num_output_acc,val_num_output_acc,val_loss,val_cat_output_acc,val_num_output_loss,num_output_loss,val_cat_output_loss,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20029/20029 [==============================] - 1s 41us/step - loss: 2.9264 - cat_output_loss: 2.5267 - num_output_loss: 0.3996 - cat_output_acc: 0.2088 - num_output_acc: 0.5815 - val_loss: 3.1991 - val_cat_output_loss: 2.7203 - val_num_output_loss: 0.4787 - val_cat_output_acc: 0.1562 - val_num_output_acc: 0.2250\n",
      "Epoch 3/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 2.8954 - cat_output_loss: 2.5174 - num_output_loss: 0.3781 - cat_output_acc: 0.2092 - num_output_acc: 0.5530 - val_loss: 3.1135 - val_cat_output_loss: 2.7163 - val_num_output_loss: 0.3972 - val_cat_output_acc: 0.1607 - val_num_output_acc: 0.7827\n",
      "Epoch 4/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.8670 - cat_output_loss: 2.4993 - num_output_loss: 0.3677 - cat_output_acc: 0.2130 - num_output_acc: 0.5336 - val_loss: 3.2465 - val_cat_output_loss: 2.7346 - val_num_output_loss: 0.5119 - val_cat_output_acc: 0.1601 - val_num_output_acc: 0.8682\n",
      "Epoch 5/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 2.9202 - cat_output_loss: 2.4892 - num_output_loss: 0.4310 - cat_output_acc: 0.2198 - num_output_acc: 0.5670 - val_loss: 3.1774 - val_cat_output_loss: 2.7161 - val_num_output_loss: 0.4613 - val_cat_output_acc: 0.1581 - val_num_output_acc: 0.8812\n",
      "Epoch 6/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.9111 - cat_output_loss: 2.4702 - num_output_loss: 0.4409 - cat_output_acc: 0.2269 - num_output_acc: 0.5328 - val_loss: 3.1984 - val_cat_output_loss: 2.7460 - val_num_output_loss: 0.4524 - val_cat_output_acc: 0.1518 - val_num_output_acc: 0.8946\n",
      "Epoch 7/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 2.8371 - cat_output_loss: 2.4521 - num_output_loss: 0.3850 - cat_output_acc: 0.2283 - num_output_acc: 0.5454 - val_loss: 3.1412 - val_cat_output_loss: 2.7478 - val_num_output_loss: 0.3934 - val_cat_output_acc: 0.1542 - val_num_output_acc: 0.5246\n",
      "Epoch 8/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 2.8516 - cat_output_loss: 2.4403 - num_output_loss: 0.4113 - cat_output_acc: 0.2344 - num_output_acc: 0.5473 - val_loss: 3.1203 - val_cat_output_loss: 2.7572 - val_num_output_loss: 0.3632 - val_cat_output_acc: 0.1508 - val_num_output_acc: 0.5565\n",
      "Epoch 9/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.8281 - cat_output_loss: 2.4268 - num_output_loss: 0.4013 - cat_output_acc: 0.2373 - num_output_acc: 0.5745 - val_loss: 3.1973 - val_cat_output_loss: 2.7524 - val_num_output_loss: 0.4449 - val_cat_output_acc: 0.1562 - val_num_output_acc: 0.5695\n",
      "Epoch 10/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 2.7738 - cat_output_loss: 2.4069 - num_output_loss: 0.3668 - cat_output_acc: 0.2426 - num_output_acc: 0.5322 - val_loss: 3.1735 - val_cat_output_loss: 2.7568 - val_num_output_loss: 0.4167 - val_cat_output_acc: 0.1516 - val_num_output_acc: 0.7238\n",
      "Epoch 11/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.7013 - cat_output_loss: 2.3890 - num_output_loss: 0.3123 - cat_output_acc: 0.2425 - num_output_acc: 0.5456 - val_loss: 3.1643 - val_cat_output_loss: 2.7660 - val_num_output_loss: 0.3984 - val_cat_output_acc: 0.1591 - val_num_output_acc: 0.2800\n",
      "Epoch 12/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.7279 - cat_output_loss: 2.3779 - num_output_loss: 0.3500 - cat_output_acc: 0.2474 - num_output_acc: 0.5375 - val_loss: 3.1714 - val_cat_output_loss: 2.7730 - val_num_output_loss: 0.3985 - val_cat_output_acc: 0.1494 - val_num_output_acc: 0.8031\n",
      "Epoch 13/100\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 2.6687 - cat_output_loss: 2.3579 - num_output_loss: 0.3109 - cat_output_acc: 0.2550 - num_output_acc: 0.5436 - val_loss: 3.1737 - val_cat_output_loss: 2.7794 - val_num_output_loss: 0.3942 - val_cat_output_acc: 0.1508 - val_num_output_acc: 0.2212\n",
      "Epoch 14/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 2.7350 - cat_output_loss: 2.3449 - num_output_loss: 0.3900 - cat_output_acc: 0.2577 - num_output_acc: 0.5477 - val_loss: 3.2015 - val_cat_output_loss: 2.7958 - val_num_output_loss: 0.4058 - val_cat_output_acc: 0.1496 - val_num_output_acc: 0.6340\n",
      "Epoch 15/100\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 2.6348 - cat_output_loss: 2.3186 - num_output_loss: 0.3162 - cat_output_acc: 0.2654 - num_output_acc: 0.5280 - val_loss: 3.2837 - val_cat_output_loss: 2.8001 - val_num_output_loss: 0.4836 - val_cat_output_acc: 0.1476 - val_num_output_acc: 0.7899\n",
      "Epoch 16/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 2.5678 - cat_output_loss: 2.3056 - num_output_loss: 0.2622 - cat_output_acc: 0.2743 - num_output_acc: 0.5279 - val_loss: 3.3838 - val_cat_output_loss: 2.8145 - val_num_output_loss: 0.5693 - val_cat_output_acc: 0.1502 - val_num_output_acc: 0.3722\n",
      "Epoch 17/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 2.5376 - cat_output_loss: 2.2848 - num_output_loss: 0.2528 - cat_output_acc: 0.2760 - num_output_acc: 0.5576 - val_loss: 3.2119 - val_cat_output_loss: 2.8247 - val_num_output_loss: 0.3872 - val_cat_output_acc: 0.1486 - val_num_output_acc: 0.3914\n",
      "Epoch 18/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 2.6468 - cat_output_loss: 2.2793 - num_output_loss: 0.3675 - cat_output_acc: 0.2800 - num_output_acc: 0.5394 - val_loss: 3.2079 - val_cat_output_loss: 2.8372 - val_num_output_loss: 0.3706 - val_cat_output_acc: 0.1478 - val_num_output_acc: 0.8431\n",
      "Epoch 19/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 2.5309 - cat_output_loss: 2.2505 - num_output_loss: 0.2804 - cat_output_acc: 0.2881 - num_output_acc: 0.5504 - val_loss: 3.2968 - val_cat_output_loss: 2.8552 - val_num_output_loss: 0.4416 - val_cat_output_acc: 0.1470 - val_num_output_acc: 0.8804\n",
      "Epoch 20/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.5253 - cat_output_loss: 2.2279 - num_output_loss: 0.2975 - cat_output_acc: 0.2938 - num_output_acc: 0.5647 - val_loss: 3.3600 - val_cat_output_loss: 2.8601 - val_num_output_loss: 0.4999 - val_cat_output_acc: 0.1482 - val_num_output_acc: 0.5769\n",
      "Epoch 21/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 2.5259 - cat_output_loss: 2.2205 - num_output_loss: 0.3054 - cat_output_acc: 0.2973 - num_output_acc: 0.5613 - val_loss: 3.3065 - val_cat_output_loss: 2.8832 - val_num_output_loss: 0.4234 - val_cat_output_acc: 0.1444 - val_num_output_acc: 0.7230\n",
      "Epoch 22/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 2.4405 - cat_output_loss: 2.2006 - num_output_loss: 0.2399 - cat_output_acc: 0.3003 - num_output_acc: 0.5367 - val_loss: 3.3086 - val_cat_output_loss: 2.9029 - val_num_output_loss: 0.4058 - val_cat_output_acc: 0.1436 - val_num_output_acc: 0.1761\n",
      "Epoch 23/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 2.4493 - cat_output_loss: 2.1885 - num_output_loss: 0.2608 - cat_output_acc: 0.2995 - num_output_acc: 0.5706 - val_loss: 3.2956 - val_cat_output_loss: 2.8860 - val_num_output_loss: 0.4096 - val_cat_output_acc: 0.1426 - val_num_output_acc: 0.6314\n",
      "Epoch 24/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.3994 - cat_output_loss: 2.1621 - num_output_loss: 0.2373 - cat_output_acc: 0.3083 - num_output_acc: 0.5541 - val_loss: 3.3314 - val_cat_output_loss: 2.9235 - val_num_output_loss: 0.4079 - val_cat_output_acc: 0.1448 - val_num_output_acc: 0.6198\n",
      "Epoch 25/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 2.3616 - cat_output_loss: 2.1447 - num_output_loss: 0.2168 - cat_output_acc: 0.3125 - num_output_acc: 0.5388 - val_loss: 3.3298 - val_cat_output_loss: 2.9196 - val_num_output_loss: 0.4101 - val_cat_output_acc: 0.1410 - val_num_output_acc: 0.3504\n",
      "Epoch 26/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.3362 - cat_output_loss: 2.1267 - num_output_loss: 0.2094 - cat_output_acc: 0.3217 - num_output_acc: 0.5450 - val_loss: 3.4081 - val_cat_output_loss: 2.9519 - val_num_output_loss: 0.4563 - val_cat_output_acc: 0.1482 - val_num_output_acc: 0.8676\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.3953 - cat_output_loss: 2.1169 - num_output_loss: 0.2785 - cat_output_acc: 0.3252 - num_output_acc: 0.5318 - val_loss: 3.4018 - val_cat_output_loss: 2.9668 - val_num_output_loss: 0.4350 - val_cat_output_acc: 0.1404 - val_num_output_acc: 0.8279\n",
      "Epoch 28/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 2.3690 - cat_output_loss: 2.1003 - num_output_loss: 0.2687 - cat_output_acc: 0.3273 - num_output_acc: 0.5930 - val_loss: 3.3679 - val_cat_output_loss: 2.9585 - val_num_output_loss: 0.4095 - val_cat_output_acc: 0.1462 - val_num_output_acc: 0.4982\n",
      "Epoch 29/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.3152 - cat_output_loss: 2.0851 - num_output_loss: 0.2301 - cat_output_acc: 0.3337 - num_output_acc: 0.5533 - val_loss: 3.4328 - val_cat_output_loss: 2.9682 - val_num_output_loss: 0.4645 - val_cat_output_acc: 0.1376 - val_num_output_acc: 0.1791\n",
      "Epoch 30/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.3120 - cat_output_loss: 2.0691 - num_output_loss: 0.2429 - cat_output_acc: 0.3367 - num_output_acc: 0.5370 - val_loss: 3.4049 - val_cat_output_loss: 2.9954 - val_num_output_loss: 0.4096 - val_cat_output_acc: 0.1368 - val_num_output_acc: 0.6452\n",
      "Epoch 31/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.2940 - cat_output_loss: 2.0522 - num_output_loss: 0.2418 - cat_output_acc: 0.3439 - num_output_acc: 0.5642 - val_loss: 3.4172 - val_cat_output_loss: 2.9917 - val_num_output_loss: 0.4255 - val_cat_output_acc: 0.1314 - val_num_output_acc: 0.4485\n",
      "Epoch 32/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 2.2775 - cat_output_loss: 2.0390 - num_output_loss: 0.2384 - cat_output_acc: 0.3469 - num_output_acc: 0.5734 - val_loss: 3.4036 - val_cat_output_loss: 3.0082 - val_num_output_loss: 0.3955 - val_cat_output_acc: 0.1388 - val_num_output_acc: 0.6697\n",
      "Epoch 33/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 2.2416 - cat_output_loss: 2.0203 - num_output_loss: 0.2213 - cat_output_acc: 0.3521 - num_output_acc: 0.5423 - val_loss: 3.4828 - val_cat_output_loss: 3.0268 - val_num_output_loss: 0.4560 - val_cat_output_acc: 0.1356 - val_num_output_acc: 0.3163\n",
      "Epoch 34/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.2772 - cat_output_loss: 2.0130 - num_output_loss: 0.2642 - cat_output_acc: 0.3523 - num_output_acc: 0.5579 - val_loss: 3.4553 - val_cat_output_loss: 3.0403 - val_num_output_loss: 0.4149 - val_cat_output_acc: 0.1368 - val_num_output_acc: 0.5781\n",
      "Epoch 35/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.2770 - cat_output_loss: 2.0027 - num_output_loss: 0.2743 - cat_output_acc: 0.3541 - num_output_acc: 0.5343 - val_loss: 3.5042 - val_cat_output_loss: 3.0423 - val_num_output_loss: 0.4619 - val_cat_output_acc: 0.1366 - val_num_output_acc: 0.4633\n",
      "Epoch 36/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.2004 - cat_output_loss: 1.9778 - num_output_loss: 0.2226 - cat_output_acc: 0.3619 - num_output_acc: 0.5366 - val_loss: 3.5308 - val_cat_output_loss: 3.0563 - val_num_output_loss: 0.4745 - val_cat_output_acc: 0.1394 - val_num_output_acc: 0.5543\n",
      "Epoch 37/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 2.2106 - cat_output_loss: 1.9679 - num_output_loss: 0.2427 - cat_output_acc: 0.3660 - num_output_acc: 0.5421 - val_loss: 3.6190 - val_cat_output_loss: 3.0703 - val_num_output_loss: 0.5487 - val_cat_output_acc: 0.1374 - val_num_output_acc: 0.8786\n",
      "Epoch 38/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.1961 - cat_output_loss: 1.9526 - num_output_loss: 0.2435 - cat_output_acc: 0.3722 - num_output_acc: 0.5360 - val_loss: 3.5057 - val_cat_output_loss: 3.0877 - val_num_output_loss: 0.4180 - val_cat_output_acc: 0.1372 - val_num_output_acc: 0.4477\n",
      "Epoch 39/100\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 2.1707 - cat_output_loss: 1.9401 - num_output_loss: 0.2306 - cat_output_acc: 0.3743 - num_output_acc: 0.5444 - val_loss: 3.6297 - val_cat_output_loss: 3.1074 - val_num_output_loss: 0.5223 - val_cat_output_acc: 0.1360 - val_num_output_acc: 0.6372\n",
      "Epoch 40/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.1629 - cat_output_loss: 1.9176 - num_output_loss: 0.2453 - cat_output_acc: 0.3813 - num_output_acc: 0.5619 - val_loss: 3.6073 - val_cat_output_loss: 3.1286 - val_num_output_loss: 0.4786 - val_cat_output_acc: 0.1356 - val_num_output_acc: 0.3341\n",
      "Epoch 41/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 2.2330 - cat_output_loss: 1.9193 - num_output_loss: 0.3136 - cat_output_acc: 0.3778 - num_output_acc: 0.5519 - val_loss: 3.6066 - val_cat_output_loss: 3.1399 - val_num_output_loss: 0.4667 - val_cat_output_acc: 0.1354 - val_num_output_acc: 0.2965\n",
      "Epoch 42/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 2.1955 - cat_output_loss: 1.9077 - num_output_loss: 0.2878 - cat_output_acc: 0.3830 - num_output_acc: 0.5499 - val_loss: 3.5764 - val_cat_output_loss: 3.1459 - val_num_output_loss: 0.4304 - val_cat_output_acc: 0.1370 - val_num_output_acc: 0.8363\n",
      "Epoch 43/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 2.1288 - cat_output_loss: 1.8818 - num_output_loss: 0.2469 - cat_output_acc: 0.3930 - num_output_acc: 0.5649 - val_loss: 3.6554 - val_cat_output_loss: 3.1418 - val_num_output_loss: 0.5136 - val_cat_output_acc: 0.1394 - val_num_output_acc: 0.4708\n",
      "Epoch 44/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.0939 - cat_output_loss: 1.8684 - num_output_loss: 0.2255 - cat_output_acc: 0.3970 - num_output_acc: 0.5631 - val_loss: 3.6569 - val_cat_output_loss: 3.1638 - val_num_output_loss: 0.4932 - val_cat_output_acc: 0.1330 - val_num_output_acc: 0.5655\n",
      "Epoch 45/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.0510 - cat_output_loss: 1.8426 - num_output_loss: 0.2084 - cat_output_acc: 0.4061 - num_output_acc: 0.5670 - val_loss: 3.6848 - val_cat_output_loss: 3.2069 - val_num_output_loss: 0.4780 - val_cat_output_acc: 0.1352 - val_num_output_acc: 0.4329\n",
      "Epoch 46/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 2.0440 - cat_output_loss: 1.8427 - num_output_loss: 0.2013 - cat_output_acc: 0.4084 - num_output_acc: 0.5806 - val_loss: 3.6460 - val_cat_output_loss: 3.2061 - val_num_output_loss: 0.4399 - val_cat_output_acc: 0.1314 - val_num_output_acc: 0.6170\n",
      "Epoch 47/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.0068 - cat_output_loss: 1.8182 - num_output_loss: 0.1886 - cat_output_acc: 0.4117 - num_output_acc: 0.5460 - val_loss: 3.6523 - val_cat_output_loss: 3.2363 - val_num_output_loss: 0.4160 - val_cat_output_acc: 0.1366 - val_num_output_acc: 0.6130\n",
      "Epoch 48/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 2.0015 - cat_output_loss: 1.8027 - num_output_loss: 0.1988 - cat_output_acc: 0.4113 - num_output_acc: 0.5482 - val_loss: 3.6907 - val_cat_output_loss: 3.2632 - val_num_output_loss: 0.4275 - val_cat_output_acc: 0.1334 - val_num_output_acc: 0.3972\n",
      "Epoch 49/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 2.0284 - cat_output_loss: 1.8035 - num_output_loss: 0.2249 - cat_output_acc: 0.4181 - num_output_acc: 0.5696 - val_loss: 3.6509 - val_cat_output_loss: 3.2346 - val_num_output_loss: 0.4163 - val_cat_output_acc: 0.1328 - val_num_output_acc: 0.7390\n",
      "Epoch 50/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 1.9916 - cat_output_loss: 1.7891 - num_output_loss: 0.2025 - cat_output_acc: 0.4173 - num_output_acc: 0.5506 - val_loss: 3.6744 - val_cat_output_loss: 3.2495 - val_num_output_loss: 0.4249 - val_cat_output_acc: 0.1336 - val_num_output_acc: 0.2079\n",
      "Epoch 51/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 2.0016 - cat_output_loss: 1.7778 - num_output_loss: 0.2238 - cat_output_acc: 0.4257 - num_output_acc: 0.5602 - val_loss: 3.7088 - val_cat_output_loss: 3.2701 - val_num_output_loss: 0.4387 - val_cat_output_acc: 0.1296 - val_num_output_acc: 0.6765\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.9822 - cat_output_loss: 1.7616 - num_output_loss: 0.2206 - cat_output_acc: 0.4266 - num_output_acc: 0.5501 - val_loss: 3.7182 - val_cat_output_loss: 3.3060 - val_num_output_loss: 0.4122 - val_cat_output_acc: 0.1310 - val_num_output_acc: 0.8476\n",
      "Epoch 53/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 1.9592 - cat_output_loss: 1.7538 - num_output_loss: 0.2055 - cat_output_acc: 0.4303 - num_output_acc: 0.5484 - val_loss: 3.6808 - val_cat_output_loss: 3.2880 - val_num_output_loss: 0.3928 - val_cat_output_acc: 0.1332 - val_num_output_acc: 0.4852\n",
      "Epoch 54/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.9815 - cat_output_loss: 1.7471 - num_output_loss: 0.2344 - cat_output_acc: 0.4335 - num_output_acc: 0.5372 - val_loss: 3.7816 - val_cat_output_loss: 3.3255 - val_num_output_loss: 0.4561 - val_cat_output_acc: 0.1306 - val_num_output_acc: 0.3874\n",
      "Epoch 55/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.9455 - cat_output_loss: 1.7363 - num_output_loss: 0.2092 - cat_output_acc: 0.4359 - num_output_acc: 0.5775 - val_loss: 3.7569 - val_cat_output_loss: 3.3210 - val_num_output_loss: 0.4359 - val_cat_output_acc: 0.1332 - val_num_output_acc: 0.1554\n",
      "Epoch 56/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 1.9851 - cat_output_loss: 1.7319 - num_output_loss: 0.2532 - cat_output_acc: 0.4370 - num_output_acc: 0.5583 - val_loss: 3.7797 - val_cat_output_loss: 3.3394 - val_num_output_loss: 0.4403 - val_cat_output_acc: 0.1320 - val_num_output_acc: 0.4535\n",
      "Epoch 57/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.9548 - cat_output_loss: 1.7176 - num_output_loss: 0.2372 - cat_output_acc: 0.4409 - num_output_acc: 0.5578 - val_loss: 3.7194 - val_cat_output_loss: 3.3054 - val_num_output_loss: 0.4141 - val_cat_output_acc: 0.1312 - val_num_output_acc: 0.6781\n",
      "Epoch 58/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 1.9451 - cat_output_loss: 1.7107 - num_output_loss: 0.2344 - cat_output_acc: 0.4427 - num_output_acc: 0.5612 - val_loss: 3.7893 - val_cat_output_loss: 3.3509 - val_num_output_loss: 0.4384 - val_cat_output_acc: 0.1312 - val_num_output_acc: 0.5062\n",
      "Epoch 59/100\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 1.9240 - cat_output_loss: 1.6974 - num_output_loss: 0.2266 - cat_output_acc: 0.4486 - num_output_acc: 0.5455 - val_loss: 3.8250 - val_cat_output_loss: 3.3527 - val_num_output_loss: 0.4724 - val_cat_output_acc: 0.1284 - val_num_output_acc: 0.4361\n",
      "Epoch 60/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 1.8956 - cat_output_loss: 1.6914 - num_output_loss: 0.2042 - cat_output_acc: 0.4519 - num_output_acc: 0.5522 - val_loss: 3.8431 - val_cat_output_loss: 3.3723 - val_num_output_loss: 0.4708 - val_cat_output_acc: 0.1280 - val_num_output_acc: 0.4724\n",
      "Epoch 61/100\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 1.8741 - cat_output_loss: 1.6790 - num_output_loss: 0.1951 - cat_output_acc: 0.4534 - num_output_acc: 0.5764 - val_loss: 3.8212 - val_cat_output_loss: 3.3908 - val_num_output_loss: 0.4304 - val_cat_output_acc: 0.1270 - val_num_output_acc: 0.7404\n",
      "Epoch 62/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 1.8632 - cat_output_loss: 1.6615 - num_output_loss: 0.2017 - cat_output_acc: 0.4524 - num_output_acc: 0.5567 - val_loss: 3.8602 - val_cat_output_loss: 3.4149 - val_num_output_loss: 0.4453 - val_cat_output_acc: 0.1250 - val_num_output_acc: 0.4565\n",
      "Epoch 63/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 1.8887 - cat_output_loss: 1.6615 - num_output_loss: 0.2272 - cat_output_acc: 0.4563 - num_output_acc: 0.5699 - val_loss: 3.9121 - val_cat_output_loss: 3.4336 - val_num_output_loss: 0.4785 - val_cat_output_acc: 0.1296 - val_num_output_acc: 0.4784\n",
      "Epoch 64/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.8525 - cat_output_loss: 1.6490 - num_output_loss: 0.2035 - cat_output_acc: 0.4607 - num_output_acc: 0.5485 - val_loss: 3.8469 - val_cat_output_loss: 3.4203 - val_num_output_loss: 0.4266 - val_cat_output_acc: 0.1280 - val_num_output_acc: 0.7959\n",
      "Epoch 65/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 1.8414 - cat_output_loss: 1.6442 - num_output_loss: 0.1972 - cat_output_acc: 0.4611 - num_output_acc: 0.5743 - val_loss: 3.9460 - val_cat_output_loss: 3.4352 - val_num_output_loss: 0.5108 - val_cat_output_acc: 0.1342 - val_num_output_acc: 0.6378\n",
      "Epoch 66/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 1.8696 - cat_output_loss: 1.6426 - num_output_loss: 0.2271 - cat_output_acc: 0.4654 - num_output_acc: 0.5618 - val_loss: 3.9234 - val_cat_output_loss: 3.4310 - val_num_output_loss: 0.4924 - val_cat_output_acc: 0.1290 - val_num_output_acc: 0.3844\n",
      "Epoch 67/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 1.9000 - cat_output_loss: 1.6427 - num_output_loss: 0.2574 - cat_output_acc: 0.4655 - num_output_acc: 0.5351 - val_loss: 3.9304 - val_cat_output_loss: 3.3980 - val_num_output_loss: 0.5324 - val_cat_output_acc: 0.1288 - val_num_output_acc: 0.7558\n",
      "Epoch 68/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 1.8489 - cat_output_loss: 1.6238 - num_output_loss: 0.2251 - cat_output_acc: 0.4691 - num_output_acc: 0.5826 - val_loss: 3.9421 - val_cat_output_loss: 3.4689 - val_num_output_loss: 0.4733 - val_cat_output_acc: 0.1272 - val_num_output_acc: 0.3548\n",
      "Epoch 69/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 1.8269 - cat_output_loss: 1.6086 - num_output_loss: 0.2183 - cat_output_acc: 0.4745 - num_output_acc: 0.5599 - val_loss: 4.0121 - val_cat_output_loss: 3.4786 - val_num_output_loss: 0.5336 - val_cat_output_acc: 0.1272 - val_num_output_acc: 0.1817\n",
      "Epoch 70/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 1.8100 - cat_output_loss: 1.6067 - num_output_loss: 0.2033 - cat_output_acc: 0.4765 - num_output_acc: 0.5640 - val_loss: 3.9309 - val_cat_output_loss: 3.4860 - val_num_output_loss: 0.4449 - val_cat_output_acc: 0.1254 - val_num_output_acc: 0.3081\n",
      "Epoch 71/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.7803 - cat_output_loss: 1.5896 - num_output_loss: 0.1907 - cat_output_acc: 0.4789 - num_output_acc: 0.5530 - val_loss: 3.9813 - val_cat_output_loss: 3.5546 - val_num_output_loss: 0.4268 - val_cat_output_acc: 0.1284 - val_num_output_acc: 0.6917\n",
      "Epoch 72/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.7720 - cat_output_loss: 1.5843 - num_output_loss: 0.1877 - cat_output_acc: 0.4819 - num_output_acc: 0.5767 - val_loss: 4.0158 - val_cat_output_loss: 3.5498 - val_num_output_loss: 0.4660 - val_cat_output_acc: 0.1258 - val_num_output_acc: 0.4195\n",
      "Epoch 73/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 1.7781 - cat_output_loss: 1.5744 - num_output_loss: 0.2037 - cat_output_acc: 0.4844 - num_output_acc: 0.5594 - val_loss: 4.0238 - val_cat_output_loss: 3.5101 - val_num_output_loss: 0.5137 - val_cat_output_acc: 0.1226 - val_num_output_acc: 0.7638\n",
      "Epoch 74/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 1.7811 - cat_output_loss: 1.5774 - num_output_loss: 0.2037 - cat_output_acc: 0.4877 - num_output_acc: 0.5512 - val_loss: 3.9903 - val_cat_output_loss: 3.5549 - val_num_output_loss: 0.4354 - val_cat_output_acc: 0.1294 - val_num_output_acc: 0.3506\n",
      "Epoch 75/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.7815 - cat_output_loss: 1.5670 - num_output_loss: 0.2145 - cat_output_acc: 0.4888 - num_output_acc: 0.5576 - val_loss: 3.9728 - val_cat_output_loss: 3.5579 - val_num_output_loss: 0.4148 - val_cat_output_acc: 0.1268 - val_num_output_acc: 0.7001\n",
      "Epoch 76/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.7944 - cat_output_loss: 1.5536 - num_output_loss: 0.2408 - cat_output_acc: 0.4924 - num_output_acc: 0.5525 - val_loss: 3.9903 - val_cat_output_loss: 3.5548 - val_num_output_loss: 0.4355 - val_cat_output_acc: 0.1264 - val_num_output_acc: 0.2396\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.7909 - cat_output_loss: 1.5535 - num_output_loss: 0.2374 - cat_output_acc: 0.4903 - num_output_acc: 0.5484 - val_loss: 4.0711 - val_cat_output_loss: 3.5642 - val_num_output_loss: 0.5069 - val_cat_output_acc: 0.1236 - val_num_output_acc: 0.5599\n",
      "Epoch 78/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 1.7345 - cat_output_loss: 1.5556 - num_output_loss: 0.1788 - cat_output_acc: 0.4885 - num_output_acc: 0.5664 - val_loss: 4.0360 - val_cat_output_loss: 3.6065 - val_num_output_loss: 0.4295 - val_cat_output_acc: 0.1268 - val_num_output_acc: 0.4489\n",
      "Epoch 79/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.7524 - cat_output_loss: 1.5449 - num_output_loss: 0.2075 - cat_output_acc: 0.4957 - num_output_acc: 0.5554 - val_loss: 4.0507 - val_cat_output_loss: 3.5943 - val_num_output_loss: 0.4565 - val_cat_output_acc: 0.1256 - val_num_output_acc: 0.5897\n",
      "Epoch 80/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 1.7200 - cat_output_loss: 1.5233 - num_output_loss: 0.1967 - cat_output_acc: 0.4958 - num_output_acc: 0.5549 - val_loss: 4.1534 - val_cat_output_loss: 3.6101 - val_num_output_loss: 0.5433 - val_cat_output_acc: 0.1240 - val_num_output_acc: 0.3546\n",
      "Epoch 81/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 1.7453 - cat_output_loss: 1.5424 - num_output_loss: 0.2028 - cat_output_acc: 0.4949 - num_output_acc: 0.5569 - val_loss: 4.0214 - val_cat_output_loss: 3.6019 - val_num_output_loss: 0.4195 - val_cat_output_acc: 0.1256 - val_num_output_acc: 0.4734\n",
      "Epoch 82/100\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 1.7170 - cat_output_loss: 1.5154 - num_output_loss: 0.2017 - cat_output_acc: 0.5028 - num_output_acc: 0.5648 - val_loss: 4.0759 - val_cat_output_loss: 3.6184 - val_num_output_loss: 0.4575 - val_cat_output_acc: 0.1286 - val_num_output_acc: 0.4768\n",
      "Epoch 83/100\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 1.7190 - cat_output_loss: 1.5130 - num_output_loss: 0.2060 - cat_output_acc: 0.5053 - num_output_acc: 0.5449 - val_loss: 4.1728 - val_cat_output_loss: 3.5921 - val_num_output_loss: 0.5807 - val_cat_output_acc: 0.1262 - val_num_output_acc: 0.2480\n",
      "Epoch 84/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.7233 - cat_output_loss: 1.5053 - num_output_loss: 0.2179 - cat_output_acc: 0.5054 - num_output_acc: 0.5703 - val_loss: 4.1160 - val_cat_output_loss: 3.6778 - val_num_output_loss: 0.4382 - val_cat_output_acc: 0.1318 - val_num_output_acc: 0.7145\n",
      "Epoch 85/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.7172 - cat_output_loss: 1.5052 - num_output_loss: 0.2120 - cat_output_acc: 0.5078 - num_output_acc: 0.5513 - val_loss: 4.1556 - val_cat_output_loss: 3.6874 - val_num_output_loss: 0.4682 - val_cat_output_acc: 0.1258 - val_num_output_acc: 0.6348\n",
      "Epoch 86/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.7169 - cat_output_loss: 1.5045 - num_output_loss: 0.2124 - cat_output_acc: 0.5021 - num_output_acc: 0.5594 - val_loss: 4.1855 - val_cat_output_loss: 3.6602 - val_num_output_loss: 0.5252 - val_cat_output_acc: 0.1220 - val_num_output_acc: 0.5499\n",
      "Epoch 87/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.7192 - cat_output_loss: 1.5014 - num_output_loss: 0.2178 - cat_output_acc: 0.5059 - num_output_acc: 0.5511 - val_loss: 4.2269 - val_cat_output_loss: 3.6916 - val_num_output_loss: 0.5353 - val_cat_output_acc: 0.1242 - val_num_output_acc: 0.4621\n",
      "Epoch 88/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.6917 - cat_output_loss: 1.4861 - num_output_loss: 0.2056 - cat_output_acc: 0.5091 - num_output_acc: 0.5851 - val_loss: 4.1604 - val_cat_output_loss: 3.7101 - val_num_output_loss: 0.4503 - val_cat_output_acc: 0.1272 - val_num_output_acc: 0.3185\n",
      "Epoch 89/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.7703 - cat_output_loss: 1.4933 - num_output_loss: 0.2769 - cat_output_acc: 0.5095 - num_output_acc: 0.5467 - val_loss: 4.1617 - val_cat_output_loss: 3.6712 - val_num_output_loss: 0.4905 - val_cat_output_acc: 0.1274 - val_num_output_acc: 0.5555\n",
      "Epoch 90/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 1.6905 - cat_output_loss: 1.4685 - num_output_loss: 0.2220 - cat_output_acc: 0.5168 - num_output_acc: 0.5809 - val_loss: 4.1360 - val_cat_output_loss: 3.7263 - val_num_output_loss: 0.4097 - val_cat_output_acc: 0.1234 - val_num_output_acc: 0.5859\n",
      "Epoch 91/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.7080 - cat_output_loss: 1.4671 - num_output_loss: 0.2409 - cat_output_acc: 0.5174 - num_output_acc: 0.5607 - val_loss: 4.1503 - val_cat_output_loss: 3.7443 - val_num_output_loss: 0.4060 - val_cat_output_acc: 0.1256 - val_num_output_acc: 0.4377\n",
      "Epoch 92/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 1.6619 - cat_output_loss: 1.4594 - num_output_loss: 0.2025 - cat_output_acc: 0.5175 - num_output_acc: 0.5562 - val_loss: 4.1669 - val_cat_output_loss: 3.7301 - val_num_output_loss: 0.4368 - val_cat_output_acc: 0.1246 - val_num_output_acc: 0.4215\n",
      "Epoch 93/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 1.6868 - cat_output_loss: 1.4628 - num_output_loss: 0.2240 - cat_output_acc: 0.5154 - num_output_acc: 0.5569 - val_loss: 4.2611 - val_cat_output_loss: 3.7222 - val_num_output_loss: 0.5389 - val_cat_output_acc: 0.1266 - val_num_output_acc: 0.5719\n",
      "Epoch 94/100\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 1.6780 - cat_output_loss: 1.4522 - num_output_loss: 0.2257 - cat_output_acc: 0.5180 - num_output_acc: 0.5569 - val_loss: 4.2515 - val_cat_output_loss: 3.7479 - val_num_output_loss: 0.5036 - val_cat_output_acc: 0.1252 - val_num_output_acc: 0.6731\n",
      "Epoch 95/100\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 1.6509 - cat_output_loss: 1.4511 - num_output_loss: 0.1997 - cat_output_acc: 0.5226 - num_output_acc: 0.5615 - val_loss: 4.1701 - val_cat_output_loss: 3.7608 - val_num_output_loss: 0.4093 - val_cat_output_acc: 0.1252 - val_num_output_acc: 0.2770\n",
      "Epoch 96/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 1.6395 - cat_output_loss: 1.4347 - num_output_loss: 0.2048 - cat_output_acc: 0.5298 - num_output_acc: 0.5677 - val_loss: 4.2862 - val_cat_output_loss: 3.7823 - val_num_output_loss: 0.5039 - val_cat_output_acc: 0.1232 - val_num_output_acc: 0.3880\n",
      "Epoch 97/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 1.6395 - cat_output_loss: 1.4467 - num_output_loss: 0.1927 - cat_output_acc: 0.5215 - num_output_acc: 0.5525 - val_loss: 4.1826 - val_cat_output_loss: 3.7617 - val_num_output_loss: 0.4209 - val_cat_output_acc: 0.1224 - val_num_output_acc: 0.6554\n",
      "Epoch 98/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 1.6383 - cat_output_loss: 1.4328 - num_output_loss: 0.2055 - cat_output_acc: 0.5238 - num_output_acc: 0.5484 - val_loss: 4.2279 - val_cat_output_loss: 3.7798 - val_num_output_loss: 0.4481 - val_cat_output_acc: 0.1224 - val_num_output_acc: 0.3035\n",
      "Epoch 99/100\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 1.6223 - cat_output_loss: 1.4254 - num_output_loss: 0.1969 - cat_output_acc: 0.5325 - num_output_acc: 0.5618 - val_loss: 4.3475 - val_cat_output_loss: 3.8019 - val_num_output_loss: 0.5457 - val_cat_output_acc: 0.1250 - val_num_output_acc: 0.7406\n",
      "Epoch 100/100\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 1.7290 - cat_output_loss: 1.4349 - num_output_loss: 0.2941 - cat_output_acc: 0.5235 - num_output_acc: 0.5638 - val_loss: 4.2821 - val_cat_output_loss: 3.7988 - val_num_output_loss: 0.4833 - val_cat_output_acc: 0.1258 - val_num_output_acc: 0.6400\n"
     ]
    }
   ],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "callbacks = [\n",
    "    learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "                                        # approach to get optimal value by gradually decreasing learning_rate\n",
    "#     EarlyStopping('val_loss', patience=10), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "#                                                             If val_loss deviates from the optimal value, \n",
    "#                                                             learning stops even if epoch remains.\n",
    "    ModelCheckpoint('model.h5', save_best_only=True)] # 모델을 학습시키면서 지금까지 등장했던 최적의 weight들을 항상 저장한다.\n",
    "\n",
    "history = model.fit(X, {'cat_output':Y_cat, 'num_output':Y_num}, epochs=100, batch_size=128, callbacks=callbacks,validation_split=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 2. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 6. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 4. 0.]], Predicted=[array([[1.47671511e-08, 1.19968178e-08, 2.71409917e-09, 4.92363982e-02,\n",
      "        1.13433501e-07, 7.02001933e-13, 2.47049325e-10, 4.22991281e-10,\n",
      "        7.48415826e-12, 9.90841009e-09, 5.74757575e-10, 1.51252955e-09,\n",
      "        2.71956925e-03, 5.50363737e-13, 7.10333112e-11, 2.95044167e-08,\n",
      "        2.88472620e-06, 8.67660507e-04, 7.90846175e-13, 6.00323613e-09,\n",
      "        6.85709125e-08, 8.54422569e-01, 8.41887532e-11, 3.53178020e-09,\n",
      "        5.52710766e-09, 5.22746124e-10, 1.46517753e-09, 3.74341758e-09,\n",
      "        7.57640706e-09, 1.91134261e-12, 9.15924194e-12, 1.36306133e-10,\n",
      "        2.49588550e-09, 5.74981772e-12, 4.63246019e-09, 1.21610055e-09,\n",
      "        1.77625907e-06, 7.88871617e-08, 2.88194056e-12, 2.05498483e-11,\n",
      "        2.20201343e-14, 7.25130066e-14, 2.45783144e-10, 2.09312006e-14,\n",
      "        1.54289026e-10, 1.63724992e-10, 4.40825241e-12, 1.60556581e-08,\n",
      "        4.49336767e-06, 1.89596494e-09, 3.13237991e-10, 4.17008095e-10,\n",
      "        8.20953865e-03, 3.80432894e-08, 1.98018957e-09, 5.95419200e-12,\n",
      "        1.52982533e-08, 2.15093965e-09, 6.32361219e-10, 5.28401108e-13,\n",
      "        6.05165188e-15, 2.00821426e-09, 2.47825493e-15, 1.52758589e-12,\n",
      "        3.30601302e-09, 1.61686428e-10, 1.25568865e-15, 2.48768471e-11,\n",
      "        2.02504402e-11, 4.71701123e-09, 3.04351184e-12, 3.00436130e-12,\n",
      "        4.64573047e-10, 5.72455382e-11, 1.69881817e-10, 2.51046406e-11,\n",
      "        4.60237293e-10, 3.79742106e-11, 8.68663752e-10, 5.06508724e-12,\n",
      "        1.69896361e-14, 2.07570853e-12, 4.43324488e-08, 4.02983424e-10,\n",
      "        1.23717394e-02, 1.16859213e-12, 4.97714925e-10, 7.00735159e-09,\n",
      "        3.54579406e-08, 4.16334312e-13, 1.51551308e-12, 6.65779823e-14,\n",
      "        1.73749495e-08, 6.09692635e-12, 6.71009635e-13, 6.20850429e-08,\n",
      "        1.88451251e-11, 7.21559078e-02, 2.31119323e-13, 2.81133450e-11,\n",
      "        1.06089183e-13, 5.20531967e-06, 8.69809257e-14, 1.57521445e-08,\n",
      "        2.05244488e-09, 7.82997556e-10, 1.46519996e-09, 1.26599425e-10,\n",
      "        4.23434616e-13, 2.09345166e-10, 4.47239329e-10, 3.81964287e-11,\n",
      "        5.83016413e-10, 5.02727200e-12, 9.95004079e-12, 2.09503153e-08,\n",
      "        1.38748487e-06, 8.01364397e-09, 2.14963229e-08, 1.02748121e-09,\n",
      "        3.44662958e-14, 1.30950462e-09, 7.07459924e-11, 1.61439051e-09,\n",
      "        3.15689336e-10, 1.00027080e-08, 6.75604350e-10, 3.43888126e-14,\n",
      "        3.15889898e-10, 3.18822831e-16, 8.03592193e-11, 8.89590901e-10,\n",
      "        7.80027848e-11, 2.52593857e-08, 9.15767906e-10, 6.55609125e-14,\n",
      "        9.40720418e-12, 2.99535211e-14, 3.25010530e-09, 3.43730747e-14,\n",
      "        3.50114049e-10, 2.03209605e-09, 2.04257809e-11, 4.01019143e-13,\n",
      "        2.54915907e-13, 2.13977124e-14, 2.90124280e-09, 5.61341826e-13,\n",
      "        5.16193685e-11, 8.69851229e-13, 2.51757247e-13, 3.05071289e-12,\n",
      "        2.39688065e-12, 8.53475568e-10, 3.51380600e-13, 9.65965228e-08,\n",
      "        4.04582678e-08, 1.13198995e-09, 1.21382237e-17, 7.07632086e-09,\n",
      "        5.59753829e-14, 6.77748385e-13, 7.51480682e-17, 8.94362980e-14,\n",
      "        1.66089137e-12, 9.55364765e-09, 3.73983136e-11, 3.84948020e-16,\n",
      "        1.01576213e-10, 1.46907345e-12, 3.59194385e-09, 3.95351862e-10,\n",
      "        3.33329267e-11, 1.69315162e-09, 1.23493338e-09, 6.20303505e-12,\n",
      "        7.36259526e-11, 2.51005972e-09, 2.10822970e-10, 1.35109271e-10,\n",
      "        6.19941219e-13, 1.41720203e-11, 7.35889349e-10, 1.95298604e-11,\n",
      "        8.61929462e-15, 2.52053119e-14, 3.93433819e-09, 2.57576648e-13,\n",
      "        1.08572405e-11, 9.02033277e-13, 6.07241774e-15, 3.00902259e-09,\n",
      "        7.53696883e-10, 2.90304558e-10, 1.04570111e-11, 3.67212129e-16,\n",
      "        2.89787888e-10, 6.60787137e-12, 8.04384044e-17, 1.08140866e-11,\n",
      "        6.00608174e-11, 6.09073486e-11, 2.81676765e-10, 4.22294005e-10,\n",
      "        1.18845162e-19, 1.94032701e-09, 4.98846589e-11, 2.06698869e-16],\n",
      "       [5.27073607e-10, 6.21968797e-15, 2.10422782e-12, 7.23917770e-09,\n",
      "        5.76983079e-11, 2.45979582e-12, 2.47364220e-16, 2.10853768e-13,\n",
      "        1.26369965e-12, 2.20865837e-09, 1.34835915e-07, 5.30543708e-12,\n",
      "        1.39557596e-04, 4.28627576e-12, 2.44019999e-10, 1.16091232e-13,\n",
      "        5.19496643e-05, 1.44625358e-06, 1.97442930e-12, 2.44377016e-08,\n",
      "        9.08616471e-09, 8.64620553e-04, 4.26498246e-12, 1.45082666e-07,\n",
      "        3.07933407e-14, 8.34216810e-12, 1.39507861e-09, 1.08001403e-11,\n",
      "        2.17057579e-16, 7.43294159e-18, 2.46454228e-17, 8.22339226e-14,\n",
      "        4.51778792e-09, 3.67208054e-13, 1.20179483e-11, 1.23479100e-16,\n",
      "        1.45580739e-01, 5.58457613e-10, 1.90168475e-17, 1.44302313e-11,\n",
      "        2.81456905e-13, 1.60358753e-15, 3.29311682e-11, 2.25450313e-16,\n",
      "        1.97583306e-17, 3.14973576e-08, 9.74485249e-13, 4.14100503e-13,\n",
      "        4.80160756e-09, 1.68588379e-08, 1.61729116e-10, 2.24922275e-10,\n",
      "        8.52767467e-01, 1.74418897e-13, 4.74444997e-11, 1.84945237e-16,\n",
      "        1.28945795e-15, 1.19907362e-09, 4.95579897e-11, 9.84688459e-13,\n",
      "        5.65753489e-17, 4.88378435e-13, 6.54552527e-18, 4.88067194e-14,\n",
      "        4.81269010e-14, 4.03393472e-07, 1.37307122e-15, 1.00071691e-14,\n",
      "        3.60324075e-13, 1.36533927e-14, 1.18281513e-11, 3.12513470e-12,\n",
      "        6.57191024e-10, 8.01519644e-16, 1.51694246e-09, 8.62477451e-12,\n",
      "        3.15635226e-11, 1.43143386e-10, 6.54613586e-11, 9.04330777e-12,\n",
      "        1.47644128e-14, 7.61764343e-15, 4.60813462e-12, 1.42892208e-13,\n",
      "        8.35242204e-08, 2.79042566e-12, 2.55294809e-12, 2.66183015e-16,\n",
      "        5.32890065e-10, 2.20742168e-19, 1.20951849e-12, 4.88866275e-19,\n",
      "        8.83130537e-13, 1.55245131e-12, 5.73596524e-16, 1.15338200e-13,\n",
      "        2.49654073e-12, 5.90614451e-04, 3.56385637e-21, 7.92571358e-13,\n",
      "        2.58693652e-12, 1.03515911e-10, 4.12876893e-15, 5.93114002e-09,\n",
      "        1.73786588e-21, 1.13749044e-09, 1.66043403e-15, 1.92958684e-22,\n",
      "        1.19150956e-12, 1.66489635e-11, 2.35982373e-10, 4.09847910e-13,\n",
      "        3.10396131e-09, 3.53446914e-18, 5.15789189e-09, 6.45822640e-09,\n",
      "        2.47873891e-06, 1.35080559e-13, 9.91657978e-10, 1.57448602e-15,\n",
      "        4.60932458e-18, 1.05012297e-15, 3.60554888e-14, 2.91486026e-14,\n",
      "        7.12443562e-15, 1.46955202e-18, 5.60653477e-12, 3.26887517e-10,\n",
      "        2.19147353e-10, 5.09479240e-22, 1.63704161e-18, 4.02277411e-09,\n",
      "        7.58632934e-10, 2.23764382e-10, 3.97005540e-10, 6.81463946e-13,\n",
      "        3.33523299e-16, 1.63922004e-21, 9.14038376e-12, 4.85600025e-14,\n",
      "        2.98086967e-12, 1.93066033e-16, 2.28332180e-11, 5.70903459e-21,\n",
      "        1.58872854e-14, 2.57202375e-16, 2.20852348e-13, 2.97976745e-23,\n",
      "        6.97526179e-16, 1.58394409e-15, 1.02775451e-24, 8.37246667e-13,\n",
      "        8.57154625e-11, 1.18767340e-11, 1.02029192e-12, 2.74236633e-10,\n",
      "        1.70502502e-15, 2.19131557e-13, 3.22485086e-21, 2.80996797e-12,\n",
      "        1.33739567e-16, 3.82173292e-17, 2.30488650e-17, 1.63524568e-16,\n",
      "        7.17718065e-18, 2.73524790e-07, 1.25774165e-11, 9.93210166e-14,\n",
      "        6.29246549e-18, 3.27467314e-21, 8.44962121e-12, 4.44717136e-12,\n",
      "        9.30806801e-19, 9.15512516e-20, 4.24795393e-10, 3.73133697e-17,\n",
      "        4.24895709e-11, 6.05217751e-11, 1.50220788e-22, 1.32520503e-12,\n",
      "        1.92646699e-16, 1.18464583e-23, 5.91602979e-14, 2.27414417e-17,\n",
      "        3.13707228e-16, 4.19099874e-14, 1.90694083e-09, 3.51979019e-14,\n",
      "        6.09586166e-12, 1.38378687e-16, 1.97165826e-28, 6.26491137e-10,\n",
      "        6.03210770e-09, 1.02763832e-10, 5.21349728e-13, 2.41817461e-24,\n",
      "        6.02892912e-14, 6.38123790e-15, 2.34348542e-27, 1.16893122e-13,\n",
      "        1.10171310e-10, 1.26700875e-23, 6.08354098e-15, 1.38763593e-11,\n",
      "        1.22295558e-29, 3.25306123e-12, 3.32977201e-09, 3.25070381e-20],\n",
      "       [6.97724363e-06, 9.66437312e-08, 3.72836297e-07, 1.28138970e-06,\n",
      "        1.40302154e-06, 9.25212749e-04, 4.33414939e-08, 4.92211029e-07,\n",
      "        2.14805323e-06, 9.77566856e-07, 2.92018490e-06, 1.73765966e-06,\n",
      "        1.95750613e-06, 3.85380496e-04, 1.15572911e-05, 2.99513545e-07,\n",
      "        7.43900102e-07, 3.99622507e-03, 6.71242697e-06, 9.70712790e-07,\n",
      "        2.90626622e-06, 2.24713585e-06, 2.70559940e-06, 4.02590075e-07,\n",
      "        3.73569122e-07, 1.02061220e-02, 2.66411917e-07, 3.73901315e-07,\n",
      "        5.39856764e-08, 1.02604099e-03, 4.14532460e-02, 2.02772057e-08,\n",
      "        3.88392294e-07, 2.49941455e-04, 7.86301644e-06, 3.18026395e-07,\n",
      "        9.65129493e-06, 2.84618864e-06, 2.90268019e-07, 6.84061766e-11,\n",
      "        1.26929099e-05, 7.44443823e-05, 1.78301216e-05, 1.07194237e-01,\n",
      "        7.32463761e-08, 1.21493849e-05, 2.55907453e-05, 1.15283498e-07,\n",
      "        4.83529671e-04, 1.32532352e-06, 3.92936417e-05, 4.20476368e-07,\n",
      "        1.58387447e-05, 4.28427411e-05, 3.84753974e-07, 1.23857080e-06,\n",
      "        1.17374432e-09, 1.01249412e-07, 1.38957304e-07, 7.48630043e-07,\n",
      "        7.15813231e-09, 1.65707533e-07, 6.67119977e-08, 6.08685380e-03,\n",
      "        3.11164570e-07, 4.17003957e-06, 3.86857039e-07, 1.63414210e-04,\n",
      "        4.15978975e-05, 7.38478957e-06, 5.79191406e-09, 4.70087916e-01,\n",
      "        1.07910205e-06, 9.63952047e-08, 1.82671863e-06, 3.21107063e-06,\n",
      "        1.95516932e-05, 7.51923892e-08, 1.42162662e-05, 8.55815670e-05,\n",
      "        1.12789239e-05, 7.46969022e-07, 1.08651017e-08, 3.75862271e-07,\n",
      "        4.01040623e-08, 1.03915583e-04, 1.71858346e-06, 2.65779800e-05,\n",
      "        1.72937121e-07, 1.29006793e-07, 1.52209941e-05, 5.02072088e-03,\n",
      "        1.73032572e-06, 3.29923387e-05, 1.51787606e-06, 4.56579510e-05,\n",
      "        5.81206621e-07, 1.16037580e-08, 3.83359020e-06, 1.89813509e-05,\n",
      "        1.08395763e-01, 1.58629689e-06, 5.92132024e-02, 1.03840139e-05,\n",
      "        1.56861830e-07, 5.42498979e-09, 2.48649059e-07, 2.00360887e-07,\n",
      "        4.76685045e-06, 2.48788638e-06, 8.61822400e-07, 1.68585572e-08,\n",
      "        7.98750762e-07, 4.42647934e-06, 1.56134911e-06, 4.41832208e-06,\n",
      "        2.51459169e-05, 2.30009917e-07, 1.91663526e-06, 1.13907754e-06,\n",
      "        8.71601421e-03, 1.34766776e-06, 5.29597571e-07, 7.05539060e-06,\n",
      "        2.40170766e-06, 1.62339219e-07, 1.81737796e-05, 9.12410451e-06,\n",
      "        1.48781439e-07, 2.12779719e-06, 1.20774494e-05, 1.01942838e-07,\n",
      "        1.94036955e-04, 5.16788667e-10, 1.28521592e-07, 1.09221628e-02,\n",
      "        2.57816805e-06, 8.78443984e-09, 7.04502611e-07, 8.74288902e-02,\n",
      "        3.73453002e-09, 3.11287185e-05, 1.01461228e-06, 3.83635401e-04,\n",
      "        8.35546743e-05, 1.53326511e-07, 8.73429826e-08, 6.93873314e-09,\n",
      "        6.50938219e-08, 2.37035192e-06, 4.98962915e-09, 2.41221060e-05,\n",
      "        1.94993999e-03, 2.08128176e-06, 1.47237230e-07, 1.69111754e-05,\n",
      "        8.04345888e-08, 4.84928132e-05, 2.35122954e-07, 5.59830804e-09,\n",
      "        8.93128060e-07, 2.49815275e-06, 7.99666537e-08, 1.25423594e-06,\n",
      "        6.91435901e-07, 2.73549836e-06, 3.80163726e-07, 6.35864410e-07,\n",
      "        7.33316085e-07, 1.92508305e-05, 7.23918490e-08, 9.20530525e-04,\n",
      "        3.18115667e-08, 3.39770416e-08, 1.65188612e-05, 1.68134255e-04,\n",
      "        7.56412604e-08, 9.02842385e-06, 5.07642484e-10, 3.74588217e-06,\n",
      "        7.00588971e-02, 9.48621803e-08, 7.33742581e-06, 6.40474518e-09,\n",
      "        8.97507834e-06, 3.23659464e-08, 4.24607919e-07, 2.75356136e-03,\n",
      "        5.47911350e-06, 3.91857233e-04, 4.74476458e-09, 1.09867108e-06,\n",
      "        4.73033033e-05, 2.68053157e-07, 2.34778213e-06, 6.98878412e-12,\n",
      "        1.65035306e-06, 5.02206319e-07, 2.97033109e-09, 3.99726332e-08,\n",
      "        8.08874319e-08, 2.02868389e-08, 8.90550034e-09, 9.97191840e-09,\n",
      "        1.46821541e-12, 7.74326807e-08, 6.63777143e-07, 4.48094409e-11]],\n",
      "      dtype=float32), array([[0.51833177, 0.15994212],\n",
      "       [0.4573509 , 4.0660214 ],\n",
      "       [1.4113574 , 1.0637263 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "Y_test = model.predict(X_test[32:35])\n",
    "Y_test1 = model.predict(X[0:5])\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (X_test[32:35],  Y_test ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['화성시' '영암군' '곡성군' '달성군' '고흥군' '영천시' '아산시' '서천군' '평창군' '음성군' '성남시' '서산시'\n",
      " '서구' '영등포구' '용인시' '광양시' '광산구' '중구' '원주시' '고양시' '논산시' '동구' '고성군' '안산시'\n",
      " '목포시' '강서구' '시흥시' '이천시' '사상구' '광진구' '서대문구' '양평군' '남양주시' '동작구' '기장군' '예산군'\n",
      " '남구' '여수시' '제천시' '세종' '춘천시' '의성군' '충주시' '서초구' '금산군' '밀양시' '김천시' '군산시'\n",
      " '대덕구' '파주시' '진주시' '김해시' '북구' '나주시' '고창군' '합천군' '무주군' '계양구' '함양군' '안동시'\n",
      " '인제군' '사하구' '철원군' '강동구' '홍성군' '안양시' '정선군' '용산구' '구미시' '부산진구' '광명시' '송파구'\n",
      " '평택시' '남원시' '함안군' '서귀포시' '경산시' '정읍시' '청주시' '상주시' '삼척시' '강릉시' '양산시' '제주시'\n",
      " '달서구' '영덕군' '여주시' '장성군' '전주시' '청도군' '포항시' '마포구' '영광군' '영주시' '도봉구' '당진시'\n",
      " '부천시' '수성구' '봉화군' '익산시' '구로구' '유성구' '금천구' '천안시' '진도군' '가평군' '강화군' '거창군'\n",
      " '군위군' '부평구' '양주시' '사천시' '의정부시' '영동군' '광주시' '창원시(통합)' '울주군' '진천군' '김포시'\n",
      " '동래구' '강남구' '보령시' '강진군' '보성군' '화순군' '순천시' '보은군' '양양군' '군포시' '청송군' '통영시'\n",
      " '수원시' '경주시' '하남시' '완주군' '양천구' '함평군' '의령군' '공주시' '성북구' '부안군' '예천군' '안성시'\n",
      " '중랑구' '칠곡군' '영월군' '수영구' '순창군' '거제시' '성주군' '장수군' '문경시' '은평구' '포천시' '울진군'\n",
      " '무안군' '해남군' '담양군' '양구군' '연천군' '횡성군' '장흥군' '태백시' '홍천군' '하동군' '남동구' '의왕시'\n",
      " '속초시' '부여군' '성동구' '김제시' '강북구' '청양군' '신안군' '해운대구' '종로구' '동두천시' '연제구' '진안군'\n",
      " '임실군' '노원구' '증평군' '단양군' '태안군' '고령군' '동해시' '연수구' '관악구' '옥천군' '동대문구' '영양군'\n",
      " '오산시' '금정구' '구례군' '괴산군' '계룡시' '완도군' '창녕군' '화천군' '남해군' '구리시' '산청군' '옹진군'\n",
      " '과천시' '울릉군' '영도구' '청원군' '연기군']\n",
      "208\n"
     ]
    }
   ],
   "source": [
    "print(all_data['발생지시군구'].unique())\n",
    "print(len(all_data['발생지시군구'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = []\n",
    "label_name.extend(all_data['발생지시군구'].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동구 0.854423\n",
      "\n",
      "남구 0.145581\n",
      "북구 0.852767\n",
      "\n",
      "서초구 0.107194\n",
      "송파구 0.470088\n",
      "구로구 0.108396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(Y_test[0])):\n",
    "    for i, x in zip(label_name, Y_test[0][n]):\n",
    "        if x>0.1:\n",
    "            print(i,'%f'%(x))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중상자수 0.518332\n",
      "경상자수 0.159942\n",
      "\n",
      "중상자수 0.457351\n",
      "경상자수 4.066021\n",
      "\n",
      "중상자수 1.411357\n",
      "경상자수 1.063726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(Y_test[0])):\n",
    "    for i, x in zip(['중상자수', '경상자수'], Y_test[1][n]):\n",
    "            print(i,'%f'%(x))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안산시 0.104156\n",
      "\n",
      "곡성군 0.932947\n",
      "\n",
      "서산시 0.435974\n",
      "예산군 0.124806\n",
      "\n",
      "서구 0.859688\n",
      "\n",
      "영등포구 0.989051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(Y_test1[0])):\n",
    "    for i, x in zip(label_name, Y_test1[0][n]):\n",
    "        if x>0.1:\n",
    "            print(i,'%f'%(x))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중상자수 0.030573\n",
      "경상자수 -0.005976\n",
      "\n",
      "중상자수 2.057601\n",
      "경상자수 1.276011\n",
      "\n",
      "중상자수 0.104355\n",
      "경상자수 -0.014663\n",
      "\n",
      "중상자수 0.083414\n",
      "경상자수 0.044379\n",
      "\n",
      "중상자수 0.307084\n",
      "경상자수 0.374533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(Y_test1[0])):\n",
    "    for i, x in zip(['중상자수', '경상자수'], Y_test1[1][n]):\n",
    "            print(i,'%f'%(x))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 11\n",
    "'발생지시도', '발생지시군구'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 108)\n",
      "(25037, 225)\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 2s 90us/step - loss: 0.0831 - acc: 0.9762 - val_loss: 0.0432 - val_acc: 0.9911\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 38us/step - loss: 0.0457 - acc: 0.9911 - val_loss: 0.0433 - val_acc: 0.9911\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0448 - acc: 0.9911 - val_loss: 0.0431 - val_acc: 0.9911\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.0442 - acc: 0.9911 - val_loss: 0.0433 - val_acc: 0.9911\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.0437 - acc: 0.9911 - val_loss: 0.0428 - val_acc: 0.9911\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.0435 - acc: 0.9911 - val_loss: 0.0426 - val_acc: 0.9911\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0432 - acc: 0.9911 - val_loss: 0.0424 - val_acc: 0.9911\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0430 - acc: 0.9911 - val_loss: 0.0423 - val_acc: 0.9911\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0428 - acc: 0.9911 - val_loss: 0.0422 - val_acc: 0.9911\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.0427 - acc: 0.9911 - val_loss: 0.0422 - val_acc: 0.9911\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0425 - acc: 0.9911 - val_loss: 0.0423 - val_acc: 0.9911\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 39us/step - loss: 0.0425 - acc: 0.9911 - val_loss: 0.0422 - val_acc: 0.9911\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0424 - acc: 0.9911 - val_loss: 0.0422 - val_acc: 0.9911\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0422 - acc: 0.9911 - val_loss: 0.0423 - val_acc: 0.9911\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.0422 - acc: 0.9911 - val_loss: 0.0423 - val_acc: 0.9911\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 1s 42us/step - loss: 0.0420 - acc: 0.9911 - val_loss: 0.0423 - val_acc: 0.9911\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0419 - acc: 0.9911 - val_loss: 0.0423 - val_acc: 0.9911\n",
      "Epoch 18/50\n",
      "20029/20029 [==============================] - 1s 41us/step - loss: 0.0418 - acc: 0.9911 - val_loss: 0.0424 - val_acc: 0.9911\n",
      "Epoch 19/50\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 0.0417 - acc: 0.9911 - val_loss: 0.0424 - val_acc: 0.9911\n",
      "Epoch 20/50\n",
      "20029/20029 [==============================] - 1s 40us/step - loss: 0.0416 - acc: 0.9911 - val_loss: 0.0424 - val_acc: 0.9911\n"
     ]
    }
   ],
   "source": [
    "col_name = []\n",
    "for col in ['발생지시도', '발생지시군구']:\n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)\n",
    "\n",
    "Y = x_train_cat[col_name].values\n",
    "X = x_train_cat.drop(columns=col_name)\n",
    "X = pd.concat([X, x_train_num], axis=1).values\n",
    "\n",
    "X_test = x_test_cat.drop(columns=col_name)\n",
    "X_test = pd.concat([X_test, x_test_num],axis=1).values\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "x = Dense(512, activation='relu')(cat_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "cat_output = Dense(len(Y[0]), activation='sigmoid', name='cat_output')(x)\n",
    "\n",
    "model = Model(inputs=cat_input, outputs=cat_output)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "callbacks = [\n",
    "    learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "                                        # approach to get optimal value by gradually decreasing learning_rate\n",
    "    EarlyStopping('val_loss', patience=10), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "                                                            # If val_loss deviates from the optimal value, \n",
    "                                                            # learning stops even if epoch remains.\n",
    "    ModelCheckpoint('model.h5', save_best_only=True)] # 모델을 학습시키면서 지금까지 등장했던 최적의 weight들을 항상 저장한다.\n",
    "\n",
    "history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[[ 1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  4.  3.  0.  0.]\n",
      " [ 0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  2.  0.  0.  0.]\n",
      " [ 0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1. 19.  9.  9.  0.]\n",
      " [ 1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.]], Predicted=[[1.58068091e-01 8.62094611e-02 1.62568726e-02 ... 5.10354235e-04\n",
      "  4.25052643e-03 1.18012995e-05]\n",
      " [1.31391928e-01 1.01974219e-01 2.15035658e-02 ... 1.03633350e-03\n",
      "  3.62043455e-03 1.77827405e-05]\n",
      " [2.93686777e-01 6.54913560e-02 2.60664839e-02 ... 6.56035088e-04\n",
      "  2.01982702e-03 1.17322879e-05]\n",
      " [1.24744907e-01 1.05279103e-01 3.31731252e-02 ... 1.42519269e-03\n",
      "  3.32491077e-03 2.44921557e-05]\n",
      " [2.04028800e-01 4.31035049e-02 6.88792691e-02 ... 9.24400170e-04\n",
      "  1.78871653e-03 5.38702125e-06]]\n",
      "['경기' '전남' '대구' '경북' '충남' '강원' '충북' '서울' '광주' '부산' '경남' '인천' '세종' '전북'\n",
      " '대전' '울산' '제주']\n",
      "17\n",
      "['화성시' '영암군' '곡성군' '달성군' '고흥군' '영천시' '아산시' '서천군' '평창군' '음성군' '성남시' '서산시'\n",
      " '서구' '영등포구' '용인시' '광양시' '광산구' '중구' '원주시' '고양시' '논산시' '동구' '고성군' '안산시'\n",
      " '목포시' '강서구' '시흥시' '이천시' '사상구' '광진구' '서대문구' '양평군' '남양주시' '동작구' '기장군' '예산군'\n",
      " '남구' '여수시' '제천시' '세종' '춘천시' '의성군' '충주시' '서초구' '금산군' '밀양시' '김천시' '군산시'\n",
      " '대덕구' '파주시' '진주시' '김해시' '북구' '나주시' '고창군' '합천군' '무주군' '계양구' '함양군' '안동시'\n",
      " '인제군' '사하구' '철원군' '강동구' '홍성군' '안양시' '정선군' '용산구' '구미시' '부산진구' '광명시' '송파구'\n",
      " '평택시' '남원시' '함안군' '서귀포시' '경산시' '정읍시' '청주시' '상주시' '삼척시' '강릉시' '양산시' '제주시'\n",
      " '달서구' '영덕군' '여주시' '장성군' '전주시' '청도군' '포항시' '마포구' '영광군' '영주시' '도봉구' '당진시'\n",
      " '부천시' '수성구' '봉화군' '익산시' '구로구' '유성구' '금천구' '천안시' '진도군' '가평군' '강화군' '거창군'\n",
      " '군위군' '부평구' '양주시' '사천시' '의정부시' '영동군' '광주시' '창원시(통합)' '울주군' '진천군' '김포시'\n",
      " '동래구' '강남구' '보령시' '강진군' '보성군' '화순군' '순천시' '보은군' '양양군' '군포시' '청송군' '통영시'\n",
      " '수원시' '경주시' '하남시' '완주군' '양천구' '함평군' '의령군' '공주시' '성북구' '부안군' '예천군' '안성시'\n",
      " '중랑구' '칠곡군' '영월군' '수영구' '순창군' '거제시' '성주군' '장수군' '문경시' '은평구' '포천시' '울진군'\n",
      " '무안군' '해남군' '담양군' '양구군' '연천군' '횡성군' '장흥군' '태백시' '홍천군' '하동군' '남동구' '의왕시'\n",
      " '속초시' '부여군' '성동구' '김제시' '강북구' '청양군' '신안군' '해운대구' '종로구' '동두천시' '연제구' '진안군'\n",
      " '임실군' '노원구' '증평군' '단양군' '태안군' '고령군' '동해시' '연수구' '관악구' '옥천군' '동대문구' '영양군'\n",
      " '오산시' '금정구' '구례군' '괴산군' '계룡시' '완도군' '창녕군' '화천군' '남해군' '구리시' '산청군' '옹진군'\n",
      " '과천시' '울릉군' '영도구' '청원군' '연기군']\n",
      "208\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# make a prediction\n",
    "Y_test = model.predict(X_test[35:40])\n",
    "Y_test1 = model.predict(X[0:5])\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (X_test[35:40],  Y_test ))\n",
    "\n",
    "print(all_data['발생지시도'].unique())\n",
    "print(len(all_data['발생지시도'].unique()))\n",
    "print(all_data['발생지시군구'].unique())\n",
    "print(len(all_data['발생지시군구'].unique()))\n",
    "\n",
    "label_name = []\n",
    "label_name.extend(all_data['발생지시도'].unique()) \n",
    "label_name.extend(all_data['발생지시군구'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경기 0.158068\n",
      "전남 0.086209\n",
      "대구 0.016257\n",
      "경북 0.182568\n",
      "충남 0.126327\n",
      "강원 0.086566\n",
      "충북 0.071384\n",
      "서울 0.015079\n",
      "광주 0.010560\n",
      "부산 0.021016\n",
      "경남 0.137889\n",
      "인천 0.015204\n",
      "전북 0.071492\n",
      "울산 0.018349\n",
      "제주 0.018146\n",
      "화성시 0.019526\n",
      "영천시 0.011078\n",
      "아산시 0.011973\n",
      "서산시 0.012585\n",
      "용인시 0.010326\n",
      "논산시 0.011160\n",
      "충주시 0.011298\n",
      "밀양시 0.010619\n",
      "파주시 0.012251\n",
      "김해시 0.013491\n",
      "평택시 0.012024\n",
      "청주시 0.012371\n",
      "상주시 0.014954\n",
      "제주시 0.010916\n",
      "당진시 0.022897\n",
      "천안시 0.011292\n",
      "창원시(통합) 0.021827\n",
      "울주군 0.011670\n",
      "경주시 0.014024\n",
      "공주시 0.012541\n",
      "안성시 0.012458\n",
      "칠곡군 0.012759\n",
      "포천시 0.010239\n"
     ]
    }
   ],
   "source": [
    "for i, x in zip(label_name, Y_test[0]):\n",
    "    if x>0.01:\n",
    "        print(i,'%f'%(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경기 0.178296\n",
      "전남 0.050037\n",
      "대구 0.075294\n",
      "경북 0.065612\n",
      "충남 0.074176\n",
      "강원 0.050881\n",
      "충북 0.040653\n",
      "서울 0.090825\n",
      "광주 0.054421\n",
      "부산 0.051104\n",
      "경남 0.084548\n",
      "인천 0.041519\n",
      "전북 0.065334\n",
      "대전 0.045206\n",
      "울산 0.027137\n",
      "제주 0.038898\n",
      "서구 0.039307\n",
      "용인시 0.013635\n",
      "광산구 0.015228\n",
      "중구 0.027567\n",
      "원주시 0.010759\n",
      "고양시 0.013146\n",
      "동구 0.025888\n",
      "안산시 0.012567\n",
      "시흥시 0.014509\n",
      "남구 0.024338\n",
      "여수시 0.012402\n",
      "춘천시 0.010288\n",
      "김해시 0.011423\n",
      "북구 0.039568\n",
      "평택시 0.010624\n",
      "청주시 0.021159\n",
      "제주시 0.029086\n",
      "전주시 0.032055\n",
      "수성구 0.017522\n",
      "천안시 0.013399\n",
      "창원시(통합) 0.018882\n",
      "순천시 0.010141\n",
      "수원시 0.016612\n"
     ]
    }
   ],
   "source": [
    "for i, x in zip(label_name, Y_test1[0]):\n",
    "    if x>0.01:\n",
    "        print(i,'%f'%(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 12\n",
    "'요일', '사고유형_대분류', '사고유형_중분류'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 303)\n",
      "(25037, 30)\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 2s 95us/step - loss: 0.2151 - acc: 0.9223 - val_loss: 0.1625 - val_acc: 0.9379\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 0.1672 - acc: 0.9368 - val_loss: 0.1616 - val_acc: 0.9380\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 47us/step - loss: 0.1634 - acc: 0.9377 - val_loss: 0.1595 - val_acc: 0.9384\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 47us/step - loss: 0.1615 - acc: 0.9385 - val_loss: 0.1599 - val_acc: 0.9378\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 0.1598 - acc: 0.9391 - val_loss: 0.1596 - val_acc: 0.9382\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 0.1583 - acc: 0.9397 - val_loss: 0.1596 - val_acc: 0.9378\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 0.1573 - acc: 0.9401 - val_loss: 0.1600 - val_acc: 0.9381\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 0.1557 - acc: 0.9406 - val_loss: 0.1597 - val_acc: 0.9381\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 0.1542 - acc: 0.9413 - val_loss: 0.1604 - val_acc: 0.9379\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 0.1530 - acc: 0.9418 - val_loss: 0.1623 - val_acc: 0.9372\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 0.1519 - acc: 0.9423 - val_loss: 0.1610 - val_acc: 0.9376\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 0.1500 - acc: 0.9432 - val_loss: 0.1621 - val_acc: 0.9374\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 0.1486 - acc: 0.9437 - val_loss: 0.1649 - val_acc: 0.9368\n"
     ]
    }
   ],
   "source": [
    "col_name = []\n",
    "for col in ['요일', '사고유형_대분류', '사고유형_중분류']:\n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)\n",
    "\n",
    "Y = x_train_cat[col_name].values\n",
    "X = x_train_cat.drop(columns=col_name)\n",
    "X = pd.concat([X, x_train_num], axis=1).values\n",
    "\n",
    "X_test = x_test_cat.drop(columns=col_name)\n",
    "X_test = pd.concat([X_test, x_test_num],axis=1).values\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "x = Dense(512, activation='relu')(cat_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "cat_output = Dense(len(Y[0]), activation='sigmoid', name='cat_output')(x)\n",
    "\n",
    "model = Model(inputs=cat_input, outputs=cat_output)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "callbacks = [\n",
    "    learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "                                        # approach to get optimal value by gradually decreasing learning_rate\n",
    "    EarlyStopping('val_loss', patience=10), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "                                                            # If val_loss deviates from the optimal value, \n",
    "                                                            # learning stops even if epoch remains.\n",
    "    ModelCheckpoint('model.h5', save_best_only=True)] # 모델을 학습시키면서 지금까지 등장했던 최적의 weight들을 항상 저장한다.\n",
    "\n",
    "history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 4. 3. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]], Predicted=[[1.8254991e-01 1.7748956e-01 6.7218043e-02 1.6199924e-01 1.6361594e-01\n",
      "  1.6820972e-01 1.6058719e-01 9.9995053e-01 3.3438475e-05 6.1423503e-05\n",
      "  4.3713189e-05 1.1081373e-01 2.0140676e-05 3.4933822e-05 1.0895180e-01\n",
      "  2.9654732e-02 6.3658386e-05 9.6006654e-02 1.7255221e-05 1.7504095e-05\n",
      "  2.0566131e-05 3.1476298e-05 9.9434819e-06 6.9980328e-05 4.8840523e-04\n",
      "  1.0225216e-04 6.9667083e-01 1.2572764e-05 1.8000661e-05 5.0014050e-06]\n",
      " [1.3333721e-01 9.2157997e-02 2.3016404e-01 1.1889083e-01 9.3463033e-02\n",
      "  1.0950976e-01 1.9154540e-01 9.9978656e-01 5.1056220e-05 3.4544332e-04\n",
      "  9.5645364e-06 6.6311136e-03 1.5766331e-05 8.1215941e-05 2.2892080e-02\n",
      "  7.7981889e-01 1.8095912e-05 1.7312765e-01 1.6795435e-05 7.8796016e-05\n",
      "  1.5902264e-05 2.1801099e-04 3.6752508e-06 4.8582792e-06 3.2818542e-04\n",
      "  3.2555652e-04 2.9722165e-02 3.0092558e-06 3.5636810e-06 1.5682330e-06]\n",
      " [1.5367904e-01 1.2940416e-01 1.1732595e-01 1.3157725e-01 1.1714340e-01\n",
      "  1.4205064e-01 1.9226772e-01 9.9998212e-01 1.2161739e-05 4.1587577e-05\n",
      "  1.8264884e-05 4.8338164e-02 8.3235609e-06 2.0050471e-05 2.8656843e-01\n",
      "  6.2591903e-02 1.6632155e-05 7.7472165e-02 8.2640581e-06 1.1732176e-05\n",
      "  8.0175123e-06 3.2739121e-05 5.0422273e-06 1.8859351e-05 2.3483807e-04\n",
      "  6.9159483e-05 5.0128615e-01 5.1875004e-06 7.6824263e-06 1.9296065e-06]]\n",
      "['금' '월' '일' '목' '수' '화' '토']\n",
      "7\n",
      "['차대차' '차대사람' '차량단독' '건널목']\n",
      "4\n",
      "['측면충돌' '차도통행중' '전도전복' '정면충돌' '추돌' '횡단중' '기타' '전도' '도로이탈' '길가장자리구역통행중'\n",
      " '공작물충돌' '전복' '보도통행중' '후진중충돌' '주/정차차량 충돌' '측면직각충돌' '차단기돌파' '직전진행' '경보기무시']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# make a prediction\n",
    "Y_test = model.predict(X_test[40:43])\n",
    "Y_test1 = model.predict(X[0:5])\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (X_test[40:43],  Y_test ))\n",
    "\n",
    "\n",
    "print(all_data['요일'].unique())\n",
    "print(len(all_data['요일'].unique()))\n",
    "print(all_data['사고유형_대분류'].unique())\n",
    "print(len(all_data['사고유형_대분류'].unique()))\n",
    "print(all_data['사고유형_중분류'].unique())\n",
    "\n",
    "\n",
    "label_name = []\n",
    "label_name.extend(all_data['요일'].unique()) \n",
    "label_name.extend(all_data['사고유형_대분류'].unique())\n",
    "label_name.extend(all_data['사고유형_중분류'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "금 0.182550\n",
      "월 0.177490\n",
      "일 0.067218\n",
      "목 0.161999\n",
      "수 0.163616\n",
      "화 0.168210\n",
      "토 0.160587\n",
      "차대차 0.999951\n",
      "측면충돌 0.110814\n",
      "정면충돌 0.108952\n",
      "추돌 0.029655\n",
      "기타 0.096007\n",
      "측면직각충돌 0.696671\n"
     ]
    }
   ],
   "source": [
    "for i, x in zip(label_name, Y_test[0]):\n",
    "    if x>0.01:\n",
    "        print(i,'%f'%(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "금 0.180167\n",
      "월 0.117220\n",
      "일 0.160982\n",
      "목 0.140193\n",
      "수 0.131615\n",
      "화 0.150877\n",
      "토 0.169509\n",
      "차대사람 0.999981\n",
      "차도통행중 0.217048\n",
      "횡단중 0.442390\n",
      "기타 0.300119\n",
      "길가장자리구역통행중 0.047238\n"
     ]
    }
   ],
   "source": [
    "for i, x in zip(label_name, Y_test1[0]):\n",
    "    if x>0.01:\n",
    "        print(i,'%f'%(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 13\n",
    "'요일', '사고유형_중분류', '법규위반', '도로형태_대분류'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25037, 278)\n",
      "(25037, 55)\n",
      "Train on 20029 samples, validate on 5008 samples\n",
      "Epoch 1/50\n",
      "20029/20029 [==============================] - 2s 96us/step - loss: 0.1667 - acc: 0.9424 - val_loss: 0.1194 - val_acc: 0.9550\n",
      "Epoch 2/50\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 0.1231 - acc: 0.9542 - val_loss: 0.1144 - val_acc: 0.9569\n",
      "Epoch 3/50\n",
      "20029/20029 [==============================] - 1s 43us/step - loss: 0.1181 - acc: 0.9556 - val_loss: 0.1137 - val_acc: 0.9569\n",
      "Epoch 4/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 0.1162 - acc: 0.9561 - val_loss: 0.1126 - val_acc: 0.9572\n",
      "Epoch 5/50\n",
      "20029/20029 [==============================] - 1s 46us/step - loss: 0.1149 - acc: 0.9565 - val_loss: 0.1125 - val_acc: 0.9572\n",
      "Epoch 6/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 0.1136 - acc: 0.9569 - val_loss: 0.1120 - val_acc: 0.9574\n",
      "Epoch 7/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 0.1127 - acc: 0.9573 - val_loss: 0.1118 - val_acc: 0.9574\n",
      "Epoch 8/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 0.1117 - acc: 0.9577 - val_loss: 0.1123 - val_acc: 0.9570\n",
      "Epoch 9/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 0.1106 - acc: 0.9581 - val_loss: 0.1125 - val_acc: 0.9568\n",
      "Epoch 10/50\n",
      "20029/20029 [==============================] - 1s 47us/step - loss: 0.1099 - acc: 0.9584 - val_loss: 0.1126 - val_acc: 0.9569\n",
      "Epoch 11/50\n",
      "20029/20029 [==============================] - 1s 48us/step - loss: 0.1090 - acc: 0.9587 - val_loss: 0.1127 - val_acc: 0.9569\n",
      "Epoch 12/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 0.1080 - acc: 0.9592 - val_loss: 0.1132 - val_acc: 0.9567\n",
      "Epoch 13/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 0.1071 - acc: 0.9595 - val_loss: 0.1134 - val_acc: 0.9566\n",
      "Epoch 14/50\n",
      "20029/20029 [==============================] - 1s 45us/step - loss: 0.1064 - acc: 0.9598 - val_loss: 0.1136 - val_acc: 0.9567\n",
      "Epoch 15/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 0.1055 - acc: 0.9600 - val_loss: 0.1147 - val_acc: 0.9562\n",
      "Epoch 16/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 0.1049 - acc: 0.9604 - val_loss: 0.1145 - val_acc: 0.9562\n",
      "Epoch 17/50\n",
      "20029/20029 [==============================] - 1s 44us/step - loss: 0.1040 - acc: 0.9607 - val_loss: 0.1154 - val_acc: 0.9559\n"
     ]
    }
   ],
   "source": [
    "col_name = []\n",
    "for col in ['요일', '사고유형_중분류', '법규위반', '도로형태_대분류']:\n",
    "        for name in all_data[col].unique():\n",
    "            col_name.append(col+'_'+name)\n",
    "\n",
    "Y = x_train_cat[col_name].values\n",
    "X = x_train_cat.drop(columns=col_name)\n",
    "X = pd.concat([X, x_train_num], axis=1).values\n",
    "\n",
    "X_test = x_test_cat.drop(columns=col_name)\n",
    "X_test = pd.concat([X_test, x_test_num],axis=1).values\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "cat_input = Input(shape=(len(X[0]),), name='cat_input')\n",
    "x = Dense(512, activation='relu')(cat_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "cat_output = Dense(len(Y[0]), activation='sigmoid', name='cat_output')(x)\n",
    "\n",
    "model = Model(inputs=cat_input, outputs=cat_output)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "callbacks = [\n",
    "    learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "                                        # approach to get optimal value by gradually decreasing learning_rate\n",
    "    EarlyStopping('val_loss', patience=10), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "                                                            # If val_loss deviates from the optimal value, \n",
    "                                                            # learning stops even if epoch remains.\n",
    "    ModelCheckpoint('model.h5', save_best_only=True)] # 모델을 학습시키면서 지금까지 등장했던 최적의 weight들을 항상 저장한다.\n",
    "\n",
    "history = model.fit(X, Y, epochs=50, batch_size=128, callbacks=callbacks,validation_split=0.2 )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[[0. 1. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 2. 8. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]], Predicted=[[1.69318214e-01 1.80260569e-01 8.84435177e-02 1.31751329e-01\n",
      "  1.80879131e-01 1.32009685e-01 1.61888152e-01 7.67939538e-02\n",
      "  2.02205447e-05 1.02532875e-04 9.37371105e-02 1.47843249e-02\n",
      "  1.93018113e-05 1.65371075e-01 2.72909965e-05 1.84416604e-05\n",
      "  5.98123552e-06 4.60999108e-05 4.43066801e-06 2.57663887e-05\n",
      "  1.64931553e-04 4.27216692e-05 6.55073345e-01 3.51177187e-06\n",
      "  2.24983592e-06 1.29216176e-06 5.44227799e-03 1.49862198e-02\n",
      "  9.75900590e-02 2.06237542e-03 1.64177746e-03 4.89804983e-01\n",
      "  2.49616817e-01 2.48315960e-01 3.88809509e-04 6.87979814e-03\n",
      "  7.29251362e-04 2.02442892e-02 4.58628601e-05 7.09910069e-07\n",
      "  4.22293041e-03 2.12216582e-06 6.54732685e-06 1.39069089e-04\n",
      "  1.36771032e-05 1.59202068e-06 4.53144867e-06 9.99995470e-01\n",
      "  1.76062542e-06 2.55748182e-06 1.88754366e-05 2.01017829e-05\n",
      "  1.93196938e-05 3.56179862e-06 6.70115332e-06]\n",
      " [1.36158869e-01 1.35781199e-01 1.79300636e-01 1.20159507e-01\n",
      "  1.16534598e-01 1.34173200e-01 2.13739708e-01 6.76218770e-04\n",
      "  1.56755454e-03 2.70964235e-01 1.09867984e-03 1.22710061e-03\n",
      "  1.17148703e-03 3.32993448e-01 3.17777619e-02 4.83566597e-02\n",
      "  2.13038363e-03 3.40727270e-01 1.11932924e-03 1.02968921e-03\n",
      "  2.63609516e-04 1.64810789e-03 9.93810594e-04 1.38959549e-05\n",
      "  1.80479819e-05 7.01192494e-06 1.06833102e-02 2.90556792e-02\n",
      "  9.22625005e-01 5.23612369e-03 2.72896197e-02 8.71131080e-04\n",
      "  2.19163394e-05 3.11120297e-04 6.23607601e-04 6.13002572e-04\n",
      "  2.85420509e-04 4.95221233e-04 1.35219633e-03 8.20538204e-04\n",
      "  4.19550925e-05 1.87070236e-05 2.32933744e-05 3.24040911e-06\n",
      "  4.68516919e-06 5.26679014e-06 9.99989033e-01 1.27883523e-05\n",
      "  2.12227405e-05 6.49931389e-05 3.67271386e-05 3.42604872e-05\n",
      "  6.12964141e-05 9.89769160e-06 3.00051306e-05]\n",
      " [1.73489749e-01 1.70127481e-01 1.33854076e-01 1.55447870e-01\n",
      "  1.48156703e-01 1.91300258e-01 1.63000897e-01 9.75632016e-03\n",
      "  2.47914577e-04 6.30271024e-05 5.39486147e-02 8.12379122e-01\n",
      "  4.35206981e-04 1.42531559e-01 1.73681110e-05 3.89202323e-05\n",
      "  1.72974847e-04 1.45944665e-04 1.33208114e-05 5.39371249e-05\n",
      "  7.29261374e-04 6.27757763e-05 2.27534566e-02 5.67806865e-06\n",
      "  2.98365444e-06 2.76243168e-06 3.12200394e-02 4.21107076e-02\n",
      "  8.87263119e-01 3.08365785e-02 4.85549308e-03 6.70378562e-04\n",
      "  7.85260909e-06 1.43199097e-04 8.71917524e-04 2.27069351e-04\n",
      "  8.09958554e-04 2.38059336e-04 3.76886630e-04 1.66702841e-04\n",
      "  3.30547518e-05 8.42044683e-05 6.08570735e-06 6.77909657e-06\n",
      "  2.44002922e-06 2.85029955e-06 9.99989152e-01 3.14615936e-05\n",
      "  4.59671082e-06 3.11249050e-06 1.04086175e-05 1.23463897e-05\n",
      "  5.39661096e-06 4.08580127e-05 6.03406488e-06]\n",
      " [1.57692060e-01 1.28748819e-01 1.50100067e-01 1.35899633e-01\n",
      "  1.39222398e-01 1.63312316e-01 1.86409384e-01 1.06282721e-04\n",
      "  1.63584724e-01 1.27128718e-04 1.15599338e-04 3.04237707e-04\n",
      "  3.76980841e-01 4.05581921e-01 1.04841776e-04 1.31042674e-04\n",
      "  1.27177775e-01 2.45073490e-04 2.78446460e-05 1.17758010e-02\n",
      "  3.51766939e-05 5.02531075e-05 5.69850781e-05 5.48194521e-06\n",
      "  2.85423835e-06 1.71288059e-06 8.67237803e-03 6.08898886e-02\n",
      "  9.19934869e-01 1.40298391e-03 9.31700412e-03 2.62944726e-03\n",
      "  6.55985832e-06 1.07826825e-04 1.09948106e-02 9.28183203e-04\n",
      "  5.12765728e-05 2.28576446e-05 5.53603822e-05 1.84039207e-04\n",
      "  1.77048169e-05 1.50126461e-05 8.91631589e-06 9.30662509e-07\n",
      "  8.09353514e-06 2.33046921e-06 9.99986768e-01 1.96536512e-05\n",
      "  1.62142333e-05 1.20425284e-05 3.24231019e-06 3.25213587e-05\n",
      "  7.00127430e-06 1.66086659e-06 7.37220580e-06]\n",
      " [1.70079112e-01 1.38975322e-01 1.38957545e-01 1.31998911e-01\n",
      "  1.34868637e-01 1.58664554e-01 1.60438791e-01 2.37461198e-02\n",
      "  2.98958528e-03 8.71847849e-03 9.34629291e-02 2.02088922e-01\n",
      "  1.72523409e-03 3.66199821e-01 2.54444289e-03 4.70784726e-03\n",
      "  4.71775373e-03 1.02803316e-02 4.57588030e-04 3.77946510e-03\n",
      "  2.69482122e-03 1.92269322e-03 7.47728273e-02 9.25258864e-05\n",
      "  8.62754896e-05 7.23152771e-05 1.26531839e-01 8.38068724e-02\n",
      "  6.47711158e-01 6.64005131e-02 5.69528565e-02 3.09269270e-03\n",
      "  1.94831344e-04 1.88419910e-03 2.92065716e-03 7.33498344e-03\n",
      "  1.05222184e-02 1.96564640e-03 4.52044699e-03 2.78403563e-03\n",
      "  3.82244150e-04 3.89999448e-04 1.35494047e-04 6.61323793e-05\n",
      "  3.73256953e-05 7.33104025e-05 9.99967813e-01 3.36392077e-05\n",
      "  5.13963641e-05 1.00553458e-04 1.23806371e-04 9.05051929e-05\n",
      "  2.62658199e-04 5.65713090e-05 1.43407073e-04]\n",
      " [1.39909595e-01 1.73847944e-01 1.13851458e-01 1.47043228e-01\n",
      "  2.09444806e-01 1.48128837e-01 1.47996515e-01 1.22789788e-05\n",
      "  7.41924718e-03 2.90725143e-06 3.02020417e-05 1.06161942e-05\n",
      "  9.11522329e-01 4.72905152e-02 3.71896704e-06 3.88662374e-06\n",
      "  6.79557119e-03 2.77625463e-06 3.10169889e-06 4.17609774e-02\n",
      "  1.36268659e-06 6.68507437e-06 1.47088767e-05 3.00858710e-06\n",
      "  1.02370723e-06 3.55205572e-07 9.21358727e-03 8.82740915e-02\n",
      "  3.09706330e-01 2.03705509e-04 3.08529660e-03 8.98156688e-02\n",
      "  2.98789673e-04 5.21319453e-04 5.34279406e-01 1.67677354e-04\n",
      "  3.40445376e-06 1.99864990e-05 2.11377937e-06 1.30888918e-06\n",
      "  3.11028052e-05 6.92540425e-07 5.21021821e-06 4.56500811e-06\n",
      "  6.16149264e-05 9.06611149e-07 2.90253287e-04 9.99744356e-01\n",
      "  2.05844248e-04 7.69040889e-06 2.17540423e-06 2.22886360e-04\n",
      "  1.92561902e-06 2.76467176e-06 8.17431646e-06]\n",
      " [1.94552168e-01 1.75242037e-01 1.16483077e-01 1.35526866e-01\n",
      "  1.96278796e-01 1.64015666e-01 1.63038269e-01 1.02709502e-01\n",
      "  2.07103803e-04 8.55429389e-04 1.54706717e-01 4.98053618e-02\n",
      "  1.45600774e-04 1.59001768e-01 3.16001591e-04 3.27821734e-04\n",
      "  9.25277418e-05 7.15378963e-04 4.87606885e-05 1.86000034e-04\n",
      "  7.70339102e-04 6.12015952e-04 5.89498162e-01 3.03610723e-05\n",
      "  2.27583096e-05 9.98867563e-06 2.22499240e-02 9.22928676e-02\n",
      "  2.43115842e-01 7.53503619e-03 7.56081101e-03 2.31699705e-01\n",
      "  2.30533302e-01 3.12023222e-01 2.07551871e-03 7.07625039e-03\n",
      "  2.70521408e-03 3.76515202e-02 4.44570789e-04 7.93926483e-06\n",
      "  1.24252886e-02 1.16892234e-05 4.84318916e-05 6.11568219e-04\n",
      "  1.33728376e-04 1.11150139e-05 1.45357008e-05 9.99984741e-01\n",
      "  1.98670823e-05 2.99306830e-05 1.00872399e-04 6.64220352e-05\n",
      "  2.01636867e-04 3.47818423e-05 5.41634508e-05]\n",
      " [1.44437492e-01 1.28337950e-01 1.45993710e-01 1.47568315e-01\n",
      "  1.32346407e-01 1.67539299e-01 2.06196383e-01 3.36251484e-04\n",
      "  9.01345164e-02 2.92883196e-05 2.26401142e-04 1.05633656e-03\n",
      "  3.89360905e-01 5.54207444e-01 2.22403087e-05 2.18842579e-05\n",
      "  4.16492820e-02 3.58313919e-05 8.19486831e-06 1.18112117e-02\n",
      "  3.84491395e-05 1.90680130e-05 2.62681511e-04 3.70860766e-06\n",
      "  1.79655274e-06 1.35723019e-06 8.32405593e-03 3.51885632e-02\n",
      "  9.19700742e-01 2.00765743e-03 7.27268914e-03 5.12412749e-03\n",
      "  4.13812859e-06 7.81080598e-05 1.52290426e-02 1.18784443e-03\n",
      "  1.05768617e-04 1.25719362e-05 2.80703080e-05 5.81019085e-05\n",
      "  1.25392480e-05 2.06413279e-05 6.78896276e-06 8.44035696e-07\n",
      "  3.54574104e-06 1.83076918e-06 9.99986410e-01 1.81281084e-05\n",
      "  6.89468925e-06 6.61911736e-06 2.02283263e-06 5.69028671e-05\n",
      "  1.83593568e-06 7.00115436e-07 4.77765298e-06]\n",
      " [1.97433218e-01 1.64845452e-01 1.79752409e-01 1.50100112e-01\n",
      "  1.73788607e-01 1.75836653e-01 1.70060545e-01 5.10311350e-02\n",
      "  2.34750146e-03 4.68010316e-03 1.80442333e-01 4.17605311e-01\n",
      "  3.53309489e-03 3.04459929e-01 1.98640418e-03 2.36906670e-03\n",
      "  3.44033819e-03 7.10015185e-03 7.50573585e-04 4.39086463e-03\n",
      "  6.28112769e-03 3.04837269e-03 1.36877596e-01 3.31660674e-04\n",
      "  2.79974367e-04 2.65306444e-04 1.83231384e-01 1.63247868e-01\n",
      "  5.09464502e-01 1.68415502e-01 6.81479722e-02 1.45201376e-02\n",
      "  5.17343695e-04 4.98379488e-03 9.81790293e-03 1.57546252e-02\n",
      "  2.02374011e-02 3.04598082e-03 8.25488009e-03 5.22147259e-03\n",
      "  1.17102917e-03 1.42469874e-03 4.44927369e-04 3.17907077e-04\n",
      "  1.47188766e-04 2.75449245e-04 9.99730408e-01 4.70602739e-04\n",
      "  3.24690511e-04 2.06796773e-04 4.29232168e-04 3.86290398e-04\n",
      "  4.95531771e-04 4.71926382e-04 4.66486847e-04]\n",
      " [1.35172382e-01 1.61488444e-01 6.95409477e-02 1.20062247e-01\n",
      "  1.89852983e-01 1.66758999e-01 1.57345697e-01 2.47891512e-05\n",
      "  5.20773083e-02 1.60075560e-05 1.78700702e-05 1.20603772e-05\n",
      "  7.19595850e-01 2.01247990e-01 1.23296240e-05 1.40003322e-05\n",
      "  3.28863077e-02 1.61073203e-05 1.62715128e-06 1.45881427e-02\n",
      "  8.24248559e-07 1.35245709e-05 1.72339223e-05 4.01273411e-07\n",
      "  1.56168383e-07 3.48511335e-08 2.53316830e-03 1.96642037e-02\n",
      "  8.40269148e-01 1.43975674e-04 2.70099635e-03 2.38763280e-02\n",
      "  4.16625524e-04 1.21288642e-03 1.33271992e-01 1.24985090e-04\n",
      "  3.55574048e-06 3.68076398e-05 7.09025073e-07 1.04310928e-07\n",
      "  5.53267128e-05 3.74189888e-08 5.01092075e-07 1.39415579e-06\n",
      "  3.34415708e-05 4.88892731e-08 9.02201975e-07 9.99999642e-01\n",
      "  4.62110529e-06 3.24778784e-06 4.74628990e-07 1.61155876e-05\n",
      "  2.79447733e-07 2.31112239e-07 7.05341392e-07]]\n",
      "['금' '월' '일' '목' '수' '화' '토']\n",
      "7\n",
      "['측면충돌' '차도통행중' '전도전복' '정면충돌' '추돌' '횡단중' '기타' '전도' '도로이탈' '길가장자리구역통행중'\n",
      " '공작물충돌' '전복' '보도통행중' '후진중충돌' '주/정차차량 충돌' '측면직각충돌' '차단기돌파' '직전진행' '경보기무시']\n",
      "19\n",
      "['중앙선 침범' '과속' '안전운전 의무 불이행' '안전거리 미확보' '기타(운전자법규위반)' '신호위반'\n",
      " '직진 및 우회전차의 통행방해' '교차로 통행방법 위반' '보행자 보호의무 위반' '부당한 회전' '차로위반(진로변경 위반)'\n",
      " '앞지르기 금지위반' '앞지르기 방법위반' '정비불량 제차의 운전금지위반' '서행 및 일시정지위반' '과로'\n",
      " '철길건널목 통과방법위반' '진로양보 의무 불이행' '보행자과실' '통행우선 순위위반']\n",
      "20\n",
      "['단일로' '교차로' '기타' '주차장' '불명' '기타/불명' '고가도로위' '지하도로내' '건널목']\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# make a prediction\n",
    "Y_test = model.predict(X_test[10:20])\n",
    "Y_test1 = model.predict(X[0:5])\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (X_test[10:20],  Y_test ))\n",
    "'요일', '사고유형_중분류', '법규위반', '도로형태_대분류'\n",
    "\n",
    "print(all_data['요일'].unique())\n",
    "print(len(all_data['요일'].unique()))\n",
    "print(all_data['사고유형_중분류'].unique())\n",
    "print(len(all_data['사고유형_중분류'].unique()))\n",
    "print(all_data['법규위반'].unique())\n",
    "print(len(all_data['법규위반'].unique()))\n",
    "print(all_data['도로형태_대분류'].unique())\n",
    "print(len(all_data['도로형태_대분류'].unique()))\n",
    "\n",
    "\n",
    "\n",
    "label_name = []\n",
    "label_name.extend(all_data['요일'].unique()) \n",
    "label_name.extend(all_data['사고유형_중분류'].unique())\n",
    "label_name.extend(all_data['법규위반'].unique())\n",
    "label_name.extend(all_data['도로형태_대분류'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "금 0.169318\n",
      "월 0.180261\n",
      "목 0.131751\n",
      "수 0.180879\n",
      "화 0.132010\n",
      "토 0.161888\n",
      "기타 0.165371\n",
      "측면직각충돌 0.655073\n",
      "신호위반 0.489805\n",
      "직진 및 우회전차의 통행방해 0.249617\n",
      "교차로 통행방법 위반 0.248316\n",
      "교차로 0.999995\n"
     ]
    }
   ],
   "source": [
    "for i, x in zip(label_name, Y_test[0]):\n",
    "    if x>0.1:\n",
    "        print(i,'%f'%(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "금 0.151723\n",
      "월 0.135136\n",
      "일 0.120095\n",
      "목 0.160154\n",
      "수 0.145061\n",
      "화 0.161431\n",
      "토 0.177064\n",
      "차도통행중 0.124685\n",
      "횡단중 0.523048\n",
      "기타 0.324323\n",
      "길가장자리구역통행중 0.038172\n",
      "보도통행중 0.011013\n",
      "과속 0.026729\n",
      "안전운전 의무 불이행 0.916653\n",
      "신호위반 0.012722\n",
      "보행자 보호의무 위반 0.019641\n",
      "단일로 0.999917\n"
     ]
    }
   ],
   "source": [
    "for i, x in zip(label_name, Y_test1[0]):\n",
    "    if x>0.01:\n",
    "        print(i,'%f'%(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_cat_data = x_train_cat[25030:25034]\n",
    "x_test_num_data = x_train_num[25030:25034]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cat = x_train_cat[:24960]\n",
    "x_train_cat_data = x_train_cat.reshape(-1,4,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_num = x_train_num[:24960]\n",
    "x_train_num_data = x_train_num.reshape(-1,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6240, 4, 11)\n",
      "(6240, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_cat_data.shape)\n",
    "print(x_train_num_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6240, 4, 11)\n"
     ]
    }
   ],
   "source": [
    "x_train_cat_data1 = np.expand_dims(x_train_cat_data, axis=0)\n",
    "print(np.expand_dims(x_train_cat_data, axis=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  1, 93,  1, 17, 10,  5,  8,  5,  2],\n",
       "       [ 0,  0, 12, 19,  2, 14, 10,  5,  8,  5,  5],\n",
       "       [ 0,  0, 15, 90,  1, 13, 10,  5,  8,  5,  2],\n",
       "       [ 0,  0,  5, 87,  2, 16, 10,  2,  4,  5, 10]])"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cat_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25030, 1, 329)\n"
     ]
    }
   ],
   "source": [
    "x_train_cat = x_train_cat[:25030]\n",
    "x_train_cat1 = np.expand_dims(x_train_cat, axis=1)\n",
    "print(x_train_cat1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"cat_input_43:0\", shape=(?, 329), dtype=float32)\n",
      "Tensor(\"reshape_1/Reshape:0\", shape=(?, 1, 329), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# cat_input = Input(shape=(329,), name='cat_input')\n",
    "# print(cat_input)\n",
    "# x = Reshape((1,329))(cat_input)\n",
    "# print(x)\n",
    "# x = LSTM(64, activation='relu', return_sequences=True)(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "# x = LSTM(64, activation='relu', return_sequences=True)(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "# x = LSTM(64, activation='relu', return_sequences=False)(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# x = Dropout(0.3)(x)\n",
    "# cat_output = Dense(329, activation='softmax', name='cat_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concatenate_42/concat:0\", shape=(?, 69), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "cate_input = Input(shape=(11,), name='cate_input')\n",
    "x = Reshape((1,11))(cate_input)\n",
    "x = LSTM(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "num_input = Input(shape=(5,), name='num_input')\n",
    "x = concatenate([x, num_input])\n",
    "print(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "cate_output = Dense(11,  activation='relu', name='cate_output')(x)\n",
    "# cate_output = Reshape((4,5),  name='cate_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[cate_input, num_input], outputs=[cate_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical_crossentropy\n",
    "model.compile(optimizer='sgd',\n",
    "              loss={'cate_output':'mse'},\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19968 samples, validate on 4992 samples\n",
      "Epoch 1/50\n",
      "19968/19968 [==============================] - 6s 295us/step - loss: 6176.9618 - acc: 0.0015 - val_loss: 1370.4375 - val_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "19968/19968 [==============================] - 3s 149us/step - loss: 1362.1600 - acc: 0.0000e+00 - val_loss: 1370.4375 - val_acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "19968/19968 [==============================] - 3s 147us/step - loss: 1362.1600 - acc: 0.0000e+00 - val_loss: 1370.4375 - val_acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "19968/19968 [==============================] - 3s 147us/step - loss: 1362.1600 - acc: 0.0000e+00 - val_loss: 1370.4375 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=25, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "callbacks = [\n",
    "    learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "                                        # approach to get optimal value by gradually decreasing learning_rate\n",
    "    EarlyStopping('val_loss', patience=3), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "                                                            # If val_loss deviates from the optimal value, \n",
    "                                                            # learning stops even if epoch remains.\n",
    "    ModelCheckpoint('model.h5', save_best_only=True)] # 모델을 학습시키면서 지금까지 등장했던 최적의 weight들을 항상 저장한다.\n",
    "\n",
    "\n",
    "hist = model.fit([x_train_cat, x_train_num], x_train_cat, epochs=50, batch_size=32, verbose=1, callbacks=callbacks, validation_split=0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   1   1 109   1  17  10   2   5   6   2]\n",
      "[1 8 0 7 0]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_cat[19])\n",
    "print(x_train_num[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_value = x_train_cat[20]\n",
    "print(type(x_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"802pt\" viewBox=\"0.00 0.00 541.50 802.00\" width=\"542pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 798)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-798 537.5,-798 537.5,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139976678122832 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139976678122832</title>\n",
       "<polygon fill=\"none\" points=\"128.5,-747.5 128.5,-793.5 400.5,-793.5 400.5,-747.5 128.5,-747.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.5\" y=\"-766.8\">cat_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"262.5,-747.5 262.5,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"262.5,-770.5 317.5,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"290\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"317.5,-747.5 317.5,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"359\" y=\"-778.3\">(None, 123)</text>\n",
       "<polyline fill=\"none\" points=\"317.5,-770.5 400.5,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"359\" y=\"-755.3\">(None, 123)</text>\n",
       "</g>\n",
       "<!-- 139976678122272 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139976678122272</title>\n",
       "<polygon fill=\"none\" points=\"141,-664.5 141,-710.5 388,-710.5 388,-664.5 141,-664.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.5\" y=\"-683.8\">dense_29: Dense</text>\n",
       "<polyline fill=\"none\" points=\"250,-664.5 250,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"250,-687.5 305,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"305,-664.5 305,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"346.5\" y=\"-695.3\">(None, 123)</text>\n",
       "<polyline fill=\"none\" points=\"305,-687.5 388,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"346.5\" y=\"-672.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139976678122832&#45;&gt;139976678122272 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139976678122832-&gt;139976678122272</title>\n",
       "<path d=\"M264.5,-747.366C264.5,-739.152 264.5,-729.658 264.5,-720.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"268,-720.607 264.5,-710.607 261,-720.607 268,-720.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139976678122048 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139976678122048</title>\n",
       "<polygon fill=\"none\" points=\"130,-581.5 130,-627.5 399,-627.5 399,-581.5 130,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.5\" y=\"-600.8\">dropout_29: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"261,-581.5 261,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.5\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"261,-604.5 316,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.5\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"316,-581.5 316,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"357.5\" y=\"-612.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"316,-604.5 399,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"357.5\" y=\"-589.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139976678122272&#45;&gt;139976678122048 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139976678122272-&gt;139976678122048</title>\n",
       "<path d=\"M264.5,-664.366C264.5,-656.152 264.5,-646.658 264.5,-637.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"268,-637.607 264.5,-627.607 261,-637.607 268,-637.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139976678122888 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139976678122888</title>\n",
       "<polygon fill=\"none\" points=\"141,-498.5 141,-544.5 388,-544.5 388,-498.5 141,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.5\" y=\"-517.8\">dense_30: Dense</text>\n",
       "<polyline fill=\"none\" points=\"250,-498.5 250,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"250,-521.5 305,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"305,-498.5 305,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"346.5\" y=\"-529.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"305,-521.5 388,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"346.5\" y=\"-506.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139976678122048&#45;&gt;139976678122888 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139976678122048-&gt;139976678122888</title>\n",
       "<path d=\"M264.5,-581.366C264.5,-573.152 264.5,-563.658 264.5,-554.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"268,-554.607 264.5,-544.607 261,-554.607 268,-554.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139977312201696 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139977312201696</title>\n",
       "<polygon fill=\"none\" points=\"130,-415.5 130,-461.5 399,-461.5 399,-415.5 130,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.5\" y=\"-434.8\">dropout_30: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"261,-415.5 261,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.5\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"261,-438.5 316,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.5\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"316,-415.5 316,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"357.5\" y=\"-446.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"316,-438.5 399,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"357.5\" y=\"-423.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139976678122888&#45;&gt;139977312201696 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139976678122888-&gt;139977312201696</title>\n",
       "<path d=\"M264.5,-498.366C264.5,-490.152 264.5,-480.658 264.5,-471.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"268,-471.607 264.5,-461.607 261,-471.607 268,-471.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139976678064200 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139976678064200</title>\n",
       "<polygon fill=\"none\" points=\"141,-332.5 141,-378.5 388,-378.5 388,-332.5 141,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.5\" y=\"-351.8\">dense_31: Dense</text>\n",
       "<polyline fill=\"none\" points=\"250,-332.5 250,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"250,-355.5 305,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"305,-332.5 305,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"346.5\" y=\"-363.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"305,-355.5 388,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"346.5\" y=\"-340.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139977312201696&#45;&gt;139976678064200 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139977312201696-&gt;139976678064200</title>\n",
       "<path d=\"M264.5,-415.366C264.5,-407.152 264.5,-397.658 264.5,-388.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"268,-388.607 264.5,-378.607 261,-388.607 268,-388.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139976678494672 -->\n",
       "<g class=\"node\" id=\"node7\"><title>139976678494672</title>\n",
       "<polygon fill=\"none\" points=\"130,-249.5 130,-295.5 399,-295.5 399,-249.5 130,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.5\" y=\"-268.8\">dropout_31: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"261,-249.5 261,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"261,-272.5 316,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"316,-249.5 316,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"357.5\" y=\"-280.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"316,-272.5 399,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"357.5\" y=\"-257.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139976678064200&#45;&gt;139976678494672 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>139976678064200-&gt;139976678494672</title>\n",
       "<path d=\"M264.5,-332.366C264.5,-324.152 264.5,-314.658 264.5,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"268,-305.607 264.5,-295.607 261,-305.607 268,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139976678475928 -->\n",
       "<g class=\"node\" id=\"node8\"><title>139976678475928</title>\n",
       "<polygon fill=\"none\" points=\"141,-166.5 141,-212.5 388,-212.5 388,-166.5 141,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.5\" y=\"-185.8\">dense_32: Dense</text>\n",
       "<polyline fill=\"none\" points=\"250,-166.5 250,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"250,-189.5 305,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"305,-166.5 305,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"346.5\" y=\"-197.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"305,-189.5 388,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"346.5\" y=\"-174.3\">(None, 256)</text>\n",
       "</g>\n",
       "<!-- 139976678494672&#45;&gt;139976678475928 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>139976678494672-&gt;139976678475928</title>\n",
       "<path d=\"M264.5,-249.366C264.5,-241.152 264.5,-231.658 264.5,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"268,-222.607 264.5,-212.607 261,-222.607 268,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139976678474024 -->\n",
       "<g class=\"node\" id=\"node9\"><title>139976678474024</title>\n",
       "<polygon fill=\"none\" points=\"130,-83.5 130,-129.5 399,-129.5 399,-83.5 130,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.5\" y=\"-102.8\">dropout_32: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"261,-83.5 261,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"261,-106.5 316,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"316,-83.5 316,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"357.5\" y=\"-114.3\">(None, 256)</text>\n",
       "<polyline fill=\"none\" points=\"316,-106.5 399,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"357.5\" y=\"-91.3\">(None, 256)</text>\n",
       "</g>\n",
       "<!-- 139976678475928&#45;&gt;139976678474024 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>139976678475928-&gt;139976678474024</title>\n",
       "<path d=\"M264.5,-166.366C264.5,-158.152 264.5,-148.658 264.5,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"268,-139.607 264.5,-129.607 261,-139.607 268,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139976678410224 -->\n",
       "<g class=\"node\" id=\"node10\"><title>139976678410224</title>\n",
       "<polygon fill=\"none\" points=\"0,-0.5 0,-46.5 253,-46.5 253,-0.5 0,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"57.5\" y=\"-19.8\">cat_output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"115,-0.5 115,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"142.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"115,-23.5 170,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"142.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"170,-0.5 170,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-31.3\">(None, 256)</text>\n",
       "<polyline fill=\"none\" points=\"170,-23.5 253,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-8.3\">(None, 208)</text>\n",
       "</g>\n",
       "<!-- 139976678474024&#45;&gt;139976678410224 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>139976678474024-&gt;139976678410224</title>\n",
       "<path d=\"M226.791,-83.3664C210.209,-73.6337 190.569,-62.1057 173.083,-51.8424\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"174.559,-48.6504 164.164,-46.6068 171.016,-54.6874 174.559,-48.6504\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139976676789496 -->\n",
       "<g class=\"node\" id=\"node11\"><title>139976676789496</title>\n",
       "<polygon fill=\"none\" points=\"271.5,-0.5 271.5,-46.5 533.5,-46.5 533.5,-0.5 271.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.5\" y=\"-19.8\">num_output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"395.5,-0.5 395.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"423\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"395.5,-23.5 450.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"423\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"450.5,-0.5 450.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492\" y=\"-31.3\">(None, 256)</text>\n",
       "<polyline fill=\"none\" points=\"450.5,-23.5 533.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"492\" y=\"-8.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 139976678474024&#45;&gt;139976676789496 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>139976678474024-&gt;139976676789496</title>\n",
       "<path d=\"M302.209,-83.3664C318.791,-73.6337 338.431,-62.1057 355.917,-51.8424\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"357.984,-54.6874 364.836,-46.6068 354.441,-48.6504 357.984,-54.6874\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[1 8 0 7 0], Predicted=[[0.86509156 7.7890024  0.33240092 6.5731373  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "Xnew2 = np.array([x_train_cat[19]])\n",
    "\n",
    "Xnew1 = np.array([x_train_num[19]])\n",
    "\n",
    "\n",
    "# make a prediction\n",
    "ynew = model.predict({'cate_input':Xnew2,'num_input':Xnew1})\n",
    "\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\" % (Xnew1[0],  ynew ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예전에 사용한 모델 데이터들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[num_input, cat_input], outputs=[num_output, cat_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'num_output':'mse', 'cat_output':'categorical_crossentropy'},\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22533 samples, validate on 2504 samples\n",
      "Epoch 1/50\n",
      "22533/22533 [==============================] - 1s 64us/step - loss: 399.6520 - num_output_loss: 0.2217 - cat_output_loss: 399.4303 - num_output_acc: 0.6617 - cat_output_acc: 0.9598 - val_loss: 380.0138 - val_num_output_loss: 0.0705 - val_cat_output_loss: 379.9433 - val_num_output_acc: 1.0000 - val_cat_output_acc: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:1043: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,val_cat_output_acc,num_output_loss,cat_output_loss,val_loss,val_cat_output_loss,val_num_output_loss,lr,cat_output_acc,val_num_output_acc,num_output_acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "22533/22533 [==============================] - 1s 49us/step - loss: 347.3038 - num_output_loss: 0.0906 - cat_output_loss: 347.2132 - num_output_acc: 0.6040 - cat_output_acc: 0.9814 - val_loss: 341.4980 - val_num_output_loss: 0.1200 - val_cat_output_loss: 341.3780 - val_num_output_acc: 1.0000 - val_cat_output_acc: 0.9800\n",
      "Epoch 3/50\n",
      "22533/22533 [==============================] - 1s 52us/step - loss: 329.4858 - num_output_loss: 0.0844 - cat_output_loss: 329.4014 - num_output_acc: 0.7987 - cat_output_acc: 0.9824 - val_loss: 332.0796 - val_num_output_loss: 0.0784 - val_cat_output_loss: 332.0012 - val_num_output_acc: 0.2716 - val_cat_output_acc: 0.9856\n",
      "Epoch 4/50\n",
      "22533/22533 [==============================] - 1s 51us/step - loss: 315.3419 - num_output_loss: 0.0825 - cat_output_loss: 315.2594 - num_output_acc: 0.8714 - cat_output_acc: 0.9835 - val_loss: 312.8341 - val_num_output_loss: 0.3030 - val_cat_output_loss: 312.5311 - val_num_output_acc: 0.2716 - val_cat_output_acc: 0.9768\n",
      "Epoch 5/50\n",
      "22533/22533 [==============================] - 1s 54us/step - loss: 307.5188 - num_output_loss: 0.0822 - cat_output_loss: 307.4366 - num_output_acc: 0.8217 - cat_output_acc: 0.9856 - val_loss: 310.0818 - val_num_output_loss: 0.0830 - val_cat_output_loss: 309.9988 - val_num_output_acc: 1.0000 - val_cat_output_acc: 0.9892\n",
      "Epoch 6/50\n",
      "22533/22533 [==============================] - 1s 52us/step - loss: 307.2955 - num_output_loss: 0.0713 - cat_output_loss: 307.2241 - num_output_acc: 0.8170 - cat_output_acc: 0.9883 - val_loss: 310.3566 - val_num_output_loss: 0.0720 - val_cat_output_loss: 310.2846 - val_num_output_acc: 1.0000 - val_cat_output_acc: 0.9896\n",
      "Epoch 7/50\n",
      "22533/22533 [==============================] - 1s 51us/step - loss: 307.2266 - num_output_loss: 0.0718 - cat_output_loss: 307.1547 - num_output_acc: 0.8099 - cat_output_acc: 0.9874 - val_loss: 310.3042 - val_num_output_loss: 0.1615 - val_cat_output_loss: 310.1427 - val_num_output_acc: 0.2716 - val_cat_output_acc: 0.9808\n",
      "Epoch 8/50\n",
      "22533/22533 [==============================] - 1s 50us/step - loss: 307.0962 - num_output_loss: 0.0722 - cat_output_loss: 307.0240 - num_output_acc: 0.7730 - cat_output_acc: 0.9876 - val_loss: 310.4889 - val_num_output_loss: 0.0804 - val_cat_output_loss: 310.4084 - val_num_output_acc: 1.0000 - val_cat_output_acc: 0.9912\n"
     ]
    }
   ],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=2, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00000001)\n",
    "\n",
    "callbacks = [\n",
    "    learning_rate_reduction, # learning_rate를 점차 감소시킴으로서 최적값에 접근하는 방식\n",
    "                                        # approach to get optimal value by gradually decreasing learning_rate\n",
    "    EarlyStopping('val_loss', patience=3), # val_loss이 최적값에서 멀어지는 순간 epoch가 남아도 학습 중지\n",
    "                                                            # If val_loss deviates from the optimal value, \n",
    "                                                            # learning stops even if epoch remains.\n",
    "    ModelCheckpoint('model.h5', save_best_only=True)] # 모델을 학습시키면서 지금까지 등장했던 최적의 weight들을 항상 저장한다.\n",
    "\n",
    "\n",
    "hist = model.fit({'num_input':x_train_num, 'cat_input':x_train_cat}, {'num_output': y_train_num, 'cat_output':x_train_cat}, epochs=50, batch_size=64, callbacks=callbacks, validation_split=0.1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25037/25037 [==============================] - 1s 39us/step\n",
      "[307.81578775862897, 0.07099316146763511, 307.74479453636155, 1.0, 0.990094659903343]\n",
      "307.81578775862897\n",
      "7.099316146763511\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate({'num_input':x_train_num, 'cat_input':x_train_cat}, {'num_output': y_train_num, 'cat_output':x_train_cat}, batch_size=32)\n",
    "print(loss_and_metrics)\n",
    "print(loss_and_metrics[0])\n",
    "print(loss_and_metrics[1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.ylim(0.0, 0.5)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
